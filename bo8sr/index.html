<!doctype html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><script async src="https://www.googletagmanager.com/gtag/js?id=G-45BYSZ6WPY"></script><script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-45BYSZ6WPY")</script><title>铃木的网络日记</title><script defer="defer" src="/static/js/main.44188c52.js"></script><link href="/static/css/main.537669bb.css" rel="stylesheet"></head><body><noscript><div><h1>论文速记</h1><h2>研究</h2><h3>【NeRF】NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis (2020)</h3>从($x,y,z,\theta,\phi$)到($R,G,B,\sigma$)</p>}experiment="测试数据集是`Diffuse Synthetic 360`、`Realistic Synthetic 360`和`Real Forward-Facing`"innovation="将输入坐标位置编码，帮助MLP表示高频函数\n分层采样"limitation="有效地优化和渲染神经辐射场\n可解释性"/><div><h4>更多笔记</h4><p>神经辐射场用于从2D的图片重建3D的场景。</p><p>文中出现的三个指标：PSNR、SSIM、LPIPS</p><div>*峰值信噪比*`(Peak Signal to Noise Ratio, PSNR)`：---用于衡量图像恢复的质量，数值越高表示图像质量越好。接近`50 dB`代表误差非常小，大于`30 dB`---人眼难察觉差异。</div><div>*结构相似性*`(Structural Similarity Index Measure, SSIM)`：---用于衡量图像的结构相似性，得分通常在`0`~`1`之间，数值越高表示图像结构越相似。相较于PSNR在图像质量的衡量上更能符合人眼对图像质量的判断。</div><div>*基于学习的感知图像质量评价*`(Learned Perceptual Image Patch Similarity, LPIPS)`：---测量从预训练网络中提取的两个图像的特征之间的相似性，得分通常在`0`~`1`之间，数值越低表示感知质量越高。</div></div><h3>【3DGS】3D Gaussian Splatting for Real-Time Radiance Field Rendering (2023)</h3><div><h4>更多笔记</h4><h4>文章的相关工作部分</h4><p>传统的场景重建与渲染：基于光场的，密集采样、非结构化捕获；运动恢复结构(Structure from Motion,SFM)用一组照片估计稀疏点云合成新视图；多视点立体视觉(Multi-View Stereo, MVS)；<br/>神经渲染和辐射场：用CNN估计混合权重，用于纹理空间；Soft3D提出Volumetric representations；NeRF提出重要性采样和位置编码来提高质量，但使用了大型多层感知器，对速度有负面影响；</p><h4>稀疏重建和稠密重建</h4><p>稀疏重建主要用于定位，得到每张图片的相机参数，提取特征点，例如SFM；稠密重建是假设相机参数已知的情况下，从不同视角的图像中找到匹配的对应点，对整个图像或图像中绝大部分像素进行重建。</p></div><h3>【NeRF RPN】NeRF-RPN: A general framework for object detection in NeRFs (2022)</h3>第一部分：特征提取器<br/>从NeRF采样的辐射度和密度网格作为输入，生成特征金字塔作为输出。<br/>第二部分：RPN头<br/>对特征金字塔进行操作并生成对象建议。</p>}innovation="第一次将RPN引入NeRF以进行3D物体检测和相关任务\n利用Hypersim和3D-FRONT数据集构建了第一个用于3D目标检测的NeRF数据集"/><h3>【Instant NGP】Instant Neural Graphics Primitives with a Multiresolution Hash Encoding (2022)</h3><div><h4>更多笔记</h4><h4>Instant NGP与NeRF的异同</h4><p>转载自<a href="https://zhuanlan.zhihu.com/p/631284285" target="_blank" rel="noreferrer">知乎：从NeRF到Instant-NGP</a></p><div>同样基于体渲染</div><div>不同于NeRF的MLP，Instant NGP使用稀疏的参数化的`voxel grid`作为场景表达</div></div>{/* <h3>【Instance NeRF】Instance Neural Radiance Field (2023)</h3>*/}{/* <div><h4>更多笔记</h4><p>稀疏重建和稠密重建<br/>稀疏重建主要用于定位，得到每张图片的相机参数，提取特征点，例如SFM；稠密重建是假设相机参数已知的情况下，从不同视角的图像中找到匹配的对应点，对整个图像或图像中绝大部分像素进行重建。</p></div> */}<h2>学习</h2><h3>【R-CNN】Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation (2014)</h3><div><h4>更多笔记</h4><p>转载自<a href="https://zh-v2.d2l.ai/chapter_computer-vision/rcnn.html" target="_blank" rel="noreferrer">动手学深度学习 -区域卷积神经网络系列</a></p><h4>R-CNN</h4><p>R-CNN先从输入图像中选取若干（例如2000个）提议区域，然后用卷积神经网络对每个提议区域进行前向传播以抽取其特征。接下来，用每个提议区域的特征来预测类别和边界框。R-CNN的速度很慢，因为可能从一张图像中选出上千个提议区域，这需要上千次的卷积神经网络的前向传播来执行目标检测。这种庞大的计算量使得R-CNN在现实世界中难以被广泛应用。</p><div>[IMAGE]</div><h4>Fast R-CNN</h4><p>R-CNN的主要性能瓶颈在于，对每个提议区域，卷积神经网络的前向传播是独立的，而没有共享计算。由于这些区域通常有重叠，独立的特征抽取会导致重复的计算。Fast R-CNN的主要改进之一，是仅在整张图象上执行卷积神经网络的前向传播，并且引入兴趣区域池化(ROI Pooling)，将卷积神经网络的输出和提议区域作为输入，输出连结后的各个提议区域抽取的特征。</p><div>[IMAGE]</div><h4>Faster R-CNN</h4><p>与Fast R-CNN相比，Faster R-CNN将生成提议区域的方法从选择性搜索改为了区域提议网络(Region ProposalNetwork, RPN)，模型的其余部分保持不变。区域提议网络作为FasterR-CNN模型的一部分，是和整个模型一起训练得到的。换句话说，FasterR-CNN的目标函数不仅包括目标检测中的类别和边界框预测，还包括区域提议网络中锚框的二元类别和边界框预测。作为端到端训练的结果，区域提议网络能够学习到如何生成高质量的提议区域，从而在减少了从数据中学习的提议区域的数量的情况下，仍保持目标检测的精度。</p><div>[IMAGE]</div></div></div></noscript><div id="root"></div></body></html>