<!DOCTYPE html><html lang="zh-CN"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="stylesheet" href="/_next/static/css/1279e9e476ea3436.css" crossorigin="" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/615f855f1eaa8d62.css" crossorigin="" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/35b01ded3cfbfcc5.css" crossorigin="" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-d5f00c42e11d76a5.js" crossorigin=""/><script src="/_next/static/chunks/fd9d1056-2b8d7efe2c8e1582.js" async="" crossorigin=""></script><script src="/_next/static/chunks/8069-254c1353640d2798.js" async="" crossorigin=""></script><script src="/_next/static/chunks/main-app-2764407e3c09a758.js" async="" crossorigin=""></script><script src="/_next/static/chunks/2202-a70b76e16443b83b.js" async=""></script><script src="/_next/static/chunks/9919-fdd433cceba36e69.js" async=""></script><script src="/_next/static/chunks/app/(posts)/23d/learn-rnn-lstm/page-4015a016e05e7e75.js" async=""></script><script src="/_next/static/chunks/5250-aaac40ffcdef4b77.js" async=""></script><script src="/_next/static/chunks/app/(posts)/layout-a1fc8e57c0d159ff.js" async=""></script><script src="/_next/static/chunks/app/layout-16a924fc60f8c1d3.js" async=""></script><script async="" src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-45BYSZ6WPY"></script><link rel="icon" href="/favicon.ico" type="image/x-icon"/><title>学习RNN和LSTM - 铃木的网络日记</title><link rel="canonical" href="https://1kuzus.github.io/23d/learn-rnn-lstm/"/><script>
window.dataLayer = window.dataLayer || [];
function gtag() {
    dataLayer.push(arguments);
}
gtag('js', new Date());
gtag('config', 'G-45BYSZ6WPY');
</script><script>const a=z=>h.getItem(z),b=(y,z)=>h.setItem(y,z),c=(y,z)=>document.documentElement.setAttribute(y,z),d='theme',e='dark',f='light',g='class',h=localStorage;a(d)!==e&&a(d)!==f&&b(d,f);a(d)===e?c(g,e):c(g,f);</script><script>
if (!Array.prototype.findLast) {
    Array.prototype.findLast = function (callback) {
        for (let i = this.length - 1; i >= 0; i--) {
            if (callback(this[i])) return this[i];
        }
        return undefined;
    };
}
if (!Array.prototype.findLastIndex) {
    Array.prototype.findLastIndex = function (callback) {
        for (let i = this.length - 1; i >= 0; i--) {
            if (callback(this[i])) return i;
        }
        return -1;
    };
}
</script><script src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js" crossorigin="" noModule=""></script></head><body><div id="header"><div id="header-left-wrapper"><a href="/"><div id="header-logo-bg"><svg xmlns="http://www.w3.org/2000/svg" width="36" height="36" viewBox="0 0 1560 1560"><path fill="#00A8C4" d="M644 97h273l272 683H916z"></path><path fill="#30303C" d="M98 97h273l409 1024L1189 97h273L916 1462H644z"></path><path fill="#00F8FF" d="M98 1462 643 97h273L371 1462z"></path></svg></div></a></div><div id="header-right-wrapper"><div id="header-show-sidebar-button" class="header-button-bg"><div></div></div><div class="header-button-bg"><div id="header-dark-theme-icon"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 1024 1024"><path fill="#FCFCFC" d="M525 939h-4a440 440 0 0 1-314-135 446 446 0 0 1-11-597A432 432 0 0 1 367 90a43 43 0 0 1 45 9 43 43 0 0 1 10 43 358 358 0 0 0 83 376 361 361 0 0 0 377 83 43 43 0 0 1 54 55 433 433 0 0 1-100 155 439 439 0 0 1-311 128z"></path></svg></div><div id="header-light-theme-icon"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 1024 1024"><path fill="#FCFCFC" d="M512 61c13 0 25 8 30 20l28 68c11 29-5 62-36 73a66 66 0 0 1-22 3c-34 0-61-25-61-56 0-7 1-14 3-20l28-68c5-12 17-20 30-20zm0 902c-13 0-25-8-30-20l-28-68a53 53 0 0 1-3-20c0-31 27-56 61-56a66 66 0 0 1 22 3c31 11 47 44 36 73l-28 68c-5 12-17 20-30 20zm451-451c0 13-8 25-20 30l-68 28c-29 11-62-5-73-36a66 66 0 0 1-3-22c0-34 25-61 56-61 7 0 14 1 20 3l68 28c12 5 20 17 20 30zm-902 0c0-13 8-25 20-30l68-28a53 53 0 0 1 20-3c31 0 56 27 56 61a66 66 0 0 1-3 22 57 57 0 0 1-73 36l-68-28c-12-5-20-17-20-30zm132-319c10-9 24-12 35-7l68 28c29 13 41 47 26 77a66 66 0 0 1-13 18c-24 24-61 26-83 4a53 53 0 0 1-12-17l-28-68c-5-11-2-25 7-35zm638 638c-10 9-24 12-35 7l-68-28a53 53 0 0 1-17-12c-22-22-20-59 4-83a66 66 0 0 1 18-13c30-15 64-3 77 26l28 68c5 11 2 25-7 35zm0-638c9 10 12 24 7 35l-28 68a56 56 0 0 1-77 26 66 66 0 0 1-18-13c-24-24-26-61-4-83 5-5 11-9 17-12l68-28c11-5 25-2 35 7zM193 831c-9-10-12-24-7-35l28-68a53 53 0 0 1 12-17c22-22 59-20 83 4a66 66 0 0 1 13 18c15 30 3 64-26 77l-68 28c-11 5-25 2-35-7zm319-94a225 225 0 1 1 0-450 225 225 0 0 1 0 450z"></path></svg></div></div><a href="https://github.com/1kuzus/1kuzus.github.io" target="_blank" rel="noreferrer"><div class="header-button-bg"><svg xmlns="http://www.w3.org/2000/svg" width="36" height="36" viewBox="0 0 1024 1024"><path fill="#FCFCFC" d="M411 831c4-5 7-10 7-12v-70c-106 22-128-44-128-44-17-45-43-56-43-56-34-24 4-24 4-24 37 3 58 39 58 39 34 58 89 41 111 32 3-24 13-41 24-51-86-10-174-43-174-188 0-41 15-75 39-102-4-10-17-48 3-101 0 0 33-10 104 40 31-9 64-12 96-12s65 5 96 12c73-50 104-40 104-40 20 53 8 91 3 101 24 27 39 60 39 102 0 145-88 178-174 188 14 12 26 34 26 70v104c0 4 2 7 7 12 5 7 3 19-4 24-3 2-7 3-10 3H425c-10 0-17-6-17-17 0-5 2-8 3-10z"></path></svg></div></a></div></div><div id="post-layout"><div id="main" class="y-center-wrapper"><div id="contents"><h4 id="contents-header">本页目录</h4></div><h1 class="x-title">学习RNN和LSTM</h1><h2 class="x-h1">RNN：一个简单的例子</h2><p class="x-p">传统神经网络每次的输入是独立的，每次输出只依赖于当前的输入；但在某些任务中需要更好的处理序列信息，即前面的输入和后面的输入是有关系的；<span class="x-inline-strong">循环神经网络</span><code class="x-inline-highlight">(Recurrent Neural Networks, RNN)</code>通过使用带自反馈的神经元，能够处理任意长度的序列。</p><p class="x-p">下面是一个非常常见的RNN结构描述图。它展示了RNN的自反馈机制和与时间的依赖关系，但是对网络结构的描述容易引起误解：右侧的展开形式并不意味着网络有<code class="x-inline-highlight">t</code>层，而是反映了随着时间增加（有时也可以理解为随着程序中循环的迭代），上一次输出的隐藏状态，和<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>共同作为网络的下一次的输入。</p><p class="x-p">或者，如果说CNN是从空间维度上堆叠卷积层，不断加深，RNN就是从时间维度上的延展，而其网络真正的参数是很少的。</p><div class="x-image-wrapper x-image-invert"><img alt="img" loading="lazy" width="2706" height="711" decoding="async" data-nimg="1" style="color:transparent;width:600px;height:auto" src="/_next/static/media/rnn1.ad2f936d.png"/></div><p class="x-p">下面以一个简单的正弦序列预测任务出发，结合代码理解RNN网络的部分细节。</p><h3 class="x-h2">预测一个正弦序列</h3><p class="x-p">这个例子中，我们对一个加了噪声的正弦序列进行预测。</p><div class="x-codeblock"><pre><code><span class="token keyword">import</span> numpy
<span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt

<span class="token comment">#生成加噪声的正弦序列数据</span>
xlim<span class="token operator">=</span>numpy<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">36</span><span class="token punctuation">,</span><span class="token number">400</span><span class="token punctuation">)</span>
y<span class="token operator">=</span>numpy<span class="token punctuation">.</span>sin<span class="token punctuation">(</span>xlim<span class="token punctuation">)</span><span class="token operator">+</span>numpy<span class="token punctuation">.</span>random<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token operator">*</span>xlim<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token operator">*</span><span class="token number">0.2</span>

<span class="token comment">#转换dtype和size，保持和后面的训练数据统一</span>
y<span class="token operator">=</span>y<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token string">"float32"</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>xlim<span class="token punctuation">,</span>y<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div><p class="x-p">代码中我们在区间<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">36</span><span class="mclose">]</span></span></span></span>取了<code class="x-inline-highlight">400</code>点数据，如果把横轴看成时间轴，可以认为数据集中有<code class="x-inline-highlight">400</code>个连续时间点的数据。</p><div class="x-image-wrapper x-image-invert"><img alt="img" loading="lazy" width="840" height="266" decoding="async" data-nimg="1" style="color:transparent;width:600px;height:auto" src="/_next/static/media/fig1.2b0c9266.png"/></div><p class="x-p no-margin-bottom">现在明确一下我们的方案：</p><div class="x-oli"><div class="x-oli-number">1.</div><div class="x-oli-content-wrapper"><p class="x-p">使用前<code class="x-inline-highlight">80%</code>也就是前<code class="x-inline-highlight">320</code>个数据作为训练集，剩余的作为测试集，观察预测结果。</p></div></div><div class="x-oli"><div class="x-oli-number">2.</div><div class="x-oli-content-wrapper"><p class="x-p">序列长度为<code class="x-inline-highlight">10</code>，也就是模型根据前<code class="x-inline-highlight">10</code>个时间点的数据去预测下一个时间点的数据。</p></div></div><div class="x-oli"><div class="x-oli-number">3.</div><div class="x-oli-content-wrapper"><p class="x-p">这个例子中输入特征的维度是<code class="x-inline-highlight">1</code>，也就是只有<code class="x-inline-highlight">y</code>值一个指标。此外，也不考虑批量大小。</p></div></div><h3 class="x-h2">定义RNN网络</h3><div class="x-codeblock"><pre><code><span class="token keyword">class</span> <span class="token class-name">MyRNN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>input_size<span class="token punctuation">,</span>hidden_size<span class="token punctuation">,</span>output_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>linear_ih<span class="token operator">=</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>input_size<span class="token punctuation">,</span>hidden_size<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>linear_hh<span class="token operator">=</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_size<span class="token punctuation">,</span>hidden_size<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>linear_ho<span class="token operator">=</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_size<span class="token punctuation">,</span>output_size<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>tanh<span class="token operator">=</span>nn<span class="token punctuation">.</span>Tanh<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">,</span>prev_state<span class="token punctuation">)</span><span class="token punctuation">:</span>
        curr_state<span class="token operator">=</span>self<span class="token punctuation">.</span>tanh<span class="token punctuation">(</span>
            self<span class="token punctuation">.</span>linear_ih<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token operator">+</span>self<span class="token punctuation">.</span>linear_hh<span class="token punctuation">(</span>prev_state<span class="token punctuation">)</span>
        <span class="token punctuation">)</span>
        output<span class="token operator">=</span>self<span class="token punctuation">.</span>linear_ho<span class="token punctuation">(</span>curr_state<span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> output<span class="token punctuation">,</span>curr_state

hidden_size<span class="token operator">=</span><span class="token number">12</span>
my_rnn<span class="token operator">=</span>MyRNN<span class="token punctuation">(</span>input_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>hidden_size<span class="token operator">=</span>hidden_size<span class="token punctuation">,</span>output_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
loss_func<span class="token operator">=</span>nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
optimizer<span class="token operator">=</span>torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>my_rnn<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span>
</code></pre></div><p class="x-p">这个是一个简单的RNN结构，从网络参数和结构来看很像一个<code class="x-inline-highlight">输入层-隐藏层-输出层</code>的感知机，但是多了一步<code class="x-inline-highlight">隐藏层-隐藏层</code>的连接，RNN的反馈结构就是由此体现的。</p><p class="x-p">并且，注意到<code class="x-inline-highlight">forward</code>函数的输入也需要两个参数：当前时刻输入<code class="x-inline-highlight">x</code>和前一时刻状态<code class="x-inline-highlight">prev_state</code>，同时也会把计算后的新状态<code class="x-inline-highlight">curr_state</code>和<code class="x-inline-highlight">output</code>一起返回，供下一次计算使用。在这里，经过<code class="x-inline-highlight">linear_ho</code>后，<code class="x-inline-highlight">output</code>的<code class="x-inline-highlight">size</code>为<code class="x-inline-highlight">(1,1)</code>，考虑到它仅仅是一个标量，我们把它<code class="x-inline-highlight">resize</code>为<code class="x-inline-highlight">(1)</code>。</p><p class="x-p">接下来设置了一些超参数，隐藏层有<code class="x-inline-highlight">12</code>个神经元，损失函数使用<code class="x-inline-highlight">MSELoss()</code>。</p><h3 class="x-h2">训练</h3><p class="x-p">首先定义这样的训练函数：它传入一个序列<code class="x-inline-highlight">train_seq</code>和目标<code class="x-inline-highlight">target</code>。<code class="x-inline-highlight">train_seq</code>的<code class="x-inline-highlight">size</code>应该为<code class="x-inline-highlight">(10,1)</code>，因为我们用前<code class="x-inline-highlight">10</code>个时间点的数据去预测下一个，而输入特征维度是<code class="x-inline-highlight">1</code>；<code class="x-inline-highlight">target</code>的<code class="x-inline-highlight">size</code>应该为<code class="x-inline-highlight">(1)</code>，因为输出只是一个标量。注意我们循环依次输入<code class="x-inline-highlight">train_seq</code>中的<code class="x-inline-highlight">10</code>个数据，迭代更新<code class="x-inline-highlight">state</code>，用最后一次的<code class="x-inline-highlight">output</code>作为最终的输出计算损失。</p><div class="x-codeblock"><pre><code><span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>train_seq<span class="token punctuation">,</span>target<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment">#初始状态</span>
    state<span class="token operator">=</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>hidden_size<span class="token punctuation">)</span>

    <span class="token keyword">for</span> x <span class="token keyword">in</span> train_seq<span class="token punctuation">:</span>
        output<span class="token punctuation">,</span>state<span class="token operator">=</span>my_rnn<span class="token punctuation">(</span>x<span class="token punctuation">,</span>state<span class="token punctuation">)</span>

    loss<span class="token operator">=</span>loss_func<span class="token punctuation">(</span>output<span class="token punctuation">,</span>target<span class="token punctuation">)</span>
    optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
    optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment">#返回损失</span>
    <span class="token keyword">return</span> loss<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
</code></pre></div><p class="x-p">下面代码把真实数据划分成：</p><div class="x-table-wrapper"><table class="x-table"><tbody><tr><th><p class="x-p"><code class="x-inline-highlight">train_seq</code></p></th><th><p class="x-p"><code class="x-inline-highlight">target</code></p></th></tr><tr><td><p class="x-p"><code class="x-inline-highlight">y[0]</code>,<code class="x-inline-highlight">y[1]</code>,<code class="x-inline-highlight">y[2]</code>, ... ,<code class="x-inline-highlight">y[9]</code></p></td><td><p class="x-p"><code class="x-inline-highlight">y[10]</code></p></td></tr><tr><td><p class="x-p"><code class="x-inline-highlight">y[1]</code>,<code class="x-inline-highlight">y[2]</code>,<code class="x-inline-highlight">y[3]</code>, ... ,<code class="x-inline-highlight">y[10]</code></p></td><td><p class="x-p"><code class="x-inline-highlight">y[11]</code></p></td></tr><tr><td><p class="x-p"><code class="x-inline-highlight">y[2]</code>,<code class="x-inline-highlight">y[3]</code>,<code class="x-inline-highlight">y[4]</code>, ... ,<code class="x-inline-highlight">y[11]</code></p></td><td><p class="x-p"><code class="x-inline-highlight">y[12]</code></p></td></tr><tr><td>...</td><td>...</td></tr><tr><td><p class="x-p"><code class="x-inline-highlight">y[309]</code>,<code class="x-inline-highlight">y[310]</code>,<code class="x-inline-highlight">y[311]</code>, ... ,<code class="x-inline-highlight">y[318]</code></p></td><td><p class="x-p"><code class="x-inline-highlight">y[319]</code></p></td></tr></tbody></table></div><div class="x-codeblock"><pre><code>train_datas<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">320</span><span class="token operator">-</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    train_seq<span class="token operator">=</span>torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>y<span class="token punctuation">[</span>i<span class="token punctuation">:</span>i<span class="token operator">+</span><span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    target<span class="token operator">=</span>torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>y<span class="token punctuation">[</span>i<span class="token operator">+</span><span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    train_datas<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span>train_seq<span class="token punctuation">,</span>target<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre></div><p class="x-p">训练网络，绘制误差：</p><div class="x-codeblock"><pre><code>metrics<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>
my_rnn<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> train_seq<span class="token punctuation">,</span>target <span class="token keyword">in</span> train_datas<span class="token punctuation">:</span>
    loss<span class="token operator">=</span>train<span class="token punctuation">(</span>train_seq<span class="token punctuation">,</span>target<span class="token punctuation">)</span>
    metrics<span class="token punctuation">.</span>append<span class="token punctuation">(</span>loss<span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">211</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>metrics<span class="token punctuation">,</span>label<span class="token operator">=</span><span class="token string">"loss"</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div><h3 class="x-h2">预测</h3><p class="x-p">这个例子中我们用<span class="x-inline-strong">单步预测</span>观察模型的效果。在单步预测时，每次预测都全部使用真实值；当然，我们可以这样做是因为验证集中本来就包含了真实的数据，换句话说，我们是在已知<code class="x-inline-highlight">t+1</code>时刻的真实数据的情况下，去看看模型使用<code class="x-inline-highlight">t-9</code>~<code class="x-inline-highlight">t</code>时刻的数据，对<code class="x-inline-highlight">t+1</code>时刻的预测值。</p><div class="x-table-wrapper"><table class="x-table"><tbody><tr><th><p class="x-p"><code class="x-inline-highlight">input</code></p></th><th><p class="x-p"><code class="x-inline-highlight">prediction</code></p></th></tr><tr><td><p class="x-p"><code class="x-inline-highlight">y[310]</code>,<code class="x-inline-highlight">y[311]</code>,<code class="x-inline-highlight">y[312]</code>, ... ,<code class="x-inline-highlight">y[319]</code></p></td><td><p class="x-p"><code class="x-inline-highlight">pred[320]</code></p></td></tr><tr><td><p class="x-p"><code class="x-inline-highlight">y[311]</code>,<code class="x-inline-highlight">y[312]</code>,<code class="x-inline-highlight">y[313]</code>, ... ,<code class="x-inline-highlight">y[320]</code></p></td><td><p class="x-p"><code class="x-inline-highlight">pred[321]</code></p></td></tr><tr><td><p class="x-p"><code class="x-inline-highlight">y[312]</code>,<code class="x-inline-highlight">y[313]</code>,<code class="x-inline-highlight">y[314]</code>, ... ,<code class="x-inline-highlight">y[321]</code></p></td><td><p class="x-p"><code class="x-inline-highlight">pred[322]</code></p></td></tr><tr><td>...</td><td>...</td></tr></tbody></table></div><div class="x-codeblock"><pre><code><span class="token keyword">def</span> <span class="token function">pred</span><span class="token punctuation">(</span>truth_seq<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        state<span class="token operator">=</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>hidden_size<span class="token punctuation">)</span>
        <span class="token keyword">for</span> x <span class="token keyword">in</span> truth_seq<span class="token punctuation">:</span>
            output<span class="token punctuation">,</span>state<span class="token operator">=</span>my_rnn<span class="token punctuation">(</span>x<span class="token punctuation">,</span>state<span class="token punctuation">)</span>
        <span class="token keyword">return</span> output

preds<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">320</span><span class="token operator">-</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">400</span><span class="token operator">-</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    truth_seq<span class="token operator">=</span>torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>y<span class="token punctuation">[</span>i<span class="token punctuation">:</span>i<span class="token operator">+</span><span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    preds<span class="token punctuation">.</span>append<span class="token punctuation">(</span>pred<span class="token punctuation">(</span>truth_seq<span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
preds<span class="token operator">=</span>numpy<span class="token punctuation">.</span>array<span class="token punctuation">(</span>preds<span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">212</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>xlim<span class="token punctuation">,</span>y<span class="token punctuation">,</span>label<span class="token operator">=</span><span class="token string">"truth"</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>xlim<span class="token punctuation">[</span><span class="token number">320</span><span class="token punctuation">:</span><span class="token number">400</span><span class="token punctuation">]</span><span class="token punctuation">,</span>preds<span class="token punctuation">,</span><span class="token string">"red"</span><span class="token punctuation">,</span>label<span class="token operator">=</span><span class="token string">"predict"</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div><p class="x-p">如果我们不只是在测试集上评估模型性能，而是去预测真实生活中的问题，例如未来<code class="x-inline-highlight">7</code>天的温度；或者假如我们的数据集到<code class="x-inline-highlight">y[319]</code>就截止了，这时如果想得到后面多个时刻的数据，就需要<span class="x-inline-strong">多步预测</span>，此时上一时刻的预测会被当做新的输入：</p><div class="x-table-wrapper"><table class="x-table"><tbody><tr><th><p class="x-p"><code class="x-inline-highlight">input</code></p></th><th><p class="x-p"><code class="x-inline-highlight">prediction</code></p></th></tr><tr><td><p class="x-p"><code class="x-inline-highlight">y[310]</code>,<code class="x-inline-highlight">y[311]</code>,<code class="x-inline-highlight">y[312]</code>, ... ,<code class="x-inline-highlight">y[319]</code></p></td><td><p class="x-p"><code class="x-inline-highlight">pred[320]</code></p></td></tr><tr><td><p class="x-p"><code class="x-inline-highlight">y[311]</code>,<code class="x-inline-highlight">y[312]</code>,<code class="x-inline-highlight">y[313]</code>, ... ,<code class="x-inline-highlight">pred[320]</code></p></td><td><p class="x-p"><code class="x-inline-highlight">pred[321]</code></p></td></tr><tr><td><p class="x-p"><code class="x-inline-highlight">y[312]</code>,<code class="x-inline-highlight">y[313]</code>,<code class="x-inline-highlight">y[314]</code>, ... ,<code class="x-inline-highlight">pred[320]</code>,<code class="x-inline-highlight">pred[321]</code></p></td><td><p class="x-p"><code class="x-inline-highlight">pred[322]</code></p></td></tr><tr><td>...</td><td>...</td></tr></tbody></table></div><p class="x-p">多步预测会导致误差的累积。</p><h3 class="x-h2">看看效果</h3><p class="x-p">如果不执行训练步骤的代码，使用初始随机参数的模型预测结果是：</p><div class="x-image-wrapper x-image-invert"><img alt="img" loading="lazy" width="840" height="261" decoding="async" data-nimg="1" style="color:transparent;width:600px;height:auto" src="/_next/static/media/fig2.51ee0782.png"/></div><p class="x-p">经过训练后，每次训练的<code class="x-inline-highlight">loss</code>和最终的预测：</p><div class="x-image-wrapper x-image-invert"><img alt="img" loading="lazy" width="840" height="543" decoding="async" data-nimg="1" style="color:transparent;width:600px;height:auto" src="/_next/static/media/fig3.6f6f5b35.png"/></div><h3 class="x-h2">使用torch.nn.RNN</h3><p class="x-p">使用<code class="x-inline-highlight">torch.nn.RNN</code>模块时，与上面例子中手动实现的RNN有几处细小的区别，下面给出了使用<code class="x-inline-highlight">torch.nn.RNN</code>时需要做出的修改：</p><div class="x-oli"><div class="x-oli-number">1.</div><div class="x-oli-content-wrapper"><p class="x-p no-margin-bottom">定义模型时，不再需要显式指定<code class="x-inline-highlight">linear_ih</code>和<code class="x-inline-highlight">linear_hh</code>两层，将由<code class="x-inline-highlight">nn.RNN</code>模块实现；<code class="x-inline-highlight">nn.RNN</code>模块没有定义输出层，因此输出层<code class="x-inline-highlight">linear_ho</code>需要设置。<br/>在<code class="x-inline-highlight">forward</code>函数中，手动实现时为了直观展示出RNN的迭代过程，只进行了一次隐藏状态的更新；而对于输入序列迭代更新隐藏状态是在训练和预测时实现的。而<code class="x-inline-highlight">nn.RNN</code>模块的一次<code class="x-inline-highlight">forward</code>就已经完成了迭代更新，其输入是整个序列<code class="x-inline-highlight">seq</code>和<code class="x-inline-highlight">prev_state</code>，返回值是<code class="x-inline-highlight">output_hidden,curr_state</code>，对于不考虑批量大小的数据，它们的<code class="x-inline-highlight">size</code>为：</p><div class="x-uli"><div class="x-uli-marker"><div class="x-uli-marker-dot"></div></div><div class="x-uli-content-wrapper"><p class="x-p"><code class="x-inline-highlight">seq</code>: <code class="x-inline-highlight">(sequence_length, input_size)</code></p></div></div><div class="x-uli"><div class="x-uli-marker"><div class="x-uli-marker-dot"></div></div><div class="x-uli-content-wrapper"><p class="x-p"><code class="x-inline-highlight">init_state</code>: <code class="x-inline-highlight">(1, hidden_size)</code></p></div></div><div class="x-uli"><div class="x-uli-marker"><div class="x-uli-marker-dot"></div></div><div class="x-uli-content-wrapper"><p class="x-p"><code class="x-inline-highlight">output_hidden</code>: <code class="x-inline-highlight">(sequence_length, hidden_size)</code></p></div></div><div class="x-uli"><div class="x-uli-marker"><div class="x-uli-marker-dot"></div></div><div class="x-uli-content-wrapper"><p class="x-p"><code class="x-inline-highlight">state</code>: <code class="x-inline-highlight">(1, hidden_size)</code></p></div></div><p class="x-p">最后在我们定义的<code class="x-inline-highlight">MyRNN</code>模块中，用<code class="x-inline-highlight">output_hidden</code>的最后一个时间点的输出，经过输出层得到最终的<code class="x-inline-highlight">output</code>。</p></div></div><div class="x-highlightblock highlight-background-gray"><h4 class="x-h3">手动实现</h4><div class="x-codeblock"><pre><code><span class="token keyword">class</span> <span class="token class-name">MyRNN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>input_size<span class="token punctuation">,</span>hidden_size<span class="token punctuation">,</span>output_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>linear_ih<span class="token operator">=</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>input_size<span class="token punctuation">,</span>hidden_size<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>linear_hh<span class="token operator">=</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_size<span class="token punctuation">,</span>hidden_size<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>linear_ho<span class="token operator">=</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_size<span class="token punctuation">,</span>output_size<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>tanh<span class="token operator">=</span>nn<span class="token punctuation">.</span>Tanh<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">,</span>prev_state<span class="token punctuation">)</span><span class="token punctuation">:</span>
        curr_state<span class="token operator">=</span>self<span class="token punctuation">.</span>tanh<span class="token punctuation">(</span>
            self<span class="token punctuation">.</span>linear_ih<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token operator">+</span>self<span class="token punctuation">.</span>linear_hh<span class="token punctuation">(</span>prev_state<span class="token punctuation">)</span>
        <span class="token punctuation">)</span>
        output<span class="token operator">=</span>self<span class="token punctuation">.</span>linear_ho<span class="token punctuation">(</span>curr_state<span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> output<span class="token punctuation">,</span>curr_state
</code></pre></div><h4 class="x-h3">使用torch.nn.RNN</h4><div class="x-codeblock"><pre><code><span class="token keyword">class</span> <span class="token class-name">MyRNN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>input_size<span class="token punctuation">,</span>hidden_size<span class="token punctuation">,</span>output_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>rnn<span class="token operator">=</span>nn<span class="token punctuation">.</span>RNN<span class="token punctuation">(</span>input_size<span class="token operator">=</span>input_size<span class="token punctuation">,</span>hidden_size<span class="token operator">=</span>hidden_size<span class="token punctuation">,</span>batch_first<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>linear_ho<span class="token operator">=</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_size<span class="token punctuation">,</span>output_size<span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>seq<span class="token punctuation">,</span>init_state<span class="token punctuation">)</span><span class="token punctuation">:</span>
        output_hidden<span class="token punctuation">,</span>tate<span class="token operator">=</span>self<span class="token punctuation">.</span>rnn<span class="token punctuation">(</span>seq<span class="token punctuation">,</span>init_state<span class="token punctuation">)</span>
        output<span class="token operator">=</span>self<span class="token punctuation">.</span>linear_ho<span class="token punctuation">(</span>output_hidden<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment">#取最后一个时间点的输出</span>
        <span class="token keyword">return</span> output<span class="token punctuation">,</span>state
</code></pre></div></div><div class="x-oli"><div class="x-oli-number">2.</div><div class="x-oli-content-wrapper"><p class="x-p">训练和预测时，也不需要再遍历序列，迭代的过程已经在<code class="x-inline-highlight">nn.RNN</code>模块内部实现。</p></div></div><div class="x-highlightblock highlight-background-gray"><h4 class="x-h3">手动实现</h4><div class="x-codeblock"><pre><code><span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>train_seq<span class="token punctuation">,</span>target<span class="token punctuation">)</span><span class="token punctuation">:</span>
    state<span class="token operator">=</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>hidden_size<span class="token punctuation">)</span>
    <span class="token keyword">for</span> x <span class="token keyword">in</span> train_seq<span class="token punctuation">:</span>
        output<span class="token punctuation">,</span>state<span class="token operator">=</span>my_rnn<span class="token punctuation">(</span>x<span class="token punctuation">,</span>state<span class="token punctuation">)</span>
    loss<span class="token operator">=</span>loss_func<span class="token punctuation">(</span>output<span class="token punctuation">,</span>target<span class="token punctuation">)</span>
    <span class="token comment"># ......</span>
</code></pre></div><div class="x-codeblock"><pre><code><span class="token keyword">def</span> <span class="token function">pred</span><span class="token punctuation">(</span>truth_seq<span class="token punctuation">,</span>net<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        state<span class="token operator">=</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>hidden_size<span class="token punctuation">)</span>
        <span class="token keyword">for</span> x <span class="token keyword">in</span> truth_seq<span class="token punctuation">:</span>
            output<span class="token punctuation">,</span>state<span class="token operator">=</span>net<span class="token punctuation">(</span>x<span class="token punctuation">,</span>state<span class="token punctuation">)</span>
        <span class="token keyword">return</span> output
</code></pre></div><h4 class="x-h3">使用torch.nn.RNN</h4><div class="x-codeblock"><pre><code><span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>train_seq<span class="token punctuation">,</span>target<span class="token punctuation">)</span><span class="token punctuation">:</span>
    state<span class="token operator">=</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>hidden_size<span class="token punctuation">)</span>
    output<span class="token punctuation">,</span>_<span class="token operator">=</span>my_rnn<span class="token punctuation">(</span>train_seq<span class="token punctuation">,</span>state<span class="token punctuation">)</span> <span class="token comment">#一次得到输出</span>
    loss<span class="token operator">=</span>loss_func<span class="token punctuation">(</span>output<span class="token punctuation">,</span>target<span class="token punctuation">)</span>
    <span class="token comment"># ......</span>
</code></pre></div><div class="x-codeblock"><pre><code><span class="token keyword">def</span> <span class="token function">pred</span><span class="token punctuation">(</span>truth_seq<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        state<span class="token operator">=</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>hidden_size<span class="token punctuation">)</span>
        output<span class="token punctuation">,</span>_<span class="token operator">=</span>my_rnn<span class="token punctuation">(</span>truth_seq<span class="token punctuation">,</span>state<span class="token punctuation">)</span> <span class="token comment">#一次得到输出</span>
        <span class="token keyword">return</span> output
</code></pre></div></div><h3 class="x-h2">FAQ</h3><p class="x-p">初次了解RNN时，我在一些问题上困惑了很久。这个版块是对它们的再次整理。（尽管有些已经包含在上述例子中了！）</p><h4 class="x-h3">用10步预测下1步，为什么 input_size 不是10，而是1？</h4><p class="x-p"><code class="x-inline-highlight">input_size</code>与序列长度并非同一个概念。用前<code class="x-inline-highlight">10</code>个时间点的数据去预测下一个，这里的<code class="x-inline-highlight">10</code>是序列长度；而<code class="x-inline-highlight">input_size</code>是输入特征的维度。由于这个例子较为简单，只是用历史的<code class="x-inline-highlight">y</code>值预测新的<code class="x-inline-highlight">y</code>值，因此特征只有<code class="x-inline-highlight">1</code>维。</p><h4 class="x-h3">什么时候 input_size 不是1？</h4><p class="x-p">例如我们在预测未来气温时，历史气温数据并不是唯一的参考，还可能参考历史的风速、气压、天气情况等等，此时输入数据将会是一个<code class="x-inline-highlight">input_size</code>维的向量。</p><h4 class="x-h3">hidden_size=12，12是在哪里体现的？</h4><p class="x-p"><code class="x-inline-highlight">12</code>只是模型的超参数，和MLP中隐藏层大小一样，并没有太多的物理含义。</p><h4 class="x-h3">训练时，每次迭代用哪些数据？应该遍历几遍数据集？每个 epoch 会使用哪些数据进行参数优化？</h4><p class="x-p no-margin-bottom">在训练一个CNN网络时（例如一个图片分类网络），策略通常是：</p><div class="x-oli"><div class="x-oli-number">1.</div><div class="x-oli-content-wrapper"><p class="x-p">指定超参数<code class="x-inline-highlight">num_epoch</code>，在每个<code class="x-inline-highlight">epoch</code>中随机遍历训练集中的所有图像进行参数优化；</p></div></div><div class="x-oli"><div class="x-oli-number">2.</div><div class="x-oli-content-wrapper"><p class="x-p">重复执行<code class="x-inline-highlight">num_epoch</code>次。</p></div></div><p class="x-p with-margin-top no-margin-bottom">然而对于RNN来说这个概念似乎并不清晰，例如上述例子的训练策略是：</p><div class="x-oli"><div class="x-oli-number">1.</div><div class="x-oli-content-wrapper"><p class="x-p">从<code class="x-inline-highlight">0</code>到<code class="x-inline-highlight">(训练集大小 - 序列长度)</code>依次遍历起始时间<code class="x-inline-highlight">t</code>；</p></div></div><div class="x-oli"><div class="x-oli-number">2.</div><div class="x-oli-content-wrapper"><p class="x-p">对于每个起始时间<code class="x-inline-highlight">t</code>，将<code class="x-inline-highlight">y[t]</code>~<code class="x-inline-highlight">y[t+9]</code>为输入，<code class="x-inline-highlight">y[t+10]</code>为真值作为一组训练样本。</p></div></div><div class="x-oli"><div class="x-oli-number">3.</div><div class="x-oli-content-wrapper"><p class="x-p">第<code class="x-inline-highlight">1</code>步只遍历了一次！</p></div></div><p class="x-p with-margin-top no-margin-bottom">或者：</p><p class="x-p no-margin-bottom">...</p><div class="x-oli"><div class="x-oli-number">3.</div><div class="x-oli-content-wrapper"><p class="x-p">前两步同上，但多次遍历训练集。</p></div></div><p class="x-p with-margin-top no-margin-bottom">另一个常用的策略是：</p><div class="x-oli"><div class="x-oli-number">1.</div><div class="x-oli-content-wrapper"><p class="x-p">指定超参数：训练轮次<code class="x-inline-highlight">num_iter</code>；</p></div></div><div class="x-oli"><div class="x-oli-number">2.</div><div class="x-oli-content-wrapper"><p class="x-p">重复执行<code class="x-inline-highlight">num_iter</code>次，每次随机抽取一个起始时间<code class="x-inline-highlight">t</code>，并且将<code class="x-inline-highlight">y[t]</code>~<code class="x-inline-highlight">y[t+9]</code>为输入，<code class="x-inline-highlight">y[t+10]</code>为真值作为一组训练样本。</p></div></div><h2 class="x-h1">LSTM：一篇很好的博客</h2><p class="x-p">以下的内容和插图总结或翻译自这篇的英文博客：<a href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/" target="_blank" rel="noreferrer" class="x-inline-link">Understanding LSTM Networks</a></p><h3 class="x-h2">长期依赖问题</h3><p class="x-p">RNN可以利用先前的信息理解当前的任务，这点非常不错；有时我们只需要短期的信息，例如一个语言模型预测下面的句子：<br/><code class="x-inline-highlight">天空中飘着一朵白色的【云】</code>，这很简单。但有些时候我们需要更多背景信息，例如：<br/><code class="x-inline-highlight">我出生在法国，…… ，我可以说流利的【法语】</code>，这个情况下，随着前后文距离变大，RNN对长期依赖关系的学习会变得困难。</p><h3 class="x-h2">LSTM</h3><p class="x-p"><span class="x-inline-strong">长短期记忆网络</span><code class="x-inline-highlight">(Long Short-Term Memory, LSTM)</code>是一种特殊的RNN，可以学习长期依赖。以RNN为例，循环神经网络随时间展开通常具有如下的示意图：</p><div class="x-image-wrapper x-image-invert"><img alt="img" loading="lazy" width="2242" height="839" decoding="async" data-nimg="1" style="color:transparent;width:600px;height:auto" src="/_next/static/media/rnn2.d1dd71bb.png"/></div><p class="x-p">对于RNN来说，利用历史状态和输入得到新的状态，只经过一个简单的<code class="x-inline-highlight">tanh</code>激活层，而对于LSTM来说，它的示意图略显复杂：</p><div class="x-image-wrapper x-image-invert"><img alt="img" loading="lazy" width="2233" height="839" decoding="async" data-nimg="1" style="color:transparent;width:600px;height:auto" src="/_next/static/media/lstm1.83284ab3.png"/></div><p class="x-p">在上图中，每条线表示一个向量，粉红色圆圈表示逐点式操作，黄色的方框是神经网络的层。这看起来很眼晕，不过我们接下来会一点点的解释图里的内容。</p><h3 class="x-h2">门控单元</h3><p class="x-p">下面的结构称为门控单元：</p><div class="x-image-wrapper x-image-invert"><img alt="img" loading="lazy" width="198" height="242" decoding="async" data-nimg="1" style="color:transparent;width:100px;height:auto" src="/_next/static/media/lstm2.96d0a9a3.png"/></div><p class="x-p">门控单元控制信息量通过的多少，通过向量<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span></span></span></span>来控制<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">x</span></span></span></span>通过的信息量：</p><div class="x-formula"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">o</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⊗</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">x</span></span></span></span></div><p class="x-p">式子中<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em;"></span><span class="mord">⊗</span></span></span></span>表示按位置相乘，<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mclose">)</span></span></span></span>的每个元素输出范围是<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">1</span><span class="mclose">]</span></span></span></span>，某个元素接近<code class="x-inline-highlight">1</code>，<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">x</span></span></span></span>对应位置保留的信息就越多，反之就越少。</p><h3 class="x-h2">逐部分分析LSTM</h3><h4 class="x-h3">遗忘门</h4><p class="x-p">LSTM的第一步是决定什么应该被遗忘，也就是对上一个<span class="x-inline-strong">单元</span><code class="x-inline-highlight">(cell)</code>状态信息选择性的遗忘。<br/>这个操作由遗忘门<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>实现，将其<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">1</span><span class="mclose">]</span></span></span></span>范围的输出按位置与单元上一时刻状态相乘。</p><div class="x-image-wrapper x-image-invert"><img alt="img" loading="lazy" width="1826" height="564" decoding="async" data-nimg="1" style="color:transparent;width:600px;height:auto" src="/_next/static/media/lstm3.ac9b9ff5.png"/></div><div class="x-highlightblock highlight-background-gray"><p class="x-p">举一个概念性的例子：</p><p class="x-p">考虑一个语言模型，输入一个句子：<code class="x-inline-highlight">Alice是一名女教师，她喜欢给学生讲课；Bob是一位男司机，他喝酒上瘾。</code></p><p class="x-p">当模型看到<code class="x-inline-highlight">Alice是一名女教师，……</code>时，单元状态中可能存储了和主语<code class="x-inline-highlight">Alice</code>和<code class="x-inline-highlight">女教师</code>有关的语义信息，以便在后文输出合适的代词<code class="x-inline-highlight">她</code>；然后，当模型看到<code class="x-inline-highlight">Alice是一名女教师，她喜欢给学生讲课；Bob是一位男司机，……</code>时，我们希望在看到新主语<code class="x-inline-highlight">Bob</code>和<code class="x-inline-highlight">男司机</code>之后，忘记此前存储的旧主语的性别语义。也就是对旧单元状态<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8917em;vertical-align:-0.2083em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em;"><span></span></span></span></span></span></span></span></span></span>乘上较小的<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>。</p></div><h4 class="x-h3">输入门</h4><p class="x-p">下一步就是决定要在单元中存入什么新的信息。这一部分有两路：<code class="x-inline-highlight">tanh</code>这一路与普通RNN很像，生成一个中间状态；<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span></span></span></span>这一路被称为输入门<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8095em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，控制这个中间状态有多少信息被存入单元。</p><div class="x-image-wrapper x-image-invert"><img alt="img" loading="lazy" width="1826" height="564" decoding="async" data-nimg="1" style="color:transparent;width:600px;height:auto" src="/_next/static/media/lstm4.00cef2df.png"/></div><p class="x-p">经历这两步之后，便可以相加得到新的单元状态：</p><div class="x-image-wrapper x-image-invert"><img alt="img" loading="lazy" width="1826" height="564" decoding="async" data-nimg="1" style="color:transparent;width:600px;height:auto" src="/_next/static/media/lstm5.3f95c1ad.png"/></div><div class="x-highlightblock highlight-background-gray"><p class="x-p">同理，当模型看到<code class="x-inline-highlight">Bob是一位男司机</code>时，我们可能会想丢掉此前的语义信息<code class="x-inline-highlight">女性</code>，并把新的语义信息<code class="x-inline-highlight">男性</code>存入单元状态，使得后文输出正确的代词<code class="x-inline-highlight">他</code>。</p></div><h4 class="x-h3">输出门</h4><p class="x-p">最后是决定新的隐藏状态，这个输出会基于单元状态，但会经过门控单元。输出门<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">o</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>决定经过<code class="x-inline-highlight">tanh</code>的单元状态<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>有多少被输出到下一时刻的隐藏状态。</p><div class="x-image-wrapper x-image-invert"><img alt="img" loading="lazy" width="1826" height="564" decoding="async" data-nimg="1" style="color:transparent;width:600px;height:auto" src="/_next/static/media/lstm6.7eca3c69.png"/></div><div class="x-highlightblock highlight-background-gray"><p class="x-p">当看到<code class="x-inline-highlight">Bob是一位男司机，他……</code>时，由于出现了主语<code class="x-inline-highlight">他</code>，模型可能会输出和<code class="x-inline-highlight">谓语动词</code>有关的语义信息。</p></div></div><div id="sidebar"><div id="sidebar-width-wrapper"><div class="category-card sidebar-card show-list"><div class="category-card-header"><div class="category-name">网络杂识</div><div class="category-rightarrow"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 1024 1024"><path fill="#50505c" d="m761 532 2-3c9-18 6-40-10-55L400 140a48 48 0 0 0-66 70l317 299-316 305a48 48 0 0 0 67 69l350-338 1-2 2-1c3-3 4-7 6-10z"></path></svg></div></div><div class="category-card-ul-wrapper"><ul class="category-card-ul"><li><a class="y-link" href="/23d/database-3nf/"><span class="post-title">数据库设计三大范式</span></a></li><li><a class="y-link" href="/23d/github-linguist-vendored/"><span class="post-title">不统计Github仓库某个目录下的语言</span></a></li><li><a class="y-link" href="/24a/deepl-shortcut-setting/"><span class="post-title">解决：DeepL该快捷键已被使用</span></a></li><li><a class="y-link" href="/24a/git-merge-allow-unrelated-histories/"><span class="post-title">记录：使用--allow-unrelated-histories</span></a></li><li><a class="y-link" href="/24b/injective-surjective-bijective/"><span class="post-title">单射、满射、双射</span></a></li></ul></div></div><div class="category-card sidebar-card show-list"><div class="category-card-header"><div class="category-name">Web</div><div class="category-rightarrow"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 1024 1024"><path fill="#50505c" d="m761 532 2-3c9-18 6-40-10-55L400 140a48 48 0 0 0-66 70l317 299-316 305a48 48 0 0 0 67 69l350-338 1-2 2-1c3-3 4-7 6-10z"></path></svg></div></div><div class="category-card-ul-wrapper"><ul class="category-card-ul"><li><a class="y-link" href="/23d/hust-cas-login/"><span class="post-title">Python登录华科统一身份认证接口</span></a></li><li><a class="y-link" href="/24b/learn-cwes/"><span class="post-title">Learn CWEs &amp; Real-word Examples</span></a></li><li><a class="y-link" href="/24b/cross-site-scripting/"><span class="post-title">Learn XSS</span></a></li><li><a class="y-link" href="/24b/cross-site-request-forgery/"><span class="post-title">Learn CSRF</span></a></li></ul></div></div><div class="category-card sidebar-card show-list"><div class="category-card-header"><div class="category-name">算法</div><div class="category-rightarrow"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 1024 1024"><path fill="#50505c" d="m761 532 2-3c9-18 6-40-10-55L400 140a48 48 0 0 0-66 70l317 299-316 305a48 48 0 0 0 67 69l350-338 1-2 2-1c3-3 4-7 6-10z"></path></svg></div></div><div class="category-card-ul-wrapper"><ul class="category-card-ul"><li><a class="y-link" href="/24a/cpp-stl/"><span class="post-title">C++中STL的基本使用</span></a></li><li><a class="y-link" href="/24b/sorting-algorithm/"><span class="post-title">排序算法总结与代码实现</span></a></li><li><a class="y-link" href="/24b/mst-and-sp/"><span class="post-title">最小生成树与最短路算法</span></a></li><li><a class="y-link" href="/24a/csp-2016-04/"><span class="post-title">CSP 201604 T1-T4题解</span></a></li><li><a class="y-link" href="/24a/csp-2018-03/"><span class="post-title">CSP 201803 T1-T4题解</span></a></li><li><a class="y-link" href="/24a/csp-2020-06/"><span class="post-title">CSP 202006 T1-T4题解</span></a></li><li><a class="y-link" href="/24a/csp-2020-09/"><span class="post-title">CSP 202009 T1-T4题解</span></a></li><li><a class="y-link" href="/24a/csp-2020-12/"><span class="post-title">CSP 202012 T1-T5题解</span></a></li><li><a class="y-link" href="/24a/csp-2022-06/"><span class="post-title">CSP 202206 T1-T5题解</span></a></li><li><a class="y-link" href="/24a/csp-2023-05/"><span class="post-title">CSP 202305 T1-T4题解</span></a></li><li><a class="y-link" href="/24a/csp-2023-09/"><span class="post-title">CSP 202309 T1-T4题解</span></a></li><li><a class="y-link" href="/24b/leetcode-4/"><span class="post-title">LeetCode 4.寻找两个正序数组的中位数</span></a></li><li><a class="y-link" href="/24b/leetcode-30/"><span class="post-title">LeetCode 30.串联所有单词的子串</span></a></li><li><a class="y-link" href="/24b/leetcode-37/"><span class="post-title">LeetCode 37.解数独</span></a></li><li><a class="y-link" href="/24c/leetcode-42/"><span class="post-title">LeetCode 42.接雨水</span></a></li><li><a class="y-link" href="/24b/leetcode-60/"><span class="post-title">LeetCode 60.排列序列</span></a></li><li><a class="y-link" href="/24b/leetcode-65/"><span class="post-title">LeetCode 65.有效数字</span></a></li><li><a class="y-link" href="/24b/leetcode-84/"><span class="post-title">LeetCode 84.柱状图中最大的矩形</span></a></li><li><a class="y-link" href="/24c/leetcode-85/"><span class="post-title">LeetCode 85.最大矩形</span></a></li><li><a class="y-link" href="/24b/leetcode-312/"><span class="post-title">LeetCode 312.戳气球</span></a></li><li><a class="y-link" href="/24b/leetcode-1373/"><span class="post-title">LeetCode 1373.二叉搜索子树的最大键值和</span></a></li><li><a class="y-link" href="/24b/leetcode-1739/"><span class="post-title">LeetCode 1739.放置盒子</span></a></li></ul></div></div><div class="category-card sidebar-card show-list"><div class="category-card-header"><div class="category-name">深度学习</div><div class="category-rightarrow"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 1024 1024"><path fill="#50505c" d="m761 532 2-3c9-18 6-40-10-55L400 140a48 48 0 0 0-66 70l317 299-316 305a48 48 0 0 0 67 69l350-338 1-2 2-1c3-3 4-7 6-10z"></path></svg></div></div><div class="category-card-ul-wrapper"><ul class="category-card-ul"><li><a class="y-link" href="/longtime/papers-dl/"><span class="post-title">论文速记</span></a></li><li><a class="y-link" href="/23d/r2plus1d/"><span class="post-title">行为识别R(2+1)D网络</span></a></li><li><a class="y-link" href="/23d/object-detection-map/"><span class="post-title">目标检测评价指标mAP</span></a></li><li><a class="y-link active" href="/23d/learn-rnn-lstm/"><span class="post-title">学习RNN和LSTM</span></a></li><li><a class="y-link" href="/24a/reproduce-nerf-rpn/"><span class="post-title">记录：复现NeRF-RPN代码</span></a></li><li><a class="y-link" href="/24b/yolov5-obb-nms-rotated/"><span class="post-title">解决：nms_rotated报错&quot;THC/THC.h&quot;: No such file or directory</span></a></li></ul></div></div><div class="category-card sidebar-card show-list"><div class="category-card-header"><div class="category-name">Python</div><div class="category-rightarrow"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 1024 1024"><path fill="#50505c" d="m761 532 2-3c9-18 6-40-10-55L400 140a48 48 0 0 0-66 70l317 299-316 305a48 48 0 0 0 67 69l350-338 1-2 2-1c3-3 4-7 6-10z"></path></svg></div></div><div class="category-card-ul-wrapper"><ul class="category-card-ul"><li><a class="y-link" href="/24a/torch-numpy-topk/"><span class="post-title">在pytorch和numpy中取top-k值和索引</span></a></li><li><a class="y-link" href="/24a/object-oriented-programming-python/"><span class="post-title">Python面向对象编程</span></a></li></ul></div></div><div class="category-card sidebar-card show-list"><div class="category-card-header"><div class="category-name">前端与JavaScript</div><div class="category-rightarrow"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 1024 1024"><path fill="#50505c" d="m761 532 2-3c9-18 6-40-10-55L400 140a48 48 0 0 0-66 70l317 299-316 305a48 48 0 0 0 67 69l350-338 1-2 2-1c3-3 4-7 6-10z"></path></svg></div></div><div class="category-card-ul-wrapper"><ul class="category-card-ul"><li><a class="y-link" href="/23c/js-array/"><span class="post-title">JavaScript数组常用方法</span></a></li><li><a class="y-link" href="/23d/css-auto-height-transition/"><span class="post-title">CSS实现auto高度的过渡动画</span></a></li></ul></div></div><div class="category-card sidebar-card show-list"><div class="category-card-header"><div class="category-name">课程</div><div class="category-rightarrow"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 1024 1024"><path fill="#50505c" d="m761 532 2-3c9-18 6-40-10-55L400 140a48 48 0 0 0-66 70l317 299-316 305a48 48 0 0 0 67 69l350-338 1-2 2-1c3-3 4-7 6-10z"></path></svg></div></div><div class="category-card-ul-wrapper"><ul class="category-card-ul"><li><a class="y-link" href="/24b/rank-inequality/"><span class="post-title">【线性代数】对秩不等式的理解</span></a></li><li><a class="y-link" href="/23c/pattern-recognition-1/"><span class="post-title">【模式识别】统计决策方法</span></a></li><li><a class="y-link" href="/23c/pattern-recognition-2/"><span class="post-title">【模式识别】参数估计</span></a></li><li><a class="y-link" href="/23c/pattern-recognition-3/"><span class="post-title">【模式识别】非参数估计</span></a></li><li><a class="y-link" href="/23d/pattern-recognition-4/"><span class="post-title">【模式识别】线性学习器与线性分类器</span></a></li><li><a class="y-link" href="/23d/protocols/"><span class="post-title">【计算机网络】协议总结</span></a></li><li><a class="y-link" href="/24a/machine-learning-exercises/"><span class="post-title">【机器学习】习题</span></a></li><li><a class="y-link" href="/24a/games101-01-transformation/"><span class="post-title">【GAMES101】Transformation</span></a></li><li><a class="y-link" href="/24a/games101-02-rasterization/"><span class="post-title">【GAMES101】Rasterization</span></a></li><li><a class="y-link" href="/24a/games101-03-shading/"><span class="post-title">【GAMES101】Shading</span></a></li><li><a class="y-link" href="/24a/games101-04-geometry/"><span class="post-title">【GAMES101】Geometry</span></a></li><li><a class="y-link" href="/24b/by-questions/"><span class="post-title">专业课复习</span></a></li></ul></div></div><div class="category-card sidebar-card show-list"><div class="category-card-header"><div class="category-name">杂记</div><div class="category-rightarrow"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 1024 1024"><path fill="#50505c" d="m761 532 2-3c9-18 6-40-10-55L400 140a48 48 0 0 0-66 70l317 299-316 305a48 48 0 0 0 67 69l350-338 1-2 2-1c3-3 4-7 6-10z"></path></svg></div></div><div class="category-card-ul-wrapper"><ul class="category-card-ul"><li><a class="y-link" href="/longtime/hundred-thousand/"><span class="post-title">十万</span></a></li></ul></div></div><div class="category-card sidebar-card show-list"><div class="category-card-header"><div class="category-name">其他</div><div class="category-rightarrow"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 1024 1024"><path fill="#50505c" d="m761 532 2-3c9-18 6-40-10-55L400 140a48 48 0 0 0-66 70l317 299-316 305a48 48 0 0 0 67 69l350-338 1-2 2-1c3-3 4-7 6-10z"></path></svg></div></div><div class="category-card-ul-wrapper"><ul class="category-card-ul"><li><a class="y-link" href="/longtime/demo/"><span class="post-title">示例</span></a></li><li><a class="y-link" href="/longtime/updates/"><span class="post-title">更新日志</span></a></li></ul></div></div></div></div><div id="sidebar-mask"></div></div><script src="/_next/static/chunks/webpack-d5f00c42e11d76a5.js" crossorigin="" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0]);self.__next_f.push([2,null])</script><script>self.__next_f.push([1,"1:HL[\"/_next/static/css/1279e9e476ea3436.css\",\"style\",{\"crossOrigin\":\"\"}]\n0:\"$L2\"\n"])</script><script>self.__next_f.push([1,"3:HL[\"/_next/static/css/615f855f1eaa8d62.css\",\"style\",{\"crossOrigin\":\"\"}]\n4:HL[\"/_next/static/css/35b01ded3cfbfcc5.css\",\"style\",{\"crossOrigin\":\"\"}]\n"])</script><script>self.__next_f.push([1,"5:I[7690,[],\"\"]\n7:I[579,[\"2202\",\"static/chunks/2202-a70b76e16443b83b.js\",\"9919\",\"static/chunks/9919-fdd433cceba36e69.js\",\"4960\",\"static/chunks/app/(posts)/23d/learn-rnn-lstm/page-4015a016e05e7e75.js\"],\"\"]\n8:I[4365,[\"2202\",\"static/chunks/2202-a70b76e16443b83b.js\",\"9919\",\"static/chunks/9919-fdd433cceba36e69.js\",\"4960\",\"static/chunks/app/(posts)/23d/learn-rnn-lstm/page-4015a016e05e7e75.js\"],\"\"]\n1a:I[5613,[],\"\"]\n1b:I[1778,[],\"\"]\n1c:I[389,[\"5250\",\"static/chunks/5250-aaac40ffcdef4b77.js\",\"1993\",\"static/chunks/app/(posts)/layout-a1fc8e57c0d159ff.js\"],\"\"]\n1d:I[5694,[\"5250\",\"static/chunks/5250-aaac40ffcdef4b77.js\",\"3185\",\"static/chunks/app/layout-16a924fc60f8c1d3.js\"],\"GlobalProvider\"]\n1e:I[397,[\"5250\",\"static/chunks/5250-aaac40ffcdef4b77.js\",\"3185\",\"static/chunks/app/layout-16a924fc60f8c1d3.js\"],\"\"]\n20:I[8955,[],\"\"]\n9:T88c,"])</script><script>self.__next_f.push([1,"\u003cspan class=\"token keyword\"\u003eimport\u003c/span\u003e numpy\n\u003cspan class=\"token keyword\"\u003eimport\u003c/span\u003e torch\n\u003cspan class=\"token keyword\"\u003efrom\u003c/span\u003e torch \u003cspan class=\"token keyword\"\u003eimport\u003c/span\u003e nn\n\u003cspan class=\"token keyword\"\u003eimport\u003c/span\u003e matplotlib\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003epyplot \u003cspan class=\"token keyword\"\u003eas\u003c/span\u003e plt\n\n\u003cspan class=\"token comment\"\u003e#生成加噪声的正弦序列数据\u003c/span\u003e\nxlim\u003cspan class=\"token operator\"\u003e=\u003c/span\u003enumpy\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003elinspace\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token number\"\u003e0\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e\u003cspan class=\"token number\"\u003e36\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e\u003cspan class=\"token number\"\u003e400\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\ny\u003cspan class=\"token operator\"\u003e=\u003c/span\u003enumpy\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003esin\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003exlim\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token operator\"\u003e+\u003c/span\u003enumpy\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003erandom\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003erand\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token operator\"\u003e*\u003c/span\u003exlim\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eshape\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token operator\"\u003e*\u003c/span\u003e\u003cspan class=\"token number\"\u003e0.2\u003c/span\u003e\n\n\u003cspan class=\"token comment\"\u003e#转换dtype和size，保持和后面的训练数据统一\u003c/span\u003e\ny\u003cspan class=\"token operator\"\u003e=\u003c/span\u003ey\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003ereshape\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token operator\"\u003e-\u003c/span\u003e\u003cspan class=\"token number\"\u003e1\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e\u003cspan class=\"token number\"\u003e1\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eastype\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"float32\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\nplt\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eplot\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003exlim\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003ey\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\nplt\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eshow\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n"])</script><script>self.__next_f.push([1,"a:T113e,"])</script><script>self.__next_f.push([1,"\u003cspan class=\"token keyword\"\u003eclass\u003c/span\u003e \u003cspan class=\"token class-name\"\u003eMyRNN\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003enn\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eModule\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n    \u003cspan class=\"token keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"token function\"\u003e__init__\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eself\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003einput_size\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003ehidden_size\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003eoutput_size\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"token builtin\"\u003esuper\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003e__init__\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n        self\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003elinear_ih\u003cspan class=\"token operator\"\u003e=\u003c/span\u003enn\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eLinear\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003einput_size\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003ehidden_size\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n        self\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003elinear_hh\u003cspan class=\"token operator\"\u003e=\u003c/span\u003enn\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eLinear\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003ehidden_size\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003ehidden_size\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n        self\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003elinear_ho\u003cspan class=\"token operator\"\u003e=\u003c/span\u003enn\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eLinear\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003ehidden_size\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003eoutput_size\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n        self\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003etanh\u003cspan class=\"token operator\"\u003e=\u003c/span\u003enn\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eTanh\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"token keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"token function\"\u003eforward\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eself\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003ex\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003eprev_state\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n        curr_state\u003cspan class=\"token operator\"\u003e=\u003c/span\u003eself\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003etanh\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\n            self\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003elinear_ih\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003ex\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token operator\"\u003e+\u003c/span\u003eself\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003elinear_hh\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eprev_state\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n        \u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n        output\u003cspan class=\"token operator\"\u003e=\u003c/span\u003eself\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003elinear_ho\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003ecurr_state\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003ereshape\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token number\"\u003e1\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n        \u003cspan class=\"token keyword\"\u003ereturn\u003c/span\u003e output\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003ecurr_state\n\nhidden_size\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token number\"\u003e12\u003c/span\u003e\nmy_rnn\u003cspan class=\"token operator\"\u003e=\u003c/span\u003eMyRNN\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003einput_size\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token number\"\u003e1\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003ehidden_size\u003cspan class=\"token operator\"\u003e=\u003c/span\u003ehidden_size\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003eoutput_size\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token number\"\u003e1\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\nloss_func\u003cspan class=\"token operator\"\u003e=\u003c/span\u003enn\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eMSELoss\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\noptimizer\u003cspan class=\"token operator\"\u003e=\u003c/span\u003etorch\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eoptim\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eSGD\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003emy_rnn\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eparameters\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003elr\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token number\"\u003e0.01\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n"])</script><script>self.__next_f.push([1,"b:T80b,"])</script><script>self.__next_f.push([1,"\u003cspan class=\"token keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"token function\"\u003etrain\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003etrain_seq\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003etarget\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n    \u003cspan class=\"token comment\"\u003e#初始状态\u003c/span\u003e\n    state\u003cspan class=\"token operator\"\u003e=\u003c/span\u003etorch\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003ezeros\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token number\"\u003e1\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003ehidden_size\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\n    \u003cspan class=\"token keyword\"\u003efor\u003c/span\u003e x \u003cspan class=\"token keyword\"\u003ein\u003c/span\u003e train_seq\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n        output\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003estate\u003cspan class=\"token operator\"\u003e=\u003c/span\u003emy_rnn\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003ex\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003estate\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\n    loss\u003cspan class=\"token operator\"\u003e=\u003c/span\u003eloss_func\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eoutput\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003etarget\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n    optimizer\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003ezero_grad\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n    loss\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003ebackward\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n    optimizer\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003estep\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\n    \u003cspan class=\"token comment\"\u003e#返回损失\u003c/span\u003e\n    \u003cspan class=\"token keyword\"\u003ereturn\u003c/span\u003e loss\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003edetach\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003enumpy\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003ereshape\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token number\"\u003e1\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n"])</script><script>self.__next_f.push([1,"c:T5c4,train_datas\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e[\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e]\u003c/span\u003e\n\u003cspan class=\"token keyword\"\u003efor\u003c/span\u003e i \u003cspan class=\"token keyword\"\u003ein\u003c/span\u003e \u003cspan class=\"token builtin\"\u003erange\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token number\"\u003e320\u003c/span\u003e\u003cspan class=\"token operator\"\u003e-\u003c/span\u003e\u003cspan class=\"token number\"\u003e10\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n    train_seq\u003cspan class=\"token operator\"\u003e=\u003c/span\u003etorch\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003efrom_numpy\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003ey\u003cspan class=\"token punctuation\"\u003e[\u003c/span\u003ei\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003ei\u003cspan class=\"token operator\"\u003e+\u003c/span\u003e\u003cspan class=\"token number\"\u003e10\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e]\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n    target\u003cspan class=\"token operator\"\u003e=\u003c/span\u003etorch\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003efrom_numpy\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003ey\u003cspan class=\"token punctuation\"\u003e[\u003c/span\u003ei\u003cspan class=\"token operator\"\u003e+\u003c/span\u003e\u003cspan class=\"token number\"\u003e10\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e]\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n    train_datas\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eappend\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003etrain_seq\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003etarget\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\nd:T52e,metrics\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e[\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e]\u003c/span\u003e\nmy_rnn\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003etrain\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\u003cspan class=\"token keyword\"\u003efor\u003c/span\u003e train_seq\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003etarget \u003cspan class=\"token keyword\"\u003ein\u003c/span\u003e train_datas\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n    loss\u003cspan class=\"token operator\"\u003e=\u003c/span\u003etrain\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003etrain_seq\u003cspan class=\"toke"])</script><script>self.__next_f.push([1,"n punctuation\"\u003e,\u003c/span\u003etarget\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n    metrics\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eappend\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eloss\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\nplt\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003esubplot\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token number\"\u003e211\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\nplt\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eplot\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003emetrics\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003elabel\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"loss\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\nplt\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003elegend\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\ne:T1086,"])</script><script>self.__next_f.push([1,"\u003cspan class=\"token keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"token function\"\u003epred\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003etruth_seq\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n    \u003cspan class=\"token keyword\"\u003ewith\u003c/span\u003e torch\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eno_grad\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n        state\u003cspan class=\"token operator\"\u003e=\u003c/span\u003etorch\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003ezeros\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token number\"\u003e1\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003ehidden_size\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n        \u003cspan class=\"token keyword\"\u003efor\u003c/span\u003e x \u003cspan class=\"token keyword\"\u003ein\u003c/span\u003e truth_seq\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n            output\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003estate\u003cspan class=\"token operator\"\u003e=\u003c/span\u003emy_rnn\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003ex\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003estate\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n        \u003cspan class=\"token keyword\"\u003ereturn\u003c/span\u003e output\n\npreds\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e[\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e]\u003c/span\u003e\n\u003cspan class=\"token keyword\"\u003efor\u003c/span\u003e i \u003cspan class=\"token keyword\"\u003ein\u003c/span\u003e \u003cspan class=\"token builtin\"\u003erange\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token number\"\u003e320\u003c/span\u003e\u003cspan class=\"token operator\"\u003e-\u003c/span\u003e\u003cspan class=\"token number\"\u003e10\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e\u003cspan class=\"token number\"\u003e400\u003c/span\u003e\u003cspan class=\"token operator\"\u003e-\u003c/span\u003e\u003cspan class=\"token number\"\u003e10\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n    truth_seq\u003cspan class=\"token operator\"\u003e=\u003c/span\u003etorch\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003efrom_numpy\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003ey\u003cspan class=\"token punctuation\"\u003e[\u003c/span\u003ei\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003ei\u003cspan class=\"token operator\"\u003e+\u003c/span\u003e\u003cspan class=\"token number\"\u003e10\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e]\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n    preds\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eappend\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003epred\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003etruth_seq\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003enumpy\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\npreds\u003cspan class=\"token operator\"\u003e=\u003c/span\u003enumpy\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003earray\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003epreds\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003ereshape\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token operator\"\u003e-\u003c/span\u003e\u003cspan class=\"token number\"\u003e1\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e\u003cspan class=\"token number\"\u003e1\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\nplt\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003esubplot\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token number\"\u003e212\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\nplt\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eplot\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003exlim\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003ey\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003elabel\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"truth\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\nplt\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eplot\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003exlim\u003cspan class=\"token punctuation\"\u003e[\u003c/span\u003e\u003cspan class=\"token number\"\u003e320\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\u003cspan class=\"token number\"\u003e400\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e]\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003epreds\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"red\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003elabel\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"predict\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\nplt\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003elegend\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\nplt\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eshow\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n"])</script><script>self.__next_f.push([1,"f:Tcae,"])</script><script>self.__next_f.push([1,"\u003cspan class=\"token keyword\"\u003eclass\u003c/span\u003e \u003cspan class=\"token class-name\"\u003eMyRNN\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003enn\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eModule\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n    \u003cspan class=\"token keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"token function\"\u003e__init__\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eself\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003einput_size\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003ehidden_size\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003eoutput_size\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"token builtin\"\u003esuper\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003e__init__\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n        self\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003elinear_ih\u003cspan class=\"token operator\"\u003e=\u003c/span\u003enn\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eLinear\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003einput_size\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003ehidden_size\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n        self\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003elinear_hh\u003cspan class=\"token operator\"\u003e=\u003c/span\u003enn\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eLinear\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003ehidden_size\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003ehidden_size\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n        self\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003elinear_ho\u003cspan class=\"token operator\"\u003e=\u003c/span\u003enn\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eLinear\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003ehidden_size\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003eoutput_size\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n        self\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003etanh\u003cspan class=\"token operator\"\u003e=\u003c/span\u003enn\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eTanh\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"token keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"token function\"\u003eforward\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eself\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003ex\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003eprev_state\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n        curr_state\u003cspan class=\"token operator\"\u003e=\u003c/span\u003eself\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003etanh\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\n            self\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003elinear_ih\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003ex\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token operator\"\u003e+\u003c/span\u003eself\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003elinear_hh\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eprev_state\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n        \u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n        output\u003cspan class=\"token operator\"\u003e=\u003c/span\u003eself\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003elinear_ho\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003ecurr_state\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003ereshape\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token number\"\u003e1\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n        \u003cspan class=\"token keyword\"\u003ereturn\u003c/span\u003e output\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003ecurr_state\n"])</script><script>self.__next_f.push([1,"10:Tb25,"])</script><script>self.__next_f.push([1,"\u003cspan class=\"token keyword\"\u003eclass\u003c/span\u003e \u003cspan class=\"token class-name\"\u003eMyRNN\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003enn\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eModule\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n    \u003cspan class=\"token keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"token function\"\u003e__init__\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eself\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003einput_size\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003ehidden_size\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003eoutput_size\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"token builtin\"\u003esuper\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003e__init__\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n        self\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003ernn\u003cspan class=\"token operator\"\u003e=\u003c/span\u003enn\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eRNN\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003einput_size\u003cspan class=\"token operator\"\u003e=\u003c/span\u003einput_size\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003ehidden_size\u003cspan class=\"token operator\"\u003e=\u003c/span\u003ehidden_size\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003ebatch_first\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token boolean\"\u003eTrue\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n        self\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003elinear_ho\u003cspan class=\"token operator\"\u003e=\u003c/span\u003enn\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eLinear\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003ehidden_size\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003eoutput_size\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"token keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"token function\"\u003eforward\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eself\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003eseq\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003einit_state\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n        output_hidden\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003etate\u003cspan class=\"token operator\"\u003e=\u003c/span\u003eself\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003ernn\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eseq\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003einit_state\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n        output\u003cspan class=\"token operator\"\u003e=\u003c/span\u003eself\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003elinear_ho\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eoutput_hidden\u003cspan class=\"token punctuation\"\u003e[\u003c/span\u003e\u003cspan class=\"token operator\"\u003e-\u003c/span\u003e\u003cspan class=\"token number\"\u003e1\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e]\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e \u003cspan class=\"token comment\"\u003e#取最后一个时间点的输出\u003c/span\u003e\n        \u003cspan class=\"token keyword\"\u003ereturn\u003c/span\u003e output\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003estate\n"])</script><script>self.__next_f.push([1,"11:T45c,\u003cspan class=\"token keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"token function\"\u003etrain\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003etrain_seq\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003etarget\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n    state\u003cspan class=\"token operator\"\u003e=\u003c/span\u003etorch\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003ezeros\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token number\"\u003e1\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003ehidden_size\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"token keyword\"\u003efor\u003c/span\u003e x \u003cspan class=\"token keyword\"\u003ein\u003c/span\u003e train_seq\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n        output\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003estate\u003cspan class=\"token operator\"\u003e=\u003c/span\u003emy_rnn\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003ex\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003estate\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n    loss\u003cspan class=\"token operator\"\u003e=\u003c/span\u003eloss_func\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eoutput\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003etarget\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"token comment\"\u003e# ......\u003c/span\u003e\n12:T488,\u003cspan class=\"token keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"token function\"\u003epred\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003etruth_seq\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003enet\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n    \u003cspan class=\"token keyword\"\u003ewith\u003c/span\u003e torch\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eno_grad\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n        state\u003cspan class=\"token operator\"\u003e=\u003c/span\u003etorch\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003ezeros\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token number\"\u003e1\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003ehidden_size\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n        \u003cspan class=\"token keyword\"\u003efor\u003c/span\u003e x \u003cspan class=\"token keyword\"\u003ein\u003c/span\u003e truth_seq\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n            output\u003cspan class=\"token punctu"])</script><script>self.__next_f.push([1,"ation\"\u003e,\u003c/span\u003estate\u003cspan class=\"token operator\"\u003e=\u003c/span\u003enet\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003ex\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003estate\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n        \u003cspan class=\"token keyword\"\u003ereturn\u003c/span\u003e output\n13:T40e,\u003cspan class=\"token keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"token function\"\u003etrain\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003etrain_seq\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003etarget\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n    state\u003cspan class=\"token operator\"\u003e=\u003c/span\u003etorch\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003ezeros\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token number\"\u003e1\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003ehidden_size\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n    output\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e_\u003cspan class=\"token operator\"\u003e=\u003c/span\u003emy_rnn\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003etrain_seq\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003estate\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e \u003cspan class=\"token comment\"\u003e#一次得到输出\u003c/span\u003e\n    loss\u003cspan class=\"token operator\"\u003e=\u003c/span\u003eloss_func\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eoutput\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003etarget\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"token comment\"\u003e# ......\u003c/span\u003e\n14:T40e,\u003cspan class=\"token keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"token function\"\u003epred\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003etruth_seq\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n    \u003cspan class=\"token keyword\"\u003ewith\u003c/span\u003e torch\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eno_grad\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n        state\u003cspan class=\"token operator\"\u003e=\u003c/span\u003etorch\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003ezeros\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token number\"\u003e1\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003ehidden_size\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n        output\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e_\u003cs"])</script><script>self.__next_f.push([1,"pan class=\"token operator\"\u003e=\u003c/span\u003emy_rnn\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003etruth_seq\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003estate\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e \u003cspan class=\"token comment\"\u003e#一次得到输出\u003c/span\u003e\n        \u003cspan class=\"token keyword\"\u003ereturn\u003c/span\u003e output\n15:T536,式子中\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6667em;vertical-align:-0.0833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e⊗\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e表示按位置相乘，\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.03588em;\"\u003eσ\u003c/span\u003e\u003cspan class=\"mopen\"\u003e(\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.04398em;\"\u003ez\u003c/span\u003e\u003cspan class=\"mclose\"\u003e)\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e的每个元素输出范围是\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"\u003e\u003c/span\u003e\u003cspan class=\"mopen\"\u003e[\u003c/span\u003e\u003cspan class=\"mord\"\u003e0\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e1\u003c/span\u003e\u003cspan class=\"mclose\"\u003e]\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e，某个元素接近\u003ccode class=\"x-inline-highlight\"\u003e1\u003c/code\u003e，\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.4306em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003ex\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e对应位置保留的信息就越多，反之就越少。16:T5a2,LSTM的第一步是决定什么应该被遗忘，也就是对上一个\u003cspan class=\"x-inline-strong\"\u003e单元\u003c/span\u003e\u003ccode class=\"x-inline-highlight\"\u003e(cell)\u003c/code\u003e状态信息选择性的遗忘。\u003cbr/\u003e这个操作由遗忘门\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan clas"])</script><script>self.__next_f.push([1,"s=\"mord mathnormal\" style=\"margin-right:0.10764em;\"\u003ef\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.2806em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003et\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e实现，将其\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"\u003e\u003c/span\u003e\u003cspan class=\"mopen\"\u003e[\u003c/span\u003e\u003cspan class=\"mord\"\u003e0\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e1\u003c/span\u003e\u003cspan class=\"mclose\"\u003e]\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e范围的输出按位置与单元上一时刻状态相乘。17:T93e,"])</script><script>self.__next_f.push([1,"当模型看到\u003ccode class=\"x-inline-highlight\"\u003eAlice是一名女教师，……\u003c/code\u003e时，单元状态中可能存储了和主语\u003ccode class=\"x-inline-highlight\"\u003eAlice\u003c/code\u003e和\u003ccode class=\"x-inline-highlight\"\u003e女教师\u003c/code\u003e有关的语义信息，以便在后文输出合适的代词\u003ccode class=\"x-inline-highlight\"\u003e她\u003c/code\u003e；然后，当模型看到\u003ccode class=\"x-inline-highlight\"\u003eAlice是一名女教师，她喜欢给学生讲课；Bob是一位男司机，……\u003c/code\u003e时，我们希望在看到新主语\u003ccode class=\"x-inline-highlight\"\u003eBob\u003c/code\u003e和\u003ccode class=\"x-inline-highlight\"\u003e男司机\u003c/code\u003e之后，忘记此前存储的旧主语的性别语义。也就是对旧单元状态\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.8917em;vertical-align:-0.2083em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.07153em;\"\u003eC\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3011em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003et\u003c/span\u003e\u003cspan class=\"mbin mtight\"\u003e−\u003c/span\u003e\u003cspan class=\"mord mtight\"\u003e1\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.2083em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e乘上较小的\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.10764em;\"\u003ef\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.2806em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003et\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e。"])</script><script>self.__next_f.push([1,"18:T4d3,下一步就是决定要在单元中存入什么新的信息。这一部分有两路：\u003ccode class=\"x-inline-highlight\"\u003etanh\u003c/code\u003e这一路与普通RNN很像，生成一个中间状态；\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.4306em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.03588em;\"\u003eσ\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e这一路被称为输入门\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.8095em;vertical-align:-0.15em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003ei\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.2806em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003et\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e，控制这个中间状态有多少信息被存入单元。19:T6c6,最后是决定新的隐藏状态，这个输出会基于单元状态，但会经过门控单元。输出门\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.5806em;vertical-align:-0.15em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003eo\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.2806em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003et\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/spa"])</script><script>self.__next_f.push([1,"n\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e决定经过\u003ccode class=\"x-inline-highlight\"\u003etanh\u003c/code\u003e的单元状态\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.8333em;vertical-align:-0.15em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.07153em;\"\u003eC\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.2806em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003et\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e有多少被输出到下一时刻的隐藏状态。21:[]\n"])</script><script>self.__next_f.push([1,"2:[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/1279e9e476ea3436.css\",\"precedence\":\"next\",\"crossOrigin\":\"\"}]],[\"$\",\"$L5\",null,{\"buildId\":\"XnwW2G2lyOsZw9GINAOjT\",\"assetPrefix\":\"\",\"initialCanonicalUrl\":\"/23d/learn-rnn-lstm/\",\"initialTree\":[\"\",{\"children\":[\"(posts)\",{\"children\":[\"23d\",{\"children\":[\"learn-rnn-lstm\",{\"children\":[\"__PAGE__\",{}]}]}]}]},\"$undefined\",\"$undefined\",true],\"initialSeedData\":[\"\",{\"children\":[\"(posts)\",{\"children\":[\"23d\",{\"children\":[\"learn-rnn-lstm\",{\"children\":[\"__PAGE__\",{},[\"$L6\",[[\"$\",\"$L7\",null,{}],[\"$\",\"h1\",null,{\"className\":\"x-title\",\"children\":\"学习RNN和LSTM\"}],[\"$\",\"h2\",null,{\"className\":\"x-h1\",\"children\":\"RNN：一个简单的例子\"}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"传统神经网络每次的输入是独立的，每次输出只依赖于当前的输入；但在某些任务中需要更好的处理序列信息，即前面的输入和后面的输入是有关系的；\u003cspan class=\\\"x-inline-strong\\\"\u003e循环神经网络\u003c/span\u003e\u003ccode class=\\\"x-inline-highlight\\\"\u003e(Recurrent Neural Networks, RNN)\u003c/code\u003e通过使用带自反馈的神经元，能够处理任意长度的序列。\"}}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"下面是一个非常常见的RNN结构描述图。它展示了RNN的自反馈机制和与时间的依赖关系，但是对网络结构的描述容易引起误解：右侧的展开形式并不意味着网络有\u003ccode class=\\\"x-inline-highlight\\\"\u003et\u003c/code\u003e层，而是反映了随着时间增加（有时也可以理解为随着程序中循环的迭代），上一次输出的隐藏状态，和\u003cspan class=\\\"katex\\\"\u003e\u003cspan class=\\\"katex-html\\\" aria-hidden=\\\"true\\\"\u003e\u003cspan class=\\\"base\\\"\u003e\u003cspan class=\\\"strut\\\" style=\\\"height:0.5806em;vertical-align:-0.15em;\\\"\u003e\u003c/span\u003e\u003cspan class=\\\"mord\\\"\u003e\u003cspan class=\\\"mord mathnormal\\\"\u003ex\u003c/span\u003e\u003cspan class=\\\"msupsub\\\"\u003e\u003cspan class=\\\"vlist-t vlist-t2\\\"\u003e\u003cspan class=\\\"vlist-r\\\"\u003e\u003cspan class=\\\"vlist\\\" style=\\\"height:0.2806em;\\\"\u003e\u003cspan style=\\\"top:-2.55em;margin-left:0em;margin-right:0.05em;\\\"\u003e\u003cspan class=\\\"pstrut\\\" style=\\\"height:2.7em;\\\"\u003e\u003c/span\u003e\u003cspan class=\\\"sizing reset-size6 size3 mtight\\\"\u003e\u003cspan class=\\\"mord mathnormal mtight\\\"\u003et\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\\\"vlist-s\\\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\\\"vlist-r\\\"\u003e\u003cspan class=\\\"vlist\\\" style=\\\"height:0.15em;\\\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e共同作为网络的下一次的输入。\"}}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"或者，如果说CNN是从空间维度上堆叠卷积层，不断加深，RNN就是从时间维度上的延展，而其网络真正的参数是很少的。\"}}],[\"$\",\"$L8\",null,{\"src\":\"rnn1.png\",\"width\":\"600px\",\"invertInDarkTheme\":true}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"下面以一个简单的正弦序列预测任务出发，结合代码理解RNN网络的部分细节。\"}}],[\"$\",\"h3\",null,{\"className\":\"x-h2\",\"children\":\"预测一个正弦序列\"}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"这个例子中，我们对一个加了噪声的正弦序列进行预测。\"}}],[\"$\",\"div\",null,{\"className\":\"x-codeblock\",\"children\":[\"$\",\"pre\",null,{\"style\":{\"background\":null},\"children\":[\"$\",\"code\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"$9\"}}]}]}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"代码中我们在区间\u003cspan class=\\\"katex\\\"\u003e\u003cspan class=\\\"katex-html\\\" aria-hidden=\\\"true\\\"\u003e\u003cspan class=\\\"base\\\"\u003e\u003cspan class=\\\"strut\\\" style=\\\"height:1em;vertical-align:-0.25em;\\\"\u003e\u003c/span\u003e\u003cspan class=\\\"mopen\\\"\u003e[\u003c/span\u003e\u003cspan class=\\\"mord\\\"\u003e0\u003c/span\u003e\u003cspan class=\\\"mpunct\\\"\u003e,\u003c/span\u003e\u003cspan class=\\\"mspace\\\" style=\\\"margin-right:0.1667em;\\\"\u003e\u003c/span\u003e\u003cspan class=\\\"mord\\\"\u003e36\u003c/span\u003e\u003cspan class=\\\"mclose\\\"\u003e]\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e取了\u003ccode class=\\\"x-inline-highlight\\\"\u003e400\u003c/code\u003e点数据，如果把横轴看成时间轴，可以认为数据集中有\u003ccode class=\\\"x-inline-highlight\\\"\u003e400\u003c/code\u003e个连续时间点的数据。\"}}],[\"$\",\"$L8\",null,{\"src\":\"fig1.png\",\"width\":\"600px\",\"invertInDarkTheme\":true}],[\"$\",\"p\",null,{\"className\":\"x-p no-margin-bottom\",\"dangerouslySetInnerHTML\":{\"__html\":\"现在明确一下我们的方案：\"}}],[\"$\",\"div\",null,{\"className\":\"x-oli\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-oli-number\",\"children\":\"1.\"}],[\"$\",\"div\",null,{\"className\":\"x-oli-content-wrapper\",\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"使用前\u003ccode class=\\\"x-inline-highlight\\\"\u003e80%\u003c/code\u003e也就是前\u003ccode class=\\\"x-inline-highlight\\\"\u003e320\u003c/code\u003e个数据作为训练集，剩余的作为测试集，观察预测结果。\"}}]}]]}],[\"$\",\"div\",null,{\"className\":\"x-oli\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-oli-number\",\"children\":\"2.\"}],[\"$\",\"div\",null,{\"className\":\"x-oli-content-wrapper\",\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"序列长度为\u003ccode class=\\\"x-inline-highlight\\\"\u003e10\u003c/code\u003e，也就是模型根据前\u003ccode class=\\\"x-inline-highlight\\\"\u003e10\u003c/code\u003e个时间点的数据去预测下一个时间点的数据。\"}}]}]]}],[\"$\",\"div\",null,{\"className\":\"x-oli\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-oli-number\",\"children\":\"3.\"}],[\"$\",\"div\",null,{\"className\":\"x-oli-content-wrapper\",\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"这个例子中输入特征的维度是\u003ccode class=\\\"x-inline-highlight\\\"\u003e1\u003c/code\u003e，也就是只有\u003ccode class=\\\"x-inline-highlight\\\"\u003ey\u003c/code\u003e值一个指标。此外，也不考虑批量大小。\"}}]}]]}],[\"$\",\"h3\",null,{\"className\":\"x-h2\",\"children\":\"定义RNN网络\"}],[\"$\",\"div\",null,{\"className\":\"x-codeblock\",\"children\":[\"$\",\"pre\",null,{\"style\":{\"background\":null},\"children\":[\"$\",\"code\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"$a\"}}]}]}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"这个是一个简单的RNN结构，从网络参数和结构来看很像一个\u003ccode class=\\\"x-inline-highlight\\\"\u003e输入层-隐藏层-输出层\u003c/code\u003e的感知机，但是多了一步\u003ccode class=\\\"x-inline-highlight\\\"\u003e隐藏层-隐藏层\u003c/code\u003e的连接，RNN的反馈结构就是由此体现的。\"}}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"并且，注意到\u003ccode class=\\\"x-inline-highlight\\\"\u003eforward\u003c/code\u003e函数的输入也需要两个参数：当前时刻输入\u003ccode class=\\\"x-inline-highlight\\\"\u003ex\u003c/code\u003e和前一时刻状态\u003ccode class=\\\"x-inline-highlight\\\"\u003eprev_state\u003c/code\u003e，同时也会把计算后的新状态\u003ccode class=\\\"x-inline-highlight\\\"\u003ecurr_state\u003c/code\u003e和\u003ccode class=\\\"x-inline-highlight\\\"\u003eoutput\u003c/code\u003e一起返回，供下一次计算使用。在这里，经过\u003ccode class=\\\"x-inline-highlight\\\"\u003elinear_ho\u003c/code\u003e后，\u003ccode class=\\\"x-inline-highlight\\\"\u003eoutput\u003c/code\u003e的\u003ccode class=\\\"x-inline-highlight\\\"\u003esize\u003c/code\u003e为\u003ccode class=\\\"x-inline-highlight\\\"\u003e(1,1)\u003c/code\u003e，考虑到它仅仅是一个标量，我们把它\u003ccode class=\\\"x-inline-highlight\\\"\u003eresize\u003c/code\u003e为\u003ccode class=\\\"x-inline-highlight\\\"\u003e(1)\u003c/code\u003e。\"}}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"接下来设置了一些超参数，隐藏层有\u003ccode class=\\\"x-inline-highlight\\\"\u003e12\u003c/code\u003e个神经元，损失函数使用\u003ccode class=\\\"x-inline-highlight\\\"\u003eMSELoss()\u003c/code\u003e。\"}}],[\"$\",\"h3\",null,{\"className\":\"x-h2\",\"children\":\"训练\"}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"首先定义这样的训练函数：它传入一个序列\u003ccode class=\\\"x-inline-highlight\\\"\u003etrain_seq\u003c/code\u003e和目标\u003ccode class=\\\"x-inline-highlight\\\"\u003etarget\u003c/code\u003e。\u003ccode class=\\\"x-inline-highlight\\\"\u003etrain_seq\u003c/code\u003e的\u003ccode class=\\\"x-inline-highlight\\\"\u003esize\u003c/code\u003e应该为\u003ccode class=\\\"x-inline-highlight\\\"\u003e(10,1)\u003c/code\u003e，因为我们用前\u003ccode class=\\\"x-inline-highlight\\\"\u003e10\u003c/code\u003e个时间点的数据去预测下一个，而输入特征维度是\u003ccode class=\\\"x-inline-highlight\\\"\u003e1\u003c/code\u003e；\u003ccode class=\\\"x-inline-highlight\\\"\u003etarget\u003c/code\u003e的\u003ccode class=\\\"x-inline-highlight\\\"\u003esize\u003c/code\u003e应该为\u003ccode class=\\\"x-inline-highlight\\\"\u003e(1)\u003c/code\u003e，因为输出只是一个标量。注意我们循环依次输入\u003ccode class=\\\"x-inline-highlight\\\"\u003etrain_seq\u003c/code\u003e中的\u003ccode class=\\\"x-inline-highlight\\\"\u003e10\u003c/code\u003e个数据，迭代更新\u003ccode class=\\\"x-inline-highlight\\\"\u003estate\u003c/code\u003e，用最后一次的\u003ccode class=\\\"x-inline-highlight\\\"\u003eoutput\u003c/code\u003e作为最终的输出计算损失。\"}}],[\"$\",\"div\",null,{\"className\":\"x-codeblock\",\"children\":[\"$\",\"pre\",null,{\"style\":{\"background\":null},\"children\":[\"$\",\"code\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"$b\"}}]}]}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"下面代码把真实数据划分成：\"}}],[\"$\",\"div\",null,{\"className\":\"x-table-wrapper\",\"children\":[\"$\",\"table\",null,{\"className\":\"x-table\",\"children\":[\"$\",\"tbody\",null,{\"children\":[[\"$\",\"tr\",null,{\"children\":[[\"$\",\"th\",null,{\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003etrain_seq\u003c/code\u003e\"}}]}],[\"$\",\"th\",null,{\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003etarget\u003c/code\u003e\"}}]}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[0]\u003c/code\u003e,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[1]\u003c/code\u003e,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[2]\u003c/code\u003e, ... ,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[9]\u003c/code\u003e\"}}]}],[\"$\",\"td\",null,{\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[10]\u003c/code\u003e\"}}]}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[1]\u003c/code\u003e,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[2]\u003c/code\u003e,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[3]\u003c/code\u003e, ... ,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[10]\u003c/code\u003e\"}}]}],[\"$\",\"td\",null,{\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[11]\u003c/code\u003e\"}}]}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[2]\u003c/code\u003e,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[3]\u003c/code\u003e,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[4]\u003c/code\u003e, ... ,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[11]\u003c/code\u003e\"}}]}],[\"$\",\"td\",null,{\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[12]\u003c/code\u003e\"}}]}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":\"...\"}],[\"$\",\"td\",null,{\"children\":\"...\"}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[309]\u003c/code\u003e,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[310]\u003c/code\u003e,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[311]\u003c/code\u003e, ... ,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[318]\u003c/code\u003e\"}}]}],[\"$\",\"td\",null,{\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[319]\u003c/code\u003e\"}}]}]]}]]}]}]}],[\"$\",\"div\",null,{\"className\":\"x-codeblock\",\"children\":[\"$\",\"pre\",null,{\"style\":{\"background\":null},\"children\":[\"$\",\"code\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"$c\"}}]}]}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"训练网络，绘制误差：\"}}],[\"$\",\"div\",null,{\"className\":\"x-codeblock\",\"children\":[\"$\",\"pre\",null,{\"style\":{\"background\":null},\"children\":[\"$\",\"code\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"$d\"}}]}]}],[\"$\",\"h3\",null,{\"className\":\"x-h2\",\"children\":\"预测\"}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"这个例子中我们用\u003cspan class=\\\"x-inline-strong\\\"\u003e单步预测\u003c/span\u003e观察模型的效果。在单步预测时，每次预测都全部使用真实值；当然，我们可以这样做是因为验证集中本来就包含了真实的数据，换句话说，我们是在已知\u003ccode class=\\\"x-inline-highlight\\\"\u003et+1\u003c/code\u003e时刻的真实数据的情况下，去看看模型使用\u003ccode class=\\\"x-inline-highlight\\\"\u003et-9\u003c/code\u003e~\u003ccode class=\\\"x-inline-highlight\\\"\u003et\u003c/code\u003e时刻的数据，对\u003ccode class=\\\"x-inline-highlight\\\"\u003et+1\u003c/code\u003e时刻的预测值。\"}}],[\"$\",\"div\",null,{\"className\":\"x-table-wrapper\",\"children\":[\"$\",\"table\",null,{\"className\":\"x-table\",\"children\":[\"$\",\"tbody\",null,{\"children\":[[\"$\",\"tr\",null,{\"children\":[[\"$\",\"th\",null,{\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003einput\u003c/code\u003e\"}}]}],[\"$\",\"th\",null,{\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003eprediction\u003c/code\u003e\"}}]}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[310]\u003c/code\u003e,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[311]\u003c/code\u003e,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[312]\u003c/code\u003e, ... ,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[319]\u003c/code\u003e\"}}]}],[\"$\",\"td\",null,{\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003epred[320]\u003c/code\u003e\"}}]}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[311]\u003c/code\u003e,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[312]\u003c/code\u003e,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[313]\u003c/code\u003e, ... ,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[320]\u003c/code\u003e\"}}]}],[\"$\",\"td\",null,{\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003epred[321]\u003c/code\u003e\"}}]}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[312]\u003c/code\u003e,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[313]\u003c/code\u003e,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[314]\u003c/code\u003e, ... ,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[321]\u003c/code\u003e\"}}]}],[\"$\",\"td\",null,{\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003epred[322]\u003c/code\u003e\"}}]}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":\"...\"}],[\"$\",\"td\",null,{\"children\":\"...\"}]]}]]}]}]}],[\"$\",\"div\",null,{\"className\":\"x-codeblock\",\"children\":[\"$\",\"pre\",null,{\"style\":{\"background\":null},\"children\":[\"$\",\"code\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"$e\"}}]}]}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"如果我们不只是在测试集上评估模型性能，而是去预测真实生活中的问题，例如未来\u003ccode class=\\\"x-inline-highlight\\\"\u003e7\u003c/code\u003e天的温度；或者假如我们的数据集到\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[319]\u003c/code\u003e就截止了，这时如果想得到后面多个时刻的数据，就需要\u003cspan class=\\\"x-inline-strong\\\"\u003e多步预测\u003c/span\u003e，此时上一时刻的预测会被当做新的输入：\"}}],[\"$\",\"div\",null,{\"className\":\"x-table-wrapper\",\"children\":[\"$\",\"table\",null,{\"className\":\"x-table\",\"children\":[\"$\",\"tbody\",null,{\"children\":[[\"$\",\"tr\",null,{\"children\":[[\"$\",\"th\",null,{\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003einput\u003c/code\u003e\"}}]}],[\"$\",\"th\",null,{\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003eprediction\u003c/code\u003e\"}}]}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[310]\u003c/code\u003e,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[311]\u003c/code\u003e,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[312]\u003c/code\u003e, ... ,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[319]\u003c/code\u003e\"}}]}],[\"$\",\"td\",null,{\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003epred[320]\u003c/code\u003e\"}}]}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[311]\u003c/code\u003e,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[312]\u003c/code\u003e,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[313]\u003c/code\u003e, ... ,\u003ccode class=\\\"x-inline-highlight\\\"\u003epred[320]\u003c/code\u003e\"}}]}],[\"$\",\"td\",null,{\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003epred[321]\u003c/code\u003e\"}}]}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[312]\u003c/code\u003e,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[313]\u003c/code\u003e,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[314]\u003c/code\u003e, ... ,\u003ccode class=\\\"x-inline-highlight\\\"\u003epred[320]\u003c/code\u003e,\u003ccode class=\\\"x-inline-highlight\\\"\u003epred[321]\u003c/code\u003e\"}}]}],[\"$\",\"td\",null,{\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003epred[322]\u003c/code\u003e\"}}]}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":\"...\"}],[\"$\",\"td\",null,{\"children\":\"...\"}]]}]]}]}]}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"多步预测会导致误差的累积。\"}}],[\"$\",\"h3\",null,{\"className\":\"x-h2\",\"children\":\"看看效果\"}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"如果不执行训练步骤的代码，使用初始随机参数的模型预测结果是：\"}}],[\"$\",\"$L8\",null,{\"src\":\"fig2.png\",\"width\":\"600px\",\"invertInDarkTheme\":true}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"经过训练后，每次训练的\u003ccode class=\\\"x-inline-highlight\\\"\u003eloss\u003c/code\u003e和最终的预测：\"}}],[\"$\",\"$L8\",null,{\"src\":\"fig3.png\",\"width\":\"600px\",\"invertInDarkTheme\":true}],[\"$\",\"h3\",null,{\"className\":\"x-h2\",\"children\":\"使用torch.nn.RNN\"}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"使用\u003ccode class=\\\"x-inline-highlight\\\"\u003etorch.nn.RNN\u003c/code\u003e模块时，与上面例子中手动实现的RNN有几处细小的区别，下面给出了使用\u003ccode class=\\\"x-inline-highlight\\\"\u003etorch.nn.RNN\u003c/code\u003e时需要做出的修改：\"}}],[\"$\",\"div\",null,{\"className\":\"x-oli\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-oli-number\",\"children\":\"1.\"}],[\"$\",\"div\",null,{\"className\":\"x-oli-content-wrapper\",\"children\":[[\"$\",\"p\",null,{\"className\":\"x-p no-margin-bottom\",\"dangerouslySetInnerHTML\":{\"__html\":\"定义模型时，不再需要显式指定\u003ccode class=\\\"x-inline-highlight\\\"\u003elinear_ih\u003c/code\u003e和\u003ccode class=\\\"x-inline-highlight\\\"\u003elinear_hh\u003c/code\u003e两层，将由\u003ccode class=\\\"x-inline-highlight\\\"\u003enn.RNN\u003c/code\u003e模块实现；\u003ccode class=\\\"x-inline-highlight\\\"\u003enn.RNN\u003c/code\u003e模块没有定义输出层，因此输出层\u003ccode class=\\\"x-inline-highlight\\\"\u003elinear_ho\u003c/code\u003e需要设置。\u003cbr/\u003e在\u003ccode class=\\\"x-inline-highlight\\\"\u003eforward\u003c/code\u003e函数中，手动实现时为了直观展示出RNN的迭代过程，只进行了一次隐藏状态的更新；而对于输入序列迭代更新隐藏状态是在训练和预测时实现的。而\u003ccode class=\\\"x-inline-highlight\\\"\u003enn.RNN\u003c/code\u003e模块的一次\u003ccode class=\\\"x-inline-highlight\\\"\u003eforward\u003c/code\u003e就已经完成了迭代更新，其输入是整个序列\u003ccode class=\\\"x-inline-highlight\\\"\u003eseq\u003c/code\u003e和\u003ccode class=\\\"x-inline-highlight\\\"\u003eprev_state\u003c/code\u003e，返回值是\u003ccode class=\\\"x-inline-highlight\\\"\u003eoutput_hidden,curr_state\u003c/code\u003e，对于不考虑批量大小的数据，它们的\u003ccode class=\\\"x-inline-highlight\\\"\u003esize\u003c/code\u003e为：\"}}],[\"$\",\"div\",null,{\"className\":\"x-uli\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-uli-marker\",\"children\":[\"$\",\"div\",null,{\"className\":\"x-uli-marker-dot\"}]}],[\"$\",\"div\",null,{\"className\":\"x-uli-content-wrapper\",\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003eseq\u003c/code\u003e: \u003ccode class=\\\"x-inline-highlight\\\"\u003e(sequence_length, input_size)\u003c/code\u003e\"}}]}]]}],[\"$\",\"div\",null,{\"className\":\"x-uli\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-uli-marker\",\"children\":[\"$\",\"div\",null,{\"className\":\"x-uli-marker-dot\"}]}],[\"$\",\"div\",null,{\"className\":\"x-uli-content-wrapper\",\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003einit_state\u003c/code\u003e: \u003ccode class=\\\"x-inline-highlight\\\"\u003e(1, hidden_size)\u003c/code\u003e\"}}]}]]}],[\"$\",\"div\",null,{\"className\":\"x-uli\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-uli-marker\",\"children\":[\"$\",\"div\",null,{\"className\":\"x-uli-marker-dot\"}]}],[\"$\",\"div\",null,{\"className\":\"x-uli-content-wrapper\",\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003eoutput_hidden\u003c/code\u003e: \u003ccode class=\\\"x-inline-highlight\\\"\u003e(sequence_length, hidden_size)\u003c/code\u003e\"}}]}]]}],[\"$\",\"div\",null,{\"className\":\"x-uli\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-uli-marker\",\"children\":[\"$\",\"div\",null,{\"className\":\"x-uli-marker-dot\"}]}],[\"$\",\"div\",null,{\"className\":\"x-uli-content-wrapper\",\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003estate\u003c/code\u003e: \u003ccode class=\\\"x-inline-highlight\\\"\u003e(1, hidden_size)\u003c/code\u003e\"}}]}]]}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"最后在我们定义的\u003ccode class=\\\"x-inline-highlight\\\"\u003eMyRNN\u003c/code\u003e模块中，用\u003ccode class=\\\"x-inline-highlight\\\"\u003eoutput_hidden\u003c/code\u003e的最后一个时间点的输出，经过输出层得到最终的\u003ccode class=\\\"x-inline-highlight\\\"\u003eoutput\u003c/code\u003e。\"}}]]}]]}],[\"$\",\"div\",null,{\"className\":\"x-highlightblock highlight-background-gray\",\"children\":[[\"$\",\"h4\",null,{\"className\":\"x-h3\",\"children\":\"手动实现\"}],[\"$\",\"div\",null,{\"className\":\"x-codeblock\",\"children\":[\"$\",\"pre\",null,{\"style\":{\"background\":null},\"children\":[\"$\",\"code\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"$f\"}}]}]}],[\"$\",\"h4\",null,{\"className\":\"x-h3\",\"children\":\"使用torch.nn.RNN\"}],[\"$\",\"div\",null,{\"className\":\"x-codeblock\",\"children\":[\"$\",\"pre\",null,{\"style\":{\"background\":null},\"children\":[\"$\",\"code\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"$10\"}}]}]}]]}],[\"$\",\"div\",null,{\"className\":\"x-oli\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-oli-number\",\"children\":\"2.\"}],[\"$\",\"div\",null,{\"className\":\"x-oli-content-wrapper\",\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"训练和预测时，也不需要再遍历序列，迭代的过程已经在\u003ccode class=\\\"x-inline-highlight\\\"\u003enn.RNN\u003c/code\u003e模块内部实现。\"}}]}]]}],[\"$\",\"div\",null,{\"className\":\"x-highlightblock highlight-background-gray\",\"children\":[[\"$\",\"h4\",null,{\"className\":\"x-h3\",\"children\":\"手动实现\"}],[\"$\",\"div\",null,{\"className\":\"x-codeblock\",\"children\":[\"$\",\"pre\",null,{\"style\":{\"background\":null},\"children\":[\"$\",\"code\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"$11\"}}]}]}],[\"$\",\"div\",null,{\"className\":\"x-codeblock\",\"children\":[\"$\",\"pre\",null,{\"style\":{\"background\":null},\"children\":[\"$\",\"code\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"$12\"}}]}]}],[\"$\",\"h4\",null,{\"className\":\"x-h3\",\"children\":\"使用torch.nn.RNN\"}],[\"$\",\"div\",null,{\"className\":\"x-codeblock\",\"children\":[\"$\",\"pre\",null,{\"style\":{\"background\":null},\"children\":[\"$\",\"code\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"$13\"}}]}]}],[\"$\",\"div\",null,{\"className\":\"x-codeblock\",\"children\":[\"$\",\"pre\",null,{\"style\":{\"background\":null},\"children\":[\"$\",\"code\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"$14\"}}]}]}]]}],[\"$\",\"h3\",null,{\"className\":\"x-h2\",\"children\":\"FAQ\"}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"初次了解RNN时，我在一些问题上困惑了很久。这个版块是对它们的再次整理。（尽管有些已经包含在上述例子中了！）\"}}],[\"$\",\"h4\",null,{\"className\":\"x-h3\",\"children\":\"用10步预测下1步，为什么 input_size 不是10，而是1？\"}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003einput_size\u003c/code\u003e与序列长度并非同一个概念。用前\u003ccode class=\\\"x-inline-highlight\\\"\u003e10\u003c/code\u003e个时间点的数据去预测下一个，这里的\u003ccode class=\\\"x-inline-highlight\\\"\u003e10\u003c/code\u003e是序列长度；而\u003ccode class=\\\"x-inline-highlight\\\"\u003einput_size\u003c/code\u003e是输入特征的维度。由于这个例子较为简单，只是用历史的\u003ccode class=\\\"x-inline-highlight\\\"\u003ey\u003c/code\u003e值预测新的\u003ccode class=\\\"x-inline-highlight\\\"\u003ey\u003c/code\u003e值，因此特征只有\u003ccode class=\\\"x-inline-highlight\\\"\u003e1\u003c/code\u003e维。\"}}],[\"$\",\"h4\",null,{\"className\":\"x-h3\",\"children\":\"什么时候 input_size 不是1？\"}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"例如我们在预测未来气温时，历史气温数据并不是唯一的参考，还可能参考历史的风速、气压、天气情况等等，此时输入数据将会是一个\u003ccode class=\\\"x-inline-highlight\\\"\u003einput_size\u003c/code\u003e维的向量。\"}}],[\"$\",\"h4\",null,{\"className\":\"x-h3\",\"children\":\"hidden_size=12，12是在哪里体现的？\"}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003e12\u003c/code\u003e只是模型的超参数，和MLP中隐藏层大小一样，并没有太多的物理含义。\"}}],[\"$\",\"h4\",null,{\"className\":\"x-h3\",\"children\":\"训练时，每次迭代用哪些数据？应该遍历几遍数据集？每个 epoch 会使用哪些数据进行参数优化？\"}],[\"$\",\"p\",null,{\"className\":\"x-p no-margin-bottom\",\"dangerouslySetInnerHTML\":{\"__html\":\"在训练一个CNN网络时（例如一个图片分类网络），策略通常是：\"}}],[\"$\",\"div\",null,{\"className\":\"x-oli\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-oli-number\",\"children\":\"1.\"}],[\"$\",\"div\",null,{\"className\":\"x-oli-content-wrapper\",\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"指定超参数\u003ccode class=\\\"x-inline-highlight\\\"\u003enum_epoch\u003c/code\u003e，在每个\u003ccode class=\\\"x-inline-highlight\\\"\u003eepoch\u003c/code\u003e中随机遍历训练集中的所有图像进行参数优化；\"}}]}]]}],[\"$\",\"div\",null,{\"className\":\"x-oli\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-oli-number\",\"children\":\"2.\"}],[\"$\",\"div\",null,{\"className\":\"x-oli-content-wrapper\",\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"重复执行\u003ccode class=\\\"x-inline-highlight\\\"\u003enum_epoch\u003c/code\u003e次。\"}}]}]]}],[\"$\",\"p\",null,{\"className\":\"x-p with-margin-top no-margin-bottom\",\"dangerouslySetInnerHTML\":{\"__html\":\"然而对于RNN来说这个概念似乎并不清晰，例如上述例子的训练策略是：\"}}],[\"$\",\"div\",null,{\"className\":\"x-oli\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-oli-number\",\"children\":\"1.\"}],[\"$\",\"div\",null,{\"className\":\"x-oli-content-wrapper\",\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"从\u003ccode class=\\\"x-inline-highlight\\\"\u003e0\u003c/code\u003e到\u003ccode class=\\\"x-inline-highlight\\\"\u003e(训练集大小 - 序列长度)\u003c/code\u003e依次遍历起始时间\u003ccode class=\\\"x-inline-highlight\\\"\u003et\u003c/code\u003e；\"}}]}]]}],[\"$\",\"div\",null,{\"className\":\"x-oli\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-oli-number\",\"children\":\"2.\"}],[\"$\",\"div\",null,{\"className\":\"x-oli-content-wrapper\",\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"对于每个起始时间\u003ccode class=\\\"x-inline-highlight\\\"\u003et\u003c/code\u003e，将\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[t]\u003c/code\u003e~\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[t+9]\u003c/code\u003e为输入，\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[t+10]\u003c/code\u003e为真值作为一组训练样本。\"}}]}]]}],[\"$\",\"div\",null,{\"className\":\"x-oli\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-oli-number\",\"children\":\"3.\"}],[\"$\",\"div\",null,{\"className\":\"x-oli-content-wrapper\",\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"第\u003ccode class=\\\"x-inline-highlight\\\"\u003e1\u003c/code\u003e步只遍历了一次！\"}}]}]]}],[\"$\",\"p\",null,{\"className\":\"x-p with-margin-top no-margin-bottom\",\"dangerouslySetInnerHTML\":{\"__html\":\"或者：\"}}],[\"$\",\"p\",null,{\"className\":\"x-p no-margin-bottom\",\"dangerouslySetInnerHTML\":{\"__html\":\"...\"}}],[\"$\",\"div\",null,{\"className\":\"x-oli\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-oli-number\",\"children\":\"3.\"}],[\"$\",\"div\",null,{\"className\":\"x-oli-content-wrapper\",\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"前两步同上，但多次遍历训练集。\"}}]}]]}],[\"$\",\"p\",null,{\"className\":\"x-p with-margin-top no-margin-bottom\",\"dangerouslySetInnerHTML\":{\"__html\":\"另一个常用的策略是：\"}}],[\"$\",\"div\",null,{\"className\":\"x-oli\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-oli-number\",\"children\":\"1.\"}],[\"$\",\"div\",null,{\"className\":\"x-oli-content-wrapper\",\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"指定超参数：训练轮次\u003ccode class=\\\"x-inline-highlight\\\"\u003enum_iter\u003c/code\u003e；\"}}]}]]}],[\"$\",\"div\",null,{\"className\":\"x-oli\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-oli-number\",\"children\":\"2.\"}],[\"$\",\"div\",null,{\"className\":\"x-oli-content-wrapper\",\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"重复执行\u003ccode class=\\\"x-inline-highlight\\\"\u003enum_iter\u003c/code\u003e次，每次随机抽取一个起始时间\u003ccode class=\\\"x-inline-highlight\\\"\u003et\u003c/code\u003e，并且将\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[t]\u003c/code\u003e~\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[t+9]\u003c/code\u003e为输入，\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[t+10]\u003c/code\u003e为真值作为一组训练样本。\"}}]}]]}],[\"$\",\"h2\",null,{\"className\":\"x-h1\",\"children\":\"LSTM：一篇很好的博客\"}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"以下的内容和插图总结或翻译自这篇的英文博客：\u003ca href=\\\"https://colah.github.io/posts/2015-08-Understanding-LSTMs/\\\" target=\\\"_blank\\\" rel=\\\"noreferrer\\\" class=\\\"x-inline-link\\\"\u003eUnderstanding LSTM Networks\u003c/a\u003e\"}}],[\"$\",\"h3\",null,{\"className\":\"x-h2\",\"children\":\"长期依赖问题\"}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"RNN可以利用先前的信息理解当前的任务，这点非常不错；有时我们只需要短期的信息，例如一个语言模型预测下面的句子：\u003cbr/\u003e\u003ccode class=\\\"x-inline-highlight\\\"\u003e天空中飘着一朵白色的【云】\u003c/code\u003e，这很简单。但有些时候我们需要更多背景信息，例如：\u003cbr/\u003e\u003ccode class=\\\"x-inline-highlight\\\"\u003e我出生在法国，…… ，我可以说流利的【法语】\u003c/code\u003e，这个情况下，随着前后文距离变大，RNN对长期依赖关系的学习会变得困难。\"}}],[\"$\",\"h3\",null,{\"className\":\"x-h2\",\"children\":\"LSTM\"}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003cspan class=\\\"x-inline-strong\\\"\u003e长短期记忆网络\u003c/span\u003e\u003ccode class=\\\"x-inline-highlight\\\"\u003e(Long Short-Term Memory, LSTM)\u003c/code\u003e是一种特殊的RNN，可以学习长期依赖。以RNN为例，循环神经网络随时间展开通常具有如下的示意图：\"}}],[\"$\",\"$L8\",null,{\"src\":\"rnn2.png\",\"width\":\"600px\",\"invertInDarkTheme\":true}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"对于RNN来说，利用历史状态和输入得到新的状态，只经过一个简单的\u003ccode class=\\\"x-inline-highlight\\\"\u003etanh\u003c/code\u003e激活层，而对于LSTM来说，它的示意图略显复杂：\"}}],[\"$\",\"$L8\",null,{\"src\":\"lstm1.png\",\"width\":\"600px\",\"invertInDarkTheme\":true}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"在上图中，每条线表示一个向量，粉红色圆圈表示逐点式操作，黄色的方框是神经网络的层。这看起来很眼晕，不过我们接下来会一点点的解释图里的内容。\"}}],[\"$\",\"h3\",null,{\"className\":\"x-h2\",\"children\":\"门控单元\"}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"下面的结构称为门控单元：\"}}],[\"$\",\"$L8\",null,{\"src\":\"lstm2.png\",\"width\":\"100px\",\"invertInDarkTheme\":true}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"门控单元控制信息量通过的多少，通过向量\u003cspan class=\\\"katex\\\"\u003e\u003cspan class=\\\"katex-html\\\" aria-hidden=\\\"true\\\"\u003e\u003cspan class=\\\"base\\\"\u003e\u003cspan class=\\\"strut\\\" style=\\\"height:0.4306em;\\\"\u003e\u003c/span\u003e\u003cspan class=\\\"mord mathnormal\\\" style=\\\"margin-right:0.04398em;\\\"\u003ez\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e来控制\u003cspan class=\\\"katex\\\"\u003e\u003cspan class=\\\"katex-html\\\" aria-hidden=\\\"true\\\"\u003e\u003cspan class=\\\"base\\\"\u003e\u003cspan class=\\\"strut\\\" style=\\\"height:0.4306em;\\\"\u003e\u003c/span\u003e\u003cspan class=\\\"mord mathnormal\\\"\u003ex\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e通过的信息量：\"}}],[\"$\",\"div\",null,{\"className\":\"x-formula\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003cspan class=\\\"katex\\\"\u003e\u003cspan class=\\\"katex-html\\\" aria-hidden=\\\"true\\\"\u003e\u003cspan class=\\\"base\\\"\u003e\u003cspan class=\\\"strut\\\" style=\\\"height:0.4306em;\\\"\u003e\u003c/span\u003e\u003cspan class=\\\"mord mathnormal\\\"\u003eo\u003c/span\u003e\u003cspan class=\\\"mspace\\\" style=\\\"margin-right:0.2778em;\\\"\u003e\u003c/span\u003e\u003cspan class=\\\"mrel\\\"\u003e=\u003c/span\u003e\u003cspan class=\\\"mspace\\\" style=\\\"margin-right:0.2778em;\\\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\\\"base\\\"\u003e\u003cspan class=\\\"strut\\\" style=\\\"height:1em;vertical-align:-0.25em;\\\"\u003e\u003c/span\u003e\u003cspan class=\\\"mord mathnormal\\\" style=\\\"margin-right:0.03588em;\\\"\u003eσ\u003c/span\u003e\u003cspan class=\\\"mopen\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"mord mathnormal\\\" style=\\\"margin-right:0.04398em;\\\"\u003ez\u003c/span\u003e\u003cspan class=\\\"mclose\\\"\u003e)\u003c/span\u003e\u003cspan class=\\\"mspace\\\" style=\\\"margin-right:0.2222em;\\\"\u003e\u003c/span\u003e\u003cspan class=\\\"mbin\\\"\u003e⊗\u003c/span\u003e\u003cspan class=\\\"mspace\\\" style=\\\"margin-right:0.2222em;\\\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\\\"base\\\"\u003e\u003cspan class=\\\"strut\\\" style=\\\"height:0.4306em;\\\"\u003e\u003c/span\u003e\u003cspan class=\\\"mord mathnormal\\\"\u003ex\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\"}}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"$15\"}}],[\"$\",\"h3\",null,{\"className\":\"x-h2\",\"children\":\"逐部分分析LSTM\"}],[\"$\",\"h4\",null,{\"className\":\"x-h3\",\"children\":\"遗忘门\"}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"$16\"}}],[\"$\",\"$L8\",null,{\"src\":\"lstm3.png\",\"width\":\"600px\",\"invertInDarkTheme\":true}],[\"$\",\"div\",null,{\"className\":\"x-highlightblock highlight-background-gray\",\"children\":[[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"举一个概念性的例子：\"}}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"考虑一个语言模型，输入一个句子：\u003ccode class=\\\"x-inline-highlight\\\"\u003eAlice是一名女教师，她喜欢给学生讲课；Bob是一位男司机，他喝酒上瘾。\u003c/code\u003e\"}}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"$17\"}}]]}],[\"$\",\"h4\",null,{\"className\":\"x-h3\",\"children\":\"输入门\"}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"$18\"}}],[\"$\",\"$L8\",null,{\"src\":\"lstm4.png\",\"width\":\"600px\",\"invertInDarkTheme\":true}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"经历这两步之后，便可以相加得到新的单元状态：\"}}],[\"$\",\"$L8\",null,{\"src\":\"lstm5.png\",\"width\":\"600px\",\"invertInDarkTheme\":true}],[\"$\",\"div\",null,{\"className\":\"x-highlightblock highlight-background-gray\",\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"同理，当模型看到\u003ccode class=\\\"x-inline-highlight\\\"\u003eBob是一位男司机\u003c/code\u003e时，我们可能会想丢掉此前的语义信息\u003ccode class=\\\"x-inline-highlight\\\"\u003e女性\u003c/code\u003e，并把新的语义信息\u003ccode class=\\\"x-inline-highlight\\\"\u003e男性\u003c/code\u003e存入单元状态，使得后文输出正确的代词\u003ccode class=\\\"x-inline-highlight\\\"\u003e他\u003c/code\u003e。\"}}]}],[\"$\",\"h4\",null,{\"className\":\"x-h3\",\"children\":\"输出门\"}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"$19\"}}],[\"$\",\"$L8\",null,{\"src\":\"lstm6.png\",\"width\":\"600px\",\"invertInDarkTheme\":true}],[\"$\",\"div\",null,{\"className\":\"x-highlightblock highlight-background-gray\",\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"当看到\u003ccode class=\\\"x-inline-highlight\\\"\u003eBob是一位男司机，他……\u003c/code\u003e时，由于出现了主语\u003ccode class=\\\"x-inline-highlight\\\"\u003e他\u003c/code\u003e，模型可能会输出和\u003ccode class=\\\"x-inline-highlight\\\"\u003e谓语动词\u003c/code\u003e有关的语义信息。\"}}]}]],null]]},[\"$\",\"$L1a\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"(posts)\",\"children\",\"23d\",\"children\",\"learn-rnn-lstm\",\"children\"],\"loading\":\"$undefined\",\"loadingStyles\":\"$undefined\",\"loadingScripts\":\"$undefined\",\"hasLoading\":false,\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L1b\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"styles\":[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/35b01ded3cfbfcc5.css\",\"precedence\":\"next\",\"crossOrigin\":\"\"}]]}]]},[\"$\",\"$L1a\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"(posts)\",\"children\",\"23d\",\"children\"],\"loading\":\"$undefined\",\"loadingStyles\":\"$undefined\",\"loadingScripts\":\"$undefined\",\"hasLoading\":false,\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L1b\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"styles\":null}]]},[null,[\"$\",\"div\",null,{\"id\":\"post-layout\",\"children\":[[\"$\",\"div\",null,{\"id\":\"main\",\"className\":\"y-center-wrapper\",\"children\":[\"$\",\"$L1a\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"(posts)\",\"children\"],\"loading\":\"$undefined\",\"loadingStyles\":\"$undefined\",\"loadingScripts\":\"$undefined\",\"hasLoading\":false,\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L1b\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"styles\":null}]}],[\"$\",\"$L1c\",null,{}]]}],null]]},[null,[\"$\",\"html\",null,{\"lang\":\"zh-CN\",\"suppressHydrationWarning\":true,\"children\":[[\"$\",\"head\",null,{\"children\":[[\"$\",\"link\",null,{\"rel\":\"icon\",\"href\":\"/favicon.ico\",\"type\":\"image/x-icon\"}],[\"$\",\"script\",null,{\"async\":true,\"src\":\"https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js\"}],[\"$\",\"script\",null,{\"async\":true,\"src\":\"https://www.googletagmanager.com/gtag/js?id=G-45BYSZ6WPY\"}],[\"$\",\"script\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"\\nwindow.dataLayer = window.dataLayer || [];\\nfunction gtag() {\\n    dataLayer.push(arguments);\\n}\\ngtag('js', new Date());\\ngtag('config', 'G-45BYSZ6WPY');\\n\"}}],[\"$\",\"script\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"const a=z=\u003eh.getItem(z),b=(y,z)=\u003eh.setItem(y,z),c=(y,z)=\u003edocument.documentElement.setAttribute(y,z),d='theme',e='dark',f='light',g='class',h=localStorage;a(d)!==e\u0026\u0026a(d)!==f\u0026\u0026b(d,f);a(d)===e?c(g,e):c(g,f);\"}}],[\"$\",\"script\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"\\nif (!Array.prototype.findLast) {\\n    Array.prototype.findLast = function (callback) {\\n        for (let i = this.length - 1; i \u003e= 0; i--) {\\n            if (callback(this[i])) return this[i];\\n        }\\n        return undefined;\\n    };\\n}\\nif (!Array.prototype.findLastIndex) {\\n    Array.prototype.findLastIndex = function (callback) {\\n        for (let i = this.length - 1; i \u003e= 0; i--) {\\n            if (callback(this[i])) return i;\\n        }\\n        return -1;\\n    };\\n}\\n\"}}]]}],[\"$\",\"body\",null,{\"children\":[\"$\",\"$L1d\",null,{\"children\":[[\"$\",\"$L1e\",null,{}],[\"$\",\"$L1a\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"loading\":\"$undefined\",\"loadingStyles\":\"$undefined\",\"loadingScripts\":\"$undefined\",\"hasLoading\":false,\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L1b\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[\"$\",\"div\",null,{\"id\":\"notfound\",\"children\":[[\"$\",\"img\",null,{\"alt\":\"img\",\"src\":\"/images/cry.gif\"}],[\"$\",\"div\",null,{\"id\":\"notfound-404\",\"children\":\"404\"}],[\"$\",\"div\",null,{\"id\":\"notfound-text\",\"children\":\"Page Not Found\"}]]}],\"notFoundStyles\":[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/0f7cce8b0dae9908.css\",\"precedence\":\"next\",\"crossOrigin\":\"\"}]],\"styles\":[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/615f855f1eaa8d62.css\",\"precedence\":\"next\",\"crossOrigin\":\"\"}]]}]]}]}]]}],null]],\"initialHead\":[false,\"$L1f\"],\"globalErrorComponent\":\"$20\",\"missingSlots\":\"$W21\"}]]\n"])</script><script>self.__next_f.push([1,"1f:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}],[\"$\",\"meta\",\"1\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"2\",{\"children\":\"学习RNN和LSTM - 铃木的网络日记\"}],[\"$\",\"link\",\"3\",{\"rel\":\"canonical\",\"href\":\"https://1kuzus.github.io/23d/learn-rnn-lstm/\"}]]\n6:null\n"])</script><script>self.__next_f.push([1,""])</script></body></html>