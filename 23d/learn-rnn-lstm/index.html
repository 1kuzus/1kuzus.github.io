<!DOCTYPE html><html lang="zh-CN"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="stylesheet" href="/_next/static/css/cd6b648520195f61.css" crossorigin="" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/9ae4a866c3254b07.css" crossorigin="" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-e16bca635fd7f9f0.js" crossorigin=""/><script src="/_next/static/chunks/fd9d1056-e278622fa62dc0bf.js" async="" crossorigin=""></script><script src="/_next/static/chunks/69-faab496ef6116e58.js" async="" crossorigin=""></script><script src="/_next/static/chunks/main-app-ed6799cd4e1df27b.js" async="" crossorigin=""></script><script src="/_next/static/chunks/457b8330-b5c9cf3fcf214847.js" async=""></script><script src="/_next/static/chunks/d3ac728e-0c798b3b8aa3bf53.js" async=""></script><script src="/_next/static/chunks/250-0ef8476c0fa8ee24.js" async=""></script><script src="/_next/static/chunks/612-fa632c1349770315.js" async=""></script><script src="/_next/static/chunks/551-19232c47cd1e883a.js" async=""></script><script src="/_next/static/chunks/app/%5B...slug%5D/page-d4a52f9ce8b82efb.js" async=""></script><script src="/_next/static/chunks/app/page-53cc083014f9456b.js" async=""></script><script src="/_next/static/chunks/app/layout-d8cba6107e479473.js" async=""></script><script async="" src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-45BYSZ6WPY"></script><title>学习RNN和LSTM - 铃木的网络日记</title><link rel="canonical" href="https://1kuzus.github.io/23d/learn-rnn-lstm/"/><link rel="icon" href="/favicon.ico" type="image/x-icon"/><script>
window.dataLayer = window.dataLayer || [];
function gtag() {
    dataLayer.push(arguments);
}
gtag('js', new Date());
gtag('config', 'G-45BYSZ6WPY');
</script><script>const a=z=>h.getItem(z),b=(y,z)=>h.setItem(y,z),c=(y,z)=>document.documentElement.setAttribute(y,z),d='theme',e='dark',f='light',g='class',h=localStorage;a(d)!==e&&a(d)!==f&&b(d,f);a(d)===e?c(g,e):c(g,f);</script><script>
if (!Array.prototype.findLast) {
    Array.prototype.findLast = function (callback) {
        for (let i = this.length - 1; i >= 0; i--) {
            if (callback(this[i])) return this[i];
        }
        return undefined;
    };
}
if (!Array.prototype.findLastIndex) {
    Array.prototype.findLastIndex = function (callback) {
        for (let i = this.length - 1; i >= 0; i--) {
            if (callback(this[i])) return i;
        }
        return -1;
    };
}
</script><script src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js" crossorigin="" noModule=""></script></head><body><div id="header"><div id="header-left-wrapper"><a href="/"><div id="header-logo-bg"><svg xmlns="http://www.w3.org/2000/svg" width="36" height="36" viewBox="0 0 1560 1560"><path fill="#00A8C4" d="M644 97h273l272 683H916z"></path><path fill="#30303C" d="M98 97h273l409 1024L1189 97h273L916 1462H644z"></path><path fill="#00F8FF" d="M98 1462 643 97h273L371 1462z"></path></svg></div></a></div><div id="header-right-wrapper"><button id="header-show-sidebar-button" class="header-button-bg"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 1024 1024"><rect fill="#FCFCFC" x="100" y="148" width="824" height="128" rx="64"></rect><rect fill="#FCFCFC" x="100" y="448" width="824" height="128" rx="64"></rect><rect fill="#FCFCFC" x="100" y="748" width="824" height="128" rx="64"></rect></svg></button><button class="header-button-bg"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 1024 1024" class="svg-dark-theme-icon"><path fill="#FCFCFC" d="M525 939h-4a440 440 0 0 1-314-135 446 446 0 0 1-11-597A432 432 0 0 1 367 90a43 43 0 0 1 45 9 43 43 0 0 1 10 43 358 358 0 0 0 83 376 361 361 0 0 0 377 83 43 43 0 0 1 54 55 433 433 0 0 1-100 155 439 439 0 0 1-311 128z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 1024 1024" class="svg-light-theme-icon"><path fill="#FCFCFC" d="M512 61c13 0 25 8 30 20l28 68c11 29-5 62-36 73a66 66 0 0 1-22 3c-34 0-61-25-61-56 0-7 1-14 3-20l28-68c5-12 17-20 30-20zm0 902c-13 0-25-8-30-20l-28-68a53 53 0 0 1-3-20c0-31 27-56 61-56a66 66 0 0 1 22 3c31 11 47 44 36 73l-28 68c-5 12-17 20-30 20zm451-451c0 13-8 25-20 30l-68 28c-29 11-62-5-73-36a66 66 0 0 1-3-22c0-34 25-61 56-61 7 0 14 1 20 3l68 28c12 5 20 17 20 30zm-902 0c0-13 8-25 20-30l68-28a53 53 0 0 1 20-3c31 0 56 27 56 61a66 66 0 0 1-3 22 57 57 0 0 1-73 36l-68-28c-12-5-20-17-20-30zm132-319c10-9 24-12 35-7l68 28c29 13 41 47 26 77a66 66 0 0 1-13 18c-24 24-61 26-83 4a53 53 0 0 1-12-17l-28-68c-5-11-2-25 7-35zm638 638c-10 9-24 12-35 7l-68-28a53 53 0 0 1-17-12c-22-22-20-59 4-83a66 66 0 0 1 18-13c30-15 64-3 77 26l28 68c5 11 2 25-7 35zm0-638c9 10 12 24 7 35l-28 68a56 56 0 0 1-77 26 66 66 0 0 1-18-13c-24-24-26-61-4-83 5-5 11-9 17-12l68-28c11-5 25-2 35 7zM193 831c-9-10-12-24-7-35l28-68a53 53 0 0 1 12-17c22-22 59-20 83 4a66 66 0 0 1 13 18c15 30 3 64-26 77l-68 28c-11 5-25 2-35-7zm319-94a225 225 0 1 1 0-450 225 225 0 0 1 0 450z"></path></svg></button><a href="https://github.com/1kuzus/1kuzus.github.io" target="_blank" rel="noreferrer"><div class="header-button-bg"><svg xmlns="http://www.w3.org/2000/svg" width="36" height="36" viewBox="0 0 1024 1024"><path fill="#FCFCFC" d="M411 831c4-5 7-10 7-12v-70c-106 22-128-44-128-44-17-45-43-56-43-56-34-24 4-24 4-24 37 3 58 39 58 39 34 58 89 41 111 32 3-24 13-41 24-51-86-10-174-43-174-188 0-41 15-75 39-102-4-10-17-48 3-101 0 0 33-10 104 40 31-9 64-12 96-12s65 5 96 12c73-50 104-40 104-40 20 53 8 91 3 101 24 27 39 60 39 102 0 145-88 178-174 188 14 12 26 34 26 70v104c0 4 2 7 7 12 5 7 3 19-4 24-3 2-7 3-10 3H425c-10 0-17-6-17-17 0-5 2-8 3-10z"></path></svg></div></a></div></div><div id="contents"><h4 id="contents-header">本页目录</h4></div><div id="post-layout"><div id="main" class="center-wrapper"><h1 class="post-title">学习RNN和LSTM</h1><div class="post-meta"><code class="not-loaded">0 views<!-- --> · </code><code>2023-12-17</code></div><!--$--><h2 class="x-h1">RNN：一个简单的例子</h2><p class="x-p">传统神经网络每次的输入是独立的，每次输出只依赖于当前的输入；但在某些任务中需要更好的处理序列信息，即前面的输入和后面的输入是有关系的；<span class="x-inline-strong">循环神经网络</span><code class="x-inline-highlight">(Recurrent Neural Networks, RNN)</code>通过使用带自反馈的神经元，能够处理任意长度的序列。</p><p class="x-p">下面是一个非常常见的RNN结构描述图。它展示了RNN的自反馈机制和与时间的依赖关系，但是对网络结构的描述容易引起误解：右侧的展开形式并不意味着网络有<code class="x-inline-highlight">t</code>层，而是反映了随着时间增加（有时也可以理解为随着程序中循环的迭代），上一次输出的隐藏状态，和<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>共同作为网络的下一次的输入。</p><p class="x-p">或者，如果说CNN是从空间维度上堆叠卷积层，不断加深，RNN就是从时间维度上的延展，而其网络真正的参数是很少的。</p><img alt="img" loading="lazy" width="2706" height="711" decoding="async" data-nimg="1" class="x-image x-image-invert" style="color:transparent;width:600px;height:auto" src="/_next/static/media/rnn1.ad2f936d.png"/><p class="x-p">下面以一个简单的正弦序列预测任务出发，结合代码理解RNN网络的部分细节。</p><h3 class="x-h2">预测一个正弦序列</h3><p class="x-p">这个例子中，我们对一个加了噪声的正弦序列进行预测。</p><div class="x-codeblock"><div class="x-codeblock-header"><div class="x-codeblock-header-language">Python</div><button class="x-codeblock-header-copy"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 1024 1024" class="svg-copy-icon"><path d="M337 138a27 27 0 0 0-27 27v78h377c50 0 92 41 92 91v377h78a28 28 0 0 0 27-28V166a28 28 0 0 0-27-27H337z m441 640v78c0 50-41 91-92 91H166a92 92 0 0 1-91-91V337c0-50 41-92 91-92h78V166c0-50 41-91 91-91h520c50 0 91 41 91 91v520c0 50-41 92-91 92h-78zM166 309a27 27 0 0 0-27 28v520c0 15 12 27 27 27h520a28 28 0 0 0 28-27V337a28 28 0 0 0-28-28H166z"></path></svg></button></div><pre><code><span class="token keyword">import</span> numpy
<span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt

<span class="token comment">#生成加噪声的正弦序列数据</span>
xlim<span class="token operator">=</span>numpy<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">36</span><span class="token punctuation">,</span><span class="token number">400</span><span class="token punctuation">)</span>
y<span class="token operator">=</span>numpy<span class="token punctuation">.</span>sin<span class="token punctuation">(</span>xlim<span class="token punctuation">)</span><span class="token operator">+</span>numpy<span class="token punctuation">.</span>random<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token operator">*</span>xlim<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token operator">*</span><span class="token number">0.2</span>

<span class="token comment">#转换dtype和size，保持和后面的训练数据统一</span>
y<span class="token operator">=</span>y<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token string">"float32"</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>xlim<span class="token punctuation">,</span>y<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div><p class="x-p">代码中我们在区间<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">36</span><span class="mclose">]</span></span></span></span>取了<code class="x-inline-highlight">400</code>点数据，如果把横轴看成时间轴，可以认为数据集中有<code class="x-inline-highlight">400</code>个连续时间点的数据。</p><img alt="img" loading="lazy" width="840" height="266" decoding="async" data-nimg="1" class="x-image x-image-invert" style="color:transparent;width:600px;height:auto" src="/_next/static/media/fig1.2b0c9266.png"/><p class="x-p">现在明确一下我们的方案：</p><div class="x-oli"><div class="x-oli-number">1.</div><div class="x-oli-content-wrapper"><p>使用前<code class="x-inline-highlight">80%</code>也就是前<code class="x-inline-highlight">320</code>个数据作为训练集，剩余的作为测试集，观察预测结果。</p></div></div><div class="x-oli"><div class="x-oli-number">2.</div><div class="x-oli-content-wrapper"><p>序列长度为<code class="x-inline-highlight">10</code>，也就是模型根据前<code class="x-inline-highlight">10</code>个时间点的数据去预测下一个时间点的数据。</p></div></div><div class="x-oli"><div class="x-oli-number">3.</div><div class="x-oli-content-wrapper"><p>这个例子中输入特征的维度是<code class="x-inline-highlight">1</code>，也就是只有<code class="x-inline-highlight">y</code>值一个指标。此外，也不考虑批量大小。</p></div></div><h3 class="x-h2">定义RNN网络</h3><div class="x-codeblock"><div class="x-codeblock-header"><div class="x-codeblock-header-language">Python</div><button class="x-codeblock-header-copy"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 1024 1024" class="svg-copy-icon"><path d="M337 138a27 27 0 0 0-27 27v78h377c50 0 92 41 92 91v377h78a28 28 0 0 0 27-28V166a28 28 0 0 0-27-27H337z m441 640v78c0 50-41 91-92 91H166a92 92 0 0 1-91-91V337c0-50 41-92 91-92h78V166c0-50 41-91 91-91h520c50 0 91 41 91 91v520c0 50-41 92-91 92h-78zM166 309a27 27 0 0 0-27 28v520c0 15 12 27 27 27h520a28 28 0 0 0 28-27V337a28 28 0 0 0-28-28H166z"></path></svg></button></div><pre><code><span class="token keyword">class</span> <span class="token class-name">MyRNN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>input_size<span class="token punctuation">,</span>hidden_size<span class="token punctuation">,</span>output_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>linear_ih<span class="token operator">=</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>input_size<span class="token punctuation">,</span>hidden_size<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>linear_hh<span class="token operator">=</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_size<span class="token punctuation">,</span>hidden_size<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>linear_ho<span class="token operator">=</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_size<span class="token punctuation">,</span>output_size<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>tanh<span class="token operator">=</span>nn<span class="token punctuation">.</span>Tanh<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">,</span>prev_state<span class="token punctuation">)</span><span class="token punctuation">:</span>
        curr_state<span class="token operator">=</span>self<span class="token punctuation">.</span>tanh<span class="token punctuation">(</span>
            self<span class="token punctuation">.</span>linear_ih<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token operator">+</span>self<span class="token punctuation">.</span>linear_hh<span class="token punctuation">(</span>prev_state<span class="token punctuation">)</span>
        <span class="token punctuation">)</span>
        output<span class="token operator">=</span>self<span class="token punctuation">.</span>linear_ho<span class="token punctuation">(</span>curr_state<span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> output<span class="token punctuation">,</span>curr_state

hidden_size<span class="token operator">=</span><span class="token number">12</span>
my_rnn<span class="token operator">=</span>MyRNN<span class="token punctuation">(</span>input_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>hidden_size<span class="token operator">=</span>hidden_size<span class="token punctuation">,</span>output_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
loss_func<span class="token operator">=</span>nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
optimizer<span class="token operator">=</span>torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>my_rnn<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span>
</code></pre></div><p class="x-p">这个是一个简单的RNN结构，从网络参数和结构来看很像一个<code class="x-inline-highlight">输入层-隐藏层-输出层</code>的感知机，但是多了一步<code class="x-inline-highlight">隐藏层-隐藏层</code>的连接，RNN的反馈结构就是由此体现的。</p><p class="x-p">并且，注意到<code class="x-inline-highlight">forward</code>函数的输入也需要两个参数：当前时刻输入<code class="x-inline-highlight">x</code>和前一时刻状态<code class="x-inline-highlight">prev_state</code>，同时也会把计算后的新状态<code class="x-inline-highlight">curr_state</code>和<code class="x-inline-highlight">output</code>一起返回，供下一次计算使用。在这里，经过<code class="x-inline-highlight">linear_ho</code>后，<code class="x-inline-highlight">output</code>的<code class="x-inline-highlight">size</code>为<code class="x-inline-highlight">(1,1)</code>，考虑到它仅仅是一个标量，我们把它<code class="x-inline-highlight">resize</code>为<code class="x-inline-highlight">(1)</code>。</p><p class="x-p">接下来设置了一些超参数，隐藏层有<code class="x-inline-highlight">12</code>个神经元，损失函数使用<code class="x-inline-highlight">MSELoss()</code>。</p><h3 class="x-h2">训练</h3><p class="x-p">首先定义这样的训练函数：它传入一个序列<code class="x-inline-highlight">train_seq</code>和目标<code class="x-inline-highlight">target</code>。<code class="x-inline-highlight">train_seq</code>的<code class="x-inline-highlight">size</code>应该为<code class="x-inline-highlight">(10,1)</code>，因为我们用前<code class="x-inline-highlight">10</code>个时间点的数据去预测下一个，而输入特征维度是<code class="x-inline-highlight">1</code>；<code class="x-inline-highlight">target</code>的<code class="x-inline-highlight">size</code>应该为<code class="x-inline-highlight">(1)</code>，因为输出只是一个标量。注意我们循环依次输入<code class="x-inline-highlight">train_seq</code>中的<code class="x-inline-highlight">10</code>个数据，迭代更新<code class="x-inline-highlight">state</code>，用最后一次的<code class="x-inline-highlight">output</code>作为最终的输出计算损失。</p><div class="x-codeblock"><div class="x-codeblock-header"><div class="x-codeblock-header-language">Python</div><button class="x-codeblock-header-copy"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 1024 1024" class="svg-copy-icon"><path d="M337 138a27 27 0 0 0-27 27v78h377c50 0 92 41 92 91v377h78a28 28 0 0 0 27-28V166a28 28 0 0 0-27-27H337z m441 640v78c0 50-41 91-92 91H166a92 92 0 0 1-91-91V337c0-50 41-92 91-92h78V166c0-50 41-91 91-91h520c50 0 91 41 91 91v520c0 50-41 92-91 92h-78zM166 309a27 27 0 0 0-27 28v520c0 15 12 27 27 27h520a28 28 0 0 0 28-27V337a28 28 0 0 0-28-28H166z"></path></svg></button></div><pre><code><span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>train_seq<span class="token punctuation">,</span>target<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment">#初始状态</span>
    state<span class="token operator">=</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>hidden_size<span class="token punctuation">)</span>

    <span class="token keyword">for</span> x <span class="token keyword">in</span> train_seq<span class="token punctuation">:</span>
        output<span class="token punctuation">,</span>state<span class="token operator">=</span>my_rnn<span class="token punctuation">(</span>x<span class="token punctuation">,</span>state<span class="token punctuation">)</span>

    loss<span class="token operator">=</span>loss_func<span class="token punctuation">(</span>output<span class="token punctuation">,</span>target<span class="token punctuation">)</span>
    optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
    optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment">#返回损失</span>
    <span class="token keyword">return</span> loss<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
</code></pre></div><p class="x-p">下面代码把真实数据划分成：</p><div class="x-table-wrapper"><table class="x-table"><tbody><tr><th><p><code class="x-inline-highlight">train_seq</code></p></th><th><p><code class="x-inline-highlight">target</code></p></th></tr><tr><td><p><code class="x-inline-highlight">y[0]</code>,<code class="x-inline-highlight">y[1]</code>,<code class="x-inline-highlight">y[2]</code>, ... ,<code class="x-inline-highlight">y[9]</code></p></td><td><p><code class="x-inline-highlight">y[10]</code></p></td></tr><tr><td><p><code class="x-inline-highlight">y[1]</code>,<code class="x-inline-highlight">y[2]</code>,<code class="x-inline-highlight">y[3]</code>, ... ,<code class="x-inline-highlight">y[10]</code></p></td><td><p><code class="x-inline-highlight">y[11]</code></p></td></tr><tr><td><p><code class="x-inline-highlight">y[2]</code>,<code class="x-inline-highlight">y[3]</code>,<code class="x-inline-highlight">y[4]</code>, ... ,<code class="x-inline-highlight">y[11]</code></p></td><td><p><code class="x-inline-highlight">y[12]</code></p></td></tr><tr><td><p>...</p></td><td><p>...</p></td></tr><tr><td><p><code class="x-inline-highlight">y[309]</code>,<code class="x-inline-highlight">y[310]</code>,<code class="x-inline-highlight">y[311]</code>, ... ,<code class="x-inline-highlight">y[318]</code></p></td><td><p><code class="x-inline-highlight">y[319]</code></p></td></tr></tbody></table></div><div class="x-codeblock"><div class="x-codeblock-header"><div class="x-codeblock-header-language">Python</div><button class="x-codeblock-header-copy"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 1024 1024" class="svg-copy-icon"><path d="M337 138a27 27 0 0 0-27 27v78h377c50 0 92 41 92 91v377h78a28 28 0 0 0 27-28V166a28 28 0 0 0-27-27H337z m441 640v78c0 50-41 91-92 91H166a92 92 0 0 1-91-91V337c0-50 41-92 91-92h78V166c0-50 41-91 91-91h520c50 0 91 41 91 91v520c0 50-41 92-91 92h-78zM166 309a27 27 0 0 0-27 28v520c0 15 12 27 27 27h520a28 28 0 0 0 28-27V337a28 28 0 0 0-28-28H166z"></path></svg></button></div><pre><code>train_datas<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">320</span><span class="token operator">-</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    train_seq<span class="token operator">=</span>torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>y<span class="token punctuation">[</span>i<span class="token punctuation">:</span>i<span class="token operator">+</span><span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    target<span class="token operator">=</span>torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>y<span class="token punctuation">[</span>i<span class="token operator">+</span><span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    train_datas<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span>train_seq<span class="token punctuation">,</span>target<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre></div><p class="x-p">训练网络，绘制误差：</p><div class="x-codeblock"><div class="x-codeblock-header"><div class="x-codeblock-header-language">Python</div><button class="x-codeblock-header-copy"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 1024 1024" class="svg-copy-icon"><path d="M337 138a27 27 0 0 0-27 27v78h377c50 0 92 41 92 91v377h78a28 28 0 0 0 27-28V166a28 28 0 0 0-27-27H337z m441 640v78c0 50-41 91-92 91H166a92 92 0 0 1-91-91V337c0-50 41-92 91-92h78V166c0-50 41-91 91-91h520c50 0 91 41 91 91v520c0 50-41 92-91 92h-78zM166 309a27 27 0 0 0-27 28v520c0 15 12 27 27 27h520a28 28 0 0 0 28-27V337a28 28 0 0 0-28-28H166z"></path></svg></button></div><pre><code>metrics<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>
my_rnn<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> train_seq<span class="token punctuation">,</span>target <span class="token keyword">in</span> train_datas<span class="token punctuation">:</span>
    loss<span class="token operator">=</span>train<span class="token punctuation">(</span>train_seq<span class="token punctuation">,</span>target<span class="token punctuation">)</span>
    metrics<span class="token punctuation">.</span>append<span class="token punctuation">(</span>loss<span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">211</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>metrics<span class="token punctuation">,</span>label<span class="token operator">=</span><span class="token string">"loss"</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div><h3 class="x-h2">预测</h3><p class="x-p">这个例子中我们用<span class="x-inline-strong">单步预测</span>观察模型的效果。在单步预测时，每次预测都全部使用真实值；当然，我们可以这样做是因为验证集中本来就包含了真实的数据，换句话说，我们是在已知<code class="x-inline-highlight">t+1</code>时刻的真实数据的情况下，去看看模型使用<code class="x-inline-highlight">t-9</code>~<code class="x-inline-highlight">t</code>时刻的数据，对<code class="x-inline-highlight">t+1</code>时刻的预测值。</p><div class="x-table-wrapper"><table class="x-table"><tbody><tr><th><p><code class="x-inline-highlight">input</code></p></th><th><p><code class="x-inline-highlight">prediction</code></p></th></tr><tr><td><p><code class="x-inline-highlight">y[310]</code>,<code class="x-inline-highlight">y[311]</code>,<code class="x-inline-highlight">y[312]</code>, ... ,<code class="x-inline-highlight">y[319]</code></p></td><td><p><code class="x-inline-highlight">pred[320]</code></p></td></tr><tr><td><p><code class="x-inline-highlight">y[311]</code>,<code class="x-inline-highlight">y[312]</code>,<code class="x-inline-highlight">y[313]</code>, ... ,<code class="x-inline-highlight">y[320]</code></p></td><td><p><code class="x-inline-highlight">pred[321]</code></p></td></tr><tr><td><p><code class="x-inline-highlight">y[312]</code>,<code class="x-inline-highlight">y[313]</code>,<code class="x-inline-highlight">y[314]</code>, ... ,<code class="x-inline-highlight">y[321]</code></p></td><td><p><code class="x-inline-highlight">pred[322]</code></p></td></tr><tr><td><p>...</p></td><td><p>...</p></td></tr></tbody></table></div><div class="x-codeblock"><div class="x-codeblock-header"><div class="x-codeblock-header-language">Python</div><button class="x-codeblock-header-copy"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 1024 1024" class="svg-copy-icon"><path d="M337 138a27 27 0 0 0-27 27v78h377c50 0 92 41 92 91v377h78a28 28 0 0 0 27-28V166a28 28 0 0 0-27-27H337z m441 640v78c0 50-41 91-92 91H166a92 92 0 0 1-91-91V337c0-50 41-92 91-92h78V166c0-50 41-91 91-91h520c50 0 91 41 91 91v520c0 50-41 92-91 92h-78zM166 309a27 27 0 0 0-27 28v520c0 15 12 27 27 27h520a28 28 0 0 0 28-27V337a28 28 0 0 0-28-28H166z"></path></svg></button></div><pre><code><span class="token keyword">def</span> <span class="token function">pred</span><span class="token punctuation">(</span>truth_seq<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        state<span class="token operator">=</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>hidden_size<span class="token punctuation">)</span>
        <span class="token keyword">for</span> x <span class="token keyword">in</span> truth_seq<span class="token punctuation">:</span>
            output<span class="token punctuation">,</span>state<span class="token operator">=</span>my_rnn<span class="token punctuation">(</span>x<span class="token punctuation">,</span>state<span class="token punctuation">)</span>
        <span class="token keyword">return</span> output

preds<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">320</span><span class="token operator">-</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">400</span><span class="token operator">-</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    truth_seq<span class="token operator">=</span>torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>y<span class="token punctuation">[</span>i<span class="token punctuation">:</span>i<span class="token operator">+</span><span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    preds<span class="token punctuation">.</span>append<span class="token punctuation">(</span>pred<span class="token punctuation">(</span>truth_seq<span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
preds<span class="token operator">=</span>numpy<span class="token punctuation">.</span>array<span class="token punctuation">(</span>preds<span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">212</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>xlim<span class="token punctuation">,</span>y<span class="token punctuation">,</span>label<span class="token operator">=</span><span class="token string">"truth"</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>xlim<span class="token punctuation">[</span><span class="token number">320</span><span class="token punctuation">:</span><span class="token number">400</span><span class="token punctuation">]</span><span class="token punctuation">,</span>preds<span class="token punctuation">,</span><span class="token string">"red"</span><span class="token punctuation">,</span>label<span class="token operator">=</span><span class="token string">"predict"</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div><p class="x-p">如果我们不只是在测试集上评估模型性能，而是去预测真实生活中的问题，例如未来<code class="x-inline-highlight">7</code>天的温度；或者假如我们的数据集到<code class="x-inline-highlight">y[319]</code>就截止了，这时如果想得到后面多个时刻的数据，就需要<span class="x-inline-strong">多步预测</span>，此时上一时刻的预测会被当做新的输入：</p><div class="x-table-wrapper"><table class="x-table"><tbody><tr><th><p><code class="x-inline-highlight">input</code></p></th><th><p><code class="x-inline-highlight">prediction</code></p></th></tr><tr><td><p><code class="x-inline-highlight">y[310]</code>,<code class="x-inline-highlight">y[311]</code>,<code class="x-inline-highlight">y[312]</code>, ... ,<code class="x-inline-highlight">y[319]</code></p></td><td><p><code class="x-inline-highlight">pred[320]</code></p></td></tr><tr><td><p><code class="x-inline-highlight">y[311]</code>,<code class="x-inline-highlight">y[312]</code>,<code class="x-inline-highlight">y[313]</code>, ... ,<code class="x-inline-highlight">pred[320]</code></p></td><td><p><code class="x-inline-highlight">pred[321]</code></p></td></tr><tr><td><p><code class="x-inline-highlight">y[312]</code>,<code class="x-inline-highlight">y[313]</code>,<code class="x-inline-highlight">y[314]</code>, ... ,<code class="x-inline-highlight">pred[320]</code>,<code class="x-inline-highlight">pred[321]</code></p></td><td><p><code class="x-inline-highlight">pred[322]</code></p></td></tr><tr><td><p>...</p></td><td><p>...</p></td></tr></tbody></table></div><p class="x-p">多步预测会导致误差的累积。</p><h3 class="x-h2">看看效果</h3><p class="x-p">如果不执行训练步骤的代码，使用初始随机参数的模型预测结果是：</p><img alt="img" loading="lazy" width="840" height="261" decoding="async" data-nimg="1" class="x-image x-image-invert" style="color:transparent;width:600px;height:auto" src="/_next/static/media/fig2.51ee0782.png"/><p class="x-p">经过训练后，每次训练的<code class="x-inline-highlight">loss</code>和最终的预测：</p><img alt="img" loading="lazy" width="840" height="543" decoding="async" data-nimg="1" class="x-image x-image-invert" style="color:transparent;width:600px;height:auto" src="/_next/static/media/fig3.6f6f5b35.png"/><h3 class="x-h2">使用torch.nn.RNN</h3><p class="x-p">使用<code class="x-inline-highlight">torch.nn.RNN</code>模块时，与上面例子中手动实现的RNN有几处细小的区别，下面给出了使用<code class="x-inline-highlight">torch.nn.RNN</code>时需要做出的修改：</p><div class="x-oli"><div class="x-oli-number">1.</div><div class="x-oli-content-wrapper"><p class="x-p">定义模型时，不再需要显式指定<code class="x-inline-highlight">linear_ih</code>和<code class="x-inline-highlight">linear_hh</code>两层，将由<code class="x-inline-highlight">nn.RNN</code>模块实现；<code class="x-inline-highlight">nn.RNN</code>模块没有定义输出层，因此输出层<code class="x-inline-highlight">linear_ho</code>需要设置。<br/>在<code class="x-inline-highlight">forward</code>函数中，手动实现时为了直观展示出RNN的迭代过程，只进行了一次隐藏状态的更新；而对于输入序列迭代更新隐藏状态是在训练和预测时实现的。而<code class="x-inline-highlight">nn.RNN</code>模块的一次<code class="x-inline-highlight">forward</code>就已经完成了迭代更新，其输入是整个序列<code class="x-inline-highlight">seq</code>和<code class="x-inline-highlight">prev_state</code>，返回值是<code class="x-inline-highlight">output_hidden,curr_state</code>，对于不考虑批量大小的数据，它们的<code class="x-inline-highlight">size</code>为：</p><div class="x-uli"><div class="x-uli-marker"><div class="x-uli-marker-dot"></div></div><div class="x-uli-content-wrapper"><p><code class="x-inline-highlight">seq</code>: <code class="x-inline-highlight">(sequence_length, input_size)</code></p></div></div><div class="x-uli"><div class="x-uli-marker"><div class="x-uli-marker-dot"></div></div><div class="x-uli-content-wrapper"><p><code class="x-inline-highlight">init_state</code>: <code class="x-inline-highlight">(1, hidden_size)</code></p></div></div><div class="x-uli"><div class="x-uli-marker"><div class="x-uli-marker-dot"></div></div><div class="x-uli-content-wrapper"><p><code class="x-inline-highlight">output_hidden</code>: <code class="x-inline-highlight">(sequence_length, hidden_size)</code></p></div></div><div class="x-uli"><div class="x-uli-marker"><div class="x-uli-marker-dot"></div></div><div class="x-uli-content-wrapper"><p><code class="x-inline-highlight">state</code>: <code class="x-inline-highlight">(1, hidden_size)</code></p></div></div><p class="x-p">最后在我们定义的<code class="x-inline-highlight">MyRNN</code>模块中，用<code class="x-inline-highlight">output_hidden</code>的最后一个时间点的输出，经过输出层得到最终的<code class="x-inline-highlight">output</code>。</p></div></div><div class="x-highlightblock highlight-background-gray"><h4 class="x-h3">手动实现</h4><div class="x-codeblock"><div class="x-codeblock-header"><div class="x-codeblock-header-language">Python</div><button class="x-codeblock-header-copy"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 1024 1024" class="svg-copy-icon"><path d="M337 138a27 27 0 0 0-27 27v78h377c50 0 92 41 92 91v377h78a28 28 0 0 0 27-28V166a28 28 0 0 0-27-27H337z m441 640v78c0 50-41 91-92 91H166a92 92 0 0 1-91-91V337c0-50 41-92 91-92h78V166c0-50 41-91 91-91h520c50 0 91 41 91 91v520c0 50-41 92-91 92h-78zM166 309a27 27 0 0 0-27 28v520c0 15 12 27 27 27h520a28 28 0 0 0 28-27V337a28 28 0 0 0-28-28H166z"></path></svg></button></div><pre><code><span class="token keyword">class</span> <span class="token class-name">MyRNN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>input_size<span class="token punctuation">,</span>hidden_size<span class="token punctuation">,</span>output_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>linear_ih<span class="token operator">=</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>input_size<span class="token punctuation">,</span>hidden_size<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>linear_hh<span class="token operator">=</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_size<span class="token punctuation">,</span>hidden_size<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>linear_ho<span class="token operator">=</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_size<span class="token punctuation">,</span>output_size<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>tanh<span class="token operator">=</span>nn<span class="token punctuation">.</span>Tanh<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">,</span>prev_state<span class="token punctuation">)</span><span class="token punctuation">:</span>
        curr_state<span class="token operator">=</span>self<span class="token punctuation">.</span>tanh<span class="token punctuation">(</span>
            self<span class="token punctuation">.</span>linear_ih<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token operator">+</span>self<span class="token punctuation">.</span>linear_hh<span class="token punctuation">(</span>prev_state<span class="token punctuation">)</span>
        <span class="token punctuation">)</span>
        output<span class="token operator">=</span>self<span class="token punctuation">.</span>linear_ho<span class="token punctuation">(</span>curr_state<span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> output<span class="token punctuation">,</span>curr_state
</code></pre></div><h4 class="x-h3">使用torch.nn.RNN</h4><div class="x-codeblock"><div class="x-codeblock-header"><div class="x-codeblock-header-language">Python</div><button class="x-codeblock-header-copy"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 1024 1024" class="svg-copy-icon"><path d="M337 138a27 27 0 0 0-27 27v78h377c50 0 92 41 92 91v377h78a28 28 0 0 0 27-28V166a28 28 0 0 0-27-27H337z m441 640v78c0 50-41 91-92 91H166a92 92 0 0 1-91-91V337c0-50 41-92 91-92h78V166c0-50 41-91 91-91h520c50 0 91 41 91 91v520c0 50-41 92-91 92h-78zM166 309a27 27 0 0 0-27 28v520c0 15 12 27 27 27h520a28 28 0 0 0 28-27V337a28 28 0 0 0-28-28H166z"></path></svg></button></div><pre><code><span class="token keyword">class</span> <span class="token class-name">MyRNN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>input_size<span class="token punctuation">,</span>hidden_size<span class="token punctuation">,</span>output_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>rnn<span class="token operator">=</span>nn<span class="token punctuation">.</span>RNN<span class="token punctuation">(</span>input_size<span class="token operator">=</span>input_size<span class="token punctuation">,</span>hidden_size<span class="token operator">=</span>hidden_size<span class="token punctuation">,</span>batch_first<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>linear_ho<span class="token operator">=</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_size<span class="token punctuation">,</span>output_size<span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>seq<span class="token punctuation">,</span>init_state<span class="token punctuation">)</span><span class="token punctuation">:</span>
        output_hidden<span class="token punctuation">,</span>tate<span class="token operator">=</span>self<span class="token punctuation">.</span>rnn<span class="token punctuation">(</span>seq<span class="token punctuation">,</span>init_state<span class="token punctuation">)</span>
        output<span class="token operator">=</span>self<span class="token punctuation">.</span>linear_ho<span class="token punctuation">(</span>output_hidden<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment">#取最后一个时间点的输出</span>
        <span class="token keyword">return</span> output<span class="token punctuation">,</span>state
</code></pre></div></div><div class="x-oli"><div class="x-oli-number">2.</div><div class="x-oli-content-wrapper"><p>训练和预测时，也不需要再遍历序列，迭代的过程已经在<code class="x-inline-highlight">nn.RNN</code>模块内部实现。</p></div></div><div class="x-highlightblock highlight-background-gray"><h4 class="x-h3">手动实现</h4><div class="x-codeblock"><div class="x-codeblock-header"><div class="x-codeblock-header-language">Python</div><button class="x-codeblock-header-copy"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 1024 1024" class="svg-copy-icon"><path d="M337 138a27 27 0 0 0-27 27v78h377c50 0 92 41 92 91v377h78a28 28 0 0 0 27-28V166a28 28 0 0 0-27-27H337z m441 640v78c0 50-41 91-92 91H166a92 92 0 0 1-91-91V337c0-50 41-92 91-92h78V166c0-50 41-91 91-91h520c50 0 91 41 91 91v520c0 50-41 92-91 92h-78zM166 309a27 27 0 0 0-27 28v520c0 15 12 27 27 27h520a28 28 0 0 0 28-27V337a28 28 0 0 0-28-28H166z"></path></svg></button></div><pre><code><span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>train_seq<span class="token punctuation">,</span>target<span class="token punctuation">)</span><span class="token punctuation">:</span>
    state<span class="token operator">=</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>hidden_size<span class="token punctuation">)</span>
    <span class="token keyword">for</span> x <span class="token keyword">in</span> train_seq<span class="token punctuation">:</span>
        output<span class="token punctuation">,</span>state<span class="token operator">=</span>my_rnn<span class="token punctuation">(</span>x<span class="token punctuation">,</span>state<span class="token punctuation">)</span>
    loss<span class="token operator">=</span>loss_func<span class="token punctuation">(</span>output<span class="token punctuation">,</span>target<span class="token punctuation">)</span>
    <span class="token comment"># ......</span>
</code></pre></div><div class="x-codeblock"><div class="x-codeblock-header"><div class="x-codeblock-header-language">Python</div><button class="x-codeblock-header-copy"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 1024 1024" class="svg-copy-icon"><path d="M337 138a27 27 0 0 0-27 27v78h377c50 0 92 41 92 91v377h78a28 28 0 0 0 27-28V166a28 28 0 0 0-27-27H337z m441 640v78c0 50-41 91-92 91H166a92 92 0 0 1-91-91V337c0-50 41-92 91-92h78V166c0-50 41-91 91-91h520c50 0 91 41 91 91v520c0 50-41 92-91 92h-78zM166 309a27 27 0 0 0-27 28v520c0 15 12 27 27 27h520a28 28 0 0 0 28-27V337a28 28 0 0 0-28-28H166z"></path></svg></button></div><pre><code><span class="token keyword">def</span> <span class="token function">pred</span><span class="token punctuation">(</span>truth_seq<span class="token punctuation">,</span>net<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        state<span class="token operator">=</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>hidden_size<span class="token punctuation">)</span>
        <span class="token keyword">for</span> x <span class="token keyword">in</span> truth_seq<span class="token punctuation">:</span>
            output<span class="token punctuation">,</span>state<span class="token operator">=</span>net<span class="token punctuation">(</span>x<span class="token punctuation">,</span>state<span class="token punctuation">)</span>
        <span class="token keyword">return</span> output
</code></pre></div><h4 class="x-h3">使用torch.nn.RNN</h4><div class="x-codeblock"><div class="x-codeblock-header"><div class="x-codeblock-header-language">Python</div><button class="x-codeblock-header-copy"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 1024 1024" class="svg-copy-icon"><path d="M337 138a27 27 0 0 0-27 27v78h377c50 0 92 41 92 91v377h78a28 28 0 0 0 27-28V166a28 28 0 0 0-27-27H337z m441 640v78c0 50-41 91-92 91H166a92 92 0 0 1-91-91V337c0-50 41-92 91-92h78V166c0-50 41-91 91-91h520c50 0 91 41 91 91v520c0 50-41 92-91 92h-78zM166 309a27 27 0 0 0-27 28v520c0 15 12 27 27 27h520a28 28 0 0 0 28-27V337a28 28 0 0 0-28-28H166z"></path></svg></button></div><pre><code><span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>train_seq<span class="token punctuation">,</span>target<span class="token punctuation">)</span><span class="token punctuation">:</span>
    state<span class="token operator">=</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>hidden_size<span class="token punctuation">)</span>
    output<span class="token punctuation">,</span>_<span class="token operator">=</span>my_rnn<span class="token punctuation">(</span>train_seq<span class="token punctuation">,</span>state<span class="token punctuation">)</span> <span class="token comment">#一次得到输出</span>
    loss<span class="token operator">=</span>loss_func<span class="token punctuation">(</span>output<span class="token punctuation">,</span>target<span class="token punctuation">)</span>
    <span class="token comment"># ......</span>
</code></pre></div><div class="x-codeblock"><div class="x-codeblock-header"><div class="x-codeblock-header-language">Python</div><button class="x-codeblock-header-copy"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 1024 1024" class="svg-copy-icon"><path d="M337 138a27 27 0 0 0-27 27v78h377c50 0 92 41 92 91v377h78a28 28 0 0 0 27-28V166a28 28 0 0 0-27-27H337z m441 640v78c0 50-41 91-92 91H166a92 92 0 0 1-91-91V337c0-50 41-92 91-92h78V166c0-50 41-91 91-91h520c50 0 91 41 91 91v520c0 50-41 92-91 92h-78zM166 309a27 27 0 0 0-27 28v520c0 15 12 27 27 27h520a28 28 0 0 0 28-27V337a28 28 0 0 0-28-28H166z"></path></svg></button></div><pre><code><span class="token keyword">def</span> <span class="token function">pred</span><span class="token punctuation">(</span>truth_seq<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        state<span class="token operator">=</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>hidden_size<span class="token punctuation">)</span>
        output<span class="token punctuation">,</span>_<span class="token operator">=</span>my_rnn<span class="token punctuation">(</span>truth_seq<span class="token punctuation">,</span>state<span class="token punctuation">)</span> <span class="token comment">#一次得到输出</span>
        <span class="token keyword">return</span> output
</code></pre></div></div><h3 class="x-h2">FAQ</h3><p class="x-p">初次了解RNN时，我在一些问题上困惑了很久。这个版块是对它们的再次整理。（尽管有些已经包含在上述例子中了！）</p><h4 class="x-h3">用10步预测下1步，为什么 input_size 不是10，而是1？</h4><p class="x-p"><code class="x-inline-highlight">input_size</code>与序列长度并非同一个概念。用前<code class="x-inline-highlight">10</code>个时间点的数据去预测下一个，这里的<code class="x-inline-highlight">10</code>是序列长度；而<code class="x-inline-highlight">input_size</code>是输入特征的维度。由于这个例子较为简单，只是用历史的<code class="x-inline-highlight">y</code>值预测新的<code class="x-inline-highlight">y</code>值，因此特征只有<code class="x-inline-highlight">1</code>维。</p><h4 class="x-h3">什么时候 input_size 不是1？</h4><p class="x-p">例如我们在预测未来气温时，历史气温数据并不是唯一的参考，还可能参考历史的风速、气压、天气情况等等，此时输入数据将会是一个<code class="x-inline-highlight">input_size</code>维的向量。</p><h4 class="x-h3">hidden_size=12，12是在哪里体现的？</h4><p class="x-p"><code class="x-inline-highlight">12</code>只是模型的超参数，和MLP中隐藏层大小一样，并没有太多的物理含义。</p><h4 class="x-h3">训练时，每次迭代用哪些数据？应该遍历几遍数据集？每个 epoch 会使用哪些数据进行参数优化？</h4><p class="x-p">在训练一个CNN网络时（例如一个图片分类网络），策略通常是：</p><div class="x-oli"><div class="x-oli-number">1.</div><div class="x-oli-content-wrapper"><p>指定超参数<code class="x-inline-highlight">num_epoch</code>，在每个<code class="x-inline-highlight">epoch</code>中随机遍历训练集中的所有图像进行参数优化；</p></div></div><div class="x-oli"><div class="x-oli-number">2.</div><div class="x-oli-content-wrapper"><p>重复执行<code class="x-inline-highlight">num_epoch</code>次。</p></div></div><p class="x-p">然而对于RNN来说这个概念似乎并不清晰，例如上述例子的训练策略是：</p><div class="x-oli"><div class="x-oli-number">1.</div><div class="x-oli-content-wrapper"><p>从<code class="x-inline-highlight">0</code>到<code class="x-inline-highlight">(训练集大小 - 序列长度)</code>依次遍历起始时间<code class="x-inline-highlight">t</code>；</p></div></div><div class="x-oli"><div class="x-oli-number">2.</div><div class="x-oli-content-wrapper"><p>对于每个起始时间<code class="x-inline-highlight">t</code>，将<code class="x-inline-highlight">y[t]</code>~<code class="x-inline-highlight">y[t+9]</code>为输入，<code class="x-inline-highlight">y[t+10]</code>为真值作为一组训练样本。</p></div></div><div class="x-oli"><div class="x-oli-number">3.</div><div class="x-oli-content-wrapper"><p>第<code class="x-inline-highlight">1</code>步只遍历了一次！</p></div></div><p class="x-p">或者：</p><div class="x-oli"><div class="x-oli-number">1.</div><div class="x-oli-content-wrapper"><p>...</p></div></div><div class="x-oli"><div class="x-oli-number">2.</div><div class="x-oli-content-wrapper"><p>...</p></div></div><div class="x-oli"><div class="x-oli-number">3.</div><div class="x-oli-content-wrapper"><p>前两步同上，但多次遍历训练集。</p></div></div><p class="x-p">另一个常用的策略是：</p><div class="x-oli"><div class="x-oli-number">1.</div><div class="x-oli-content-wrapper"><p>指定超参数：训练轮次<code class="x-inline-highlight">num_iter</code>；</p></div></div><div class="x-oli"><div class="x-oli-number">2.</div><div class="x-oli-content-wrapper"><p>重复执行<code class="x-inline-highlight">num_iter</code>次，每次随机抽取一个起始时间<code class="x-inline-highlight">t</code>，并且将<code class="x-inline-highlight">y[t]</code>~<code class="x-inline-highlight">y[t+9]</code>为输入，<code class="x-inline-highlight">y[t+10]</code>为真值作为一组训练样本。</p></div></div><h2 class="x-h1">LSTM：一篇很好的博客</h2><p class="x-p">以下的内容和插图总结或翻译自这篇的英文博客：<a href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/" target="_blank" rel="noreferrer" class="x-inline-link">Understanding LSTM Networks</a></p><h3 class="x-h2">长期依赖问题</h3><p class="x-p">RNN可以利用先前的信息理解当前的任务，这点非常不错；有时我们只需要短期的信息，例如一个语言模型预测下面的句子：<br/><code class="x-inline-highlight">天空中飘着一朵白色的【云】</code>，这很简单。但有些时候我们需要更多背景信息，例如：<br/><code class="x-inline-highlight">我出生在法国，…… ，我可以说流利的【法语】</code>，这个情况下，随着前后文距离变大，RNN对长期依赖关系的学习会变得困难。</p><h3 class="x-h2">LSTM</h3><p class="x-p"><span class="x-inline-strong">长短期记忆网络</span><code class="x-inline-highlight">(Long Short-Term Memory, LSTM)</code>是一种特殊的RNN，可以学习长期依赖。以RNN为例，循环神经网络随时间展开通常具有如下的示意图：</p><img alt="img" loading="lazy" width="2242" height="839" decoding="async" data-nimg="1" class="x-image x-image-invert" style="color:transparent;width:600px;height:auto" src="/_next/static/media/rnn2.d1dd71bb.png"/><p class="x-p">对于RNN来说，利用历史状态和输入得到新的状态，只经过一个简单的<code class="x-inline-highlight">tanh</code>激活层，而对于LSTM来说，它的示意图略显复杂：</p><img alt="img" loading="lazy" width="2233" height="839" decoding="async" data-nimg="1" class="x-image x-image-invert" style="color:transparent;width:600px;height:auto" src="/_next/static/media/lstm1.83284ab3.png"/><p class="x-p">在上图中，每条线表示一个向量，粉红色圆圈表示逐点式操作，黄色的方框是神经网络的层。这看起来很眼晕，不过我们接下来会一点点的解释图里的内容。</p><h3 class="x-h2">门控单元</h3><p class="x-p">下面的结构称为门控单元：</p><img alt="img" loading="lazy" width="198" height="242" decoding="async" data-nimg="1" class="x-image x-image-invert" style="color:transparent;width:100px;height:auto" src="/_next/static/media/lstm2.96d0a9a3.png"/><p class="x-p">门控单元控制信息量通过的多少，通过向量<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span></span></span></span>来控制<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">x</span></span></span></span>通过的信息量：</p><div class="x-formula"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">o</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⊗</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">x</span></span></span></span></div><p class="x-p">式子中<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em;"></span><span class="mord">⊗</span></span></span></span>表示按位置相乘，<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mclose">)</span></span></span></span>的每个元素输出范围是<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">1</span><span class="mclose">]</span></span></span></span>，某个元素接近<code class="x-inline-highlight">1</code>，<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">x</span></span></span></span>对应位置保留的信息就越多，反之就越少。</p><h3 class="x-h2">逐部分分析LSTM</h3><h4 class="x-h3">遗忘门</h4><p class="x-p">LSTM的第一步是决定什么应该被遗忘，也就是对上一个<span class="x-inline-strong">单元</span><code class="x-inline-highlight">(cell)</code>状态信息选择性的遗忘。<br/>这个操作由遗忘门<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>实现，将其<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">1</span><span class="mclose">]</span></span></span></span>范围的输出按位置与单元上一时刻状态相乘。</p><img alt="img" loading="lazy" width="1826" height="564" decoding="async" data-nimg="1" class="x-image x-image-invert" style="color:transparent;width:600px;height:auto" src="/_next/static/media/lstm3.ac9b9ff5.png"/><div class="x-highlightblock highlight-background-gray"><p class="x-p">举一个概念性的例子：</p><p class="x-p">考虑一个语言模型，输入一个句子：<code class="x-inline-highlight">Alice是一名女教师，她喜欢给学生讲课；Bob是一位男司机，他喝酒上瘾。</code></p><p class="x-p">当模型看到<code class="x-inline-highlight">Alice是一名女教师，……</code>时，单元状态中可能存储了和主语<code class="x-inline-highlight">Alice</code>和<code class="x-inline-highlight">女教师</code>有关的语义信息，以便在后文输出合适的代词<code class="x-inline-highlight">她</code>；然后，当模型看到<code class="x-inline-highlight">Alice是一名女教师，她喜欢给学生讲课；Bob是一位男司机，……</code>时，我们希望在看到新主语<code class="x-inline-highlight">Bob</code>和<code class="x-inline-highlight">男司机</code>之后，忘记此前存储的旧主语的性别语义。也就是对旧单元状态<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8917em;vertical-align:-0.2083em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em;"><span></span></span></span></span></span></span></span></span></span>乘上较小的<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>。</p></div><h4 class="x-h3">输入门</h4><p class="x-p">下一步就是决定要在单元中存入什么新的信息。这一部分有两路：<code class="x-inline-highlight">tanh</code>这一路与普通RNN很像，生成一个中间状态；<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span></span></span></span>这一路被称为输入门<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8095em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，控制这个中间状态有多少信息被存入单元。</p><img alt="img" loading="lazy" width="1826" height="564" decoding="async" data-nimg="1" class="x-image x-image-invert" style="color:transparent;width:600px;height:auto" src="/_next/static/media/lstm4.00cef2df.png"/><p class="x-p">经历这两步之后，便可以相加得到新的单元状态：</p><img alt="img" loading="lazy" width="1826" height="564" decoding="async" data-nimg="1" class="x-image x-image-invert" style="color:transparent;width:600px;height:auto" src="/_next/static/media/lstm5.3f95c1ad.png"/><div class="x-highlightblock highlight-background-gray"><p class="x-p">同理，当模型看到<code class="x-inline-highlight">Bob是一位男司机</code>时，我们可能会想丢掉此前的语义信息<code class="x-inline-highlight">女性</code>，并把新的语义信息<code class="x-inline-highlight">男性</code>存入单元状态，使得后文输出正确的代词<code class="x-inline-highlight">他</code>。</p></div><h4 class="x-h3">输出门</h4><p class="x-p">最后是决定新的隐藏状态，这个输出会基于单元状态，但会经过门控单元。输出门<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">o</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>决定经过<code class="x-inline-highlight">tanh</code>的单元状态<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>有多少被输出到下一时刻的隐藏状态。</p><img alt="img" loading="lazy" width="1826" height="564" decoding="async" data-nimg="1" class="x-image x-image-invert" style="color:transparent;width:600px;height:auto" src="/_next/static/media/lstm6.7eca3c69.png"/><div class="x-highlightblock highlight-background-gray"><p class="x-p">当看到<code class="x-inline-highlight">Bob是一位男司机，他……</code>时，由于出现了主语<code class="x-inline-highlight">他</code>，模型可能会输出和<code class="x-inline-highlight">谓语动词</code>有关的语义信息。</p></div><!--/$--></div><div id="sidebar"><div id="sidebar-width-wrapper"><div class="category-card sidebar-card show-list"><div class="category-card-header"><div class="category-name">网络杂识<!-- --> (<!-- -->8<!-- -->)</div><button class="category-rightarrow"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 1024 1024"><path fill="#50505c" d="m761 532 2-3c9-18 6-40-10-55L400 140a48 48 0 0 0-66 70l317 299-316 305a48 48 0 0 0 67 69l350-338 1-2 2-1c3-3 4-7 6-10z"></path></svg></button></div><div class="category-card-ul-wrapper"><ul class="category-card-ul"><li><a class="link" href="/23d/database-3nf/"><span>数据库设计三大范式</span></a></li><li><a class="link" href="/23d/github-linguist-vendored/"><span>不统计Github仓库某个目录下的语言</span></a></li><li><a class="link" href="/24a/deepl-shortcut-setting/"><span>解决：DeepL该快捷键已被使用</span></a></li><li><a class="link" href="/24a/git-merge-allow-unrelated-histories/"><span>记录：使用--allow-unrelated-histories</span></a></li><li><a class="link" href="/24b/injective-surjective-bijective/"><span>单射、满射、双射</span></a></li><li><a class="link" href="/25a/tai-e-a2-additional-case/"><span>南京大学程序分析Lab2（常量传播）易错样例补充</span></a></li><li><a class="link" href="/25a/tai-e-a3-solution/"><span>南京大学程序分析Lab3（死代码消除）思路</span></a></li><li><a class="link" href="/25b/debug-x86_64-program-in-arm64-system/"><span>使用QEMU在ARM64系统上调试x86_64程序</span></a></li></ul></div></div><div class="category-card sidebar-card show-list"><div class="category-card-header"><div class="category-name">安全学习<!-- --> (<!-- -->13<!-- -->)</div><button class="category-rightarrow"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 1024 1024"><path fill="#50505c" d="m761 532 2-3c9-18 6-40-10-55L400 140a48 48 0 0 0-66 70l317 299-316 305a48 48 0 0 0 67 69l350-338 1-2 2-1c3-3 4-7 6-10z"></path></svg></button></div><div class="category-card-ul-wrapper"><ul class="category-card-ul"><li><a class="link" href="/longtime/wp-portswigger/"><span>PortSwigger Writeup</span></a></li><li><a class="link" href="/23d/hust-cas-login/"><span>Python登录华科统一身份认证接口</span></a></li><li><a class="link" href="/24b/learn-cwes/"><span>Learn CWEs &amp; Real-word Examples</span></a></li><li><a class="link" href="/24b/cross-site-scripting/"><span>Learn XSS</span></a></li><li><a class="link" href="/24b/cross-site-request-forgery/"><span>Learn CSRF</span></a></li><li><a class="link" href="/24d/wp-bluehens-2024/"><span>BlueHens CTF 2024 Writeup</span></a></li><li><a class="link" href="/24d/wp-1337uplive-2024/"><span>1337UP LIVE CTF 2024 Writeup</span></a></li><li><a class="link" href="/24d/wp-m0lecon-2025/"><span>m0leCon Beginner CTF 2025 Writeup</span></a></li><li><a class="link" href="/24d/wp-0xl4ugh-2024/"><span>0xl4ugh CTF 2024 Writeup</span></a></li><li><a class="link" href="/25a/wp-nullcon-hackim-2025/"><span>Nullcon HackIM CTF 2025 Writeup</span></a></li><li><a class="link" href="/25a/wp-picoctf-2025/"><span>picoCTF 2025 Writeup</span></a></li><li><a class="link" href="/25a/wp-cyber-apocalypse-ctf-2025/"><span>HTB Cyber Apocalypse CTF 2025 Writeup</span></a></li><li><a class="link" href="/25a/wp-swampctf-2025/"><span>SwampCTF 2025 Writeup</span></a></li></ul></div></div><div class="category-card sidebar-card show-list"><div class="category-card-header"><div class="category-name">安全研究<!-- --> (<!-- -->10<!-- -->)</div><button class="category-rightarrow"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 1024 1024"><path fill="#50505c" d="m761 532 2-3c9-18 6-40-10-55L400 140a48 48 0 0 0-66 70l317 299-316 305a48 48 0 0 0 67 69l350-338 1-2 2-1c3-3 4-7 6-10z"></path></svg></button></div><div class="category-card-ul-wrapper"><ul class="category-card-ul"><li><a class="link" href="/longtime/papers-sec/"><span>论文速记：安全</span></a></li><li><a class="link" href="/24b/papers-sec-240514-taintmini/"><span>论文阅读：TAINTMINI: Detecting Flow of Sensitive Data in Mini-Programs with Static Taint Analysis (ICSE 2023)</span></a></li><li><a class="link" href="/24c/papers-sec-240728-2fa-consistency/"><span>论文阅读：A Systematic Study of the Consistency of Two-Factor Authentication User Journeys on Top-Ranked Websites (NDSS 2023)</span></a></li><li><a class="link" href="/24c/papers-sec-240810-conquer/"><span>论文阅读：Do Not Give A Dog Bread Every Time He Wags His Tail: Stealing Passwords through Content Queries (CONQUER) Attack (NDSS 2023)</span></a></li><li><a class="link" href="/24c/papers-sec-240817-2fa-failures/"><span>论文阅读：Security and Privacy Failures in Popular 2FA Apps (Security 2023)</span></a></li><li><a class="link" href="/24c/papers-sec-240824-zxcvbn/"><span>论文阅读：zxcvbn: Low-Budget Password Strength Estimation (Security 2016)</span></a></li><li><a class="link" href="/24c/papers-sec-240902-pafa-authentication/"><span>论文阅读：Maginot Line: Assessing a New Cross-app Threat to PII-as-Factor Authentication in Chinese Mobile Apps (NDSS 2024)</span></a></li><li><a class="link" href="/24c/papers-sec-240922-pre-hijacked-accounts/"><span>论文阅读：Pre-hijacked accounts: An Empirical Study of Security Failures in User Account Creation on the Web (Security 2022)</span></a></li><li><a class="link" href="/24d/papers-sec-241207-aimie/"><span>论文阅读：Understanding and Detecting Abused Image Hosting Modules as Malicious Services (CCS 2023)</span></a></li><li><a class="link" href="/25a/papers-sec-250225-minitracker/"><span>论文阅读：MiniTracker: Large-Scale Sensitive Information Tracking in Mini Apps (TDSC 2023)</span></a></li></ul></div></div><div class="category-card sidebar-card show-list"><div class="category-card-header"><div class="category-name">算法<!-- --> (<!-- -->26<!-- -->)</div><button class="category-rightarrow"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 1024 1024"><path fill="#50505c" d="m761 532 2-3c9-18 6-40-10-55L400 140a48 48 0 0 0-66 70l317 299-316 305a48 48 0 0 0 67 69l350-338 1-2 2-1c3-3 4-7 6-10z"></path></svg></button></div><div class="category-card-ul-wrapper"><ul class="category-card-ul"><li><a class="link" href="/24b/sorting-algorithm/"><span>排序算法总结与代码实现</span></a></li><li><a class="link" href="/24b/mst-and-sp/"><span>最小生成树与最短路算法</span></a></li><li><a class="link" href="/24a/csp-2016-04/"><span>CSP 201604 T1-T4题解</span></a></li><li><a class="link" href="/24a/csp-2018-03/"><span>CSP 201803 T1-T4题解</span></a></li><li><a class="link" href="/24a/csp-2020-06/"><span>CSP 202006 T1-T4题解</span></a></li><li><a class="link" href="/24a/csp-2020-09/"><span>CSP 202009 T1-T4题解</span></a></li><li><a class="link" href="/24a/csp-2020-12/"><span>CSP 202012 T1-T5题解</span></a></li><li><a class="link" href="/24a/csp-2022-06/"><span>CSP 202206 T1-T5题解</span></a></li><li><a class="link" href="/24a/csp-2023-05/"><span>CSP 202305 T1-T5题解</span></a></li><li><a class="link" href="/24a/csp-2023-09/"><span>CSP 202309 T1-T4题解</span></a></li><li><a class="link" href="/24b/leetcode-4/"><span>LeetCode 4.寻找两个正序数组的中位数</span></a></li><li><a class="link" href="/24b/leetcode-30/"><span>LeetCode 30.串联所有单词的子串</span></a></li><li><a class="link" href="/24b/leetcode-37/"><span>LeetCode 37.解数独</span></a></li><li><a class="link" href="/24c/leetcode-42/"><span>LeetCode 42.接雨水</span></a></li><li><a class="link" href="/24c/leetcode-51/"><span>LeetCode 51.N皇后</span></a></li><li><a class="link" href="/24c/leetcode-52/"><span>LeetCode 52.N皇后 II</span></a></li><li><a class="link" href="/24b/leetcode-60/"><span>LeetCode 60.排列序列</span></a></li><li><a class="link" href="/24b/leetcode-65/"><span>LeetCode 65.有效数字</span></a></li><li><a class="link" href="/24c/leetcode-68/"><span>LeetCode 68.文本左右对齐</span></a></li><li><a class="link" href="/24b/leetcode-84/"><span>LeetCode 84.柱状图中最大的矩形</span></a></li><li><a class="link" href="/24c/leetcode-85/"><span>LeetCode 85.最大矩形</span></a></li><li><a class="link" href="/24c/leetcode-149/"><span>LeetCode 149.直线上最多的点数</span></a></li><li><a class="link" href="/24d/leetcode-282/"><span>LeetCode 282.给表达式添加运算符</span></a></li><li><a class="link" href="/24b/leetcode-312/"><span>LeetCode 312.戳气球</span></a></li><li><a class="link" href="/24b/leetcode-1373/"><span>LeetCode 1373.二叉搜索子树的最大键值和</span></a></li><li><a class="link" href="/24b/leetcode-1739/"><span>LeetCode 1739.放置盒子</span></a></li></ul></div></div><div class="category-card sidebar-card show-list"><div class="category-card-header"><div class="category-name">深度学习<!-- --> (<!-- -->8<!-- -->)</div><button class="category-rightarrow"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 1024 1024"><path fill="#50505c" d="m761 532 2-3c9-18 6-40-10-55L400 140a48 48 0 0 0-66 70l317 299-316 305a48 48 0 0 0 67 69l350-338 1-2 2-1c3-3 4-7 6-10z"></path></svg></button></div><div class="category-card-ul-wrapper"><ul class="category-card-ul"><li><a class="link" href="/longtime/papers-dl/"><span>论文速记：深度学习</span></a></li><li><a class="link" href="/23d/r2plus1d/"><span>行为识别R(2+1)D网络</span></a></li><li><a class="link" href="/23d/object-detection-map/"><span>目标检测评价指标mAP</span></a></li><li><a class="link active" href="/23d/learn-rnn-lstm/"><span>学习RNN和LSTM</span></a></li><li><a class="link" href="/24a/reproduce-nerf-rpn/"><span>记录：复现NeRF-RPN代码</span></a></li><li><a class="link" href="/24b/yolov5-obb-nms-rotated/"><span>解决：nms_rotated报错&quot;THC/THC.h&quot;: No such file or directory</span></a></li><li><a class="link" href="/24c/winograd/"><span>Winograd算法</span></a></li><li><a class="link" href="/24c/model-optimization/"><span>模型优化概述：量化、压缩、轻量化</span></a></li></ul></div></div><div class="category-card sidebar-card show-list"><div class="category-card-header"><div class="category-name">编程语言<!-- --> (<!-- -->5<!-- -->)</div><button class="category-rightarrow"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 1024 1024"><path fill="#50505c" d="m761 532 2-3c9-18 6-40-10-55L400 140a48 48 0 0 0-66 70l317 299-316 305a48 48 0 0 0 67 69l350-338 1-2 2-1c3-3 4-7 6-10z"></path></svg></button></div><div class="category-card-ul-wrapper"><ul class="category-card-ul"><li><a class="link" href="/23c/js-array/"><span>JavaScript数组常用方法</span></a></li><li><a class="link" href="/24a/cpp-stl/"><span>C++中STL的基本使用</span></a></li><li><a class="link" href="/24a/torch-numpy-topk/"><span>在pytorch和numpy中取top-k值和索引</span></a></li><li><a class="link" href="/24a/object-oriented-programming-python/"><span>Python面向对象编程</span></a></li><li><a class="link" href="/24c/asm8086-snake/"><span>8086汇编贪吃蛇</span></a></li></ul></div></div><div class="category-card sidebar-card show-list"><div class="category-card-header"><div class="category-name">前端<!-- --> (<!-- -->2<!-- -->)</div><button class="category-rightarrow"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 1024 1024"><path fill="#50505c" d="m761 532 2-3c9-18 6-40-10-55L400 140a48 48 0 0 0-66 70l317 299-316 305a48 48 0 0 0 67 69l350-338 1-2 2-1c3-3 4-7 6-10z"></path></svg></button></div><div class="category-card-ul-wrapper"><ul class="category-card-ul"><li><a class="link" href="/23d/css-auto-height-transition/"><span>CSS实现auto高度的过渡动画</span></a></li><li><a class="link" href="/24d/android-send-explicit-intent-to-dynamically-registered-receiver/"><span>不能向动态注册的广播接收器发送显式Intent</span></a></li></ul></div></div><div class="category-card sidebar-card show-list"><div class="category-card-header"><div class="category-name">课程笔记<!-- --> (<!-- -->19<!-- -->)</div><button class="category-rightarrow"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 1024 1024"><path fill="#50505c" d="m761 532 2-3c9-18 6-40-10-55L400 140a48 48 0 0 0-66 70l317 299-316 305a48 48 0 0 0 67 69l350-338 1-2 2-1c3-3 4-7 6-10z"></path></svg></button></div><div class="category-card-ul-wrapper"><ul class="category-card-ul"><li><a class="link" href="/24b/rank-inequality/"><span>【线性代数】对秩不等式的理解</span></a></li><li><a class="link" href="/23c/pattern-recognition-1/"><span>【模式识别】统计决策方法</span></a></li><li><a class="link" href="/23c/pattern-recognition-2/"><span>【模式识别】参数估计</span></a></li><li><a class="link" href="/23c/pattern-recognition-3/"><span>【模式识别】非参数估计</span></a></li><li><a class="link" href="/23d/pattern-recognition-4/"><span>【模式识别】线性学习器与线性分类器</span></a></li><li><a class="link" href="/23d/protocols/"><span>【计算机网络】协议总结</span></a></li><li><a class="link" href="/24a/machine-learning-exercises/"><span>【机器学习】习题</span></a></li><li><a class="link" href="/24a/games101-01-transformation/"><span>【GAMES101】Transformation</span></a></li><li><a class="link" href="/24a/games101-02-rasterization/"><span>【GAMES101】Rasterization</span></a></li><li><a class="link" href="/24a/games101-03-shading/"><span>【GAMES101】Shading</span></a></li><li><a class="link" href="/24a/games101-04-geometry/"><span>【GAMES101】Geometry</span></a></li><li><a class="link" href="/24c/assembly-1/"><span>【汇编语言】访问寄存器和内存</span></a></li><li><a class="link" href="/24c/assembly-2/"><span>【汇编语言】汇编语言编程</span></a></li><li><a class="link" href="/24c/assembly-3/"><span>【汇编语言】内存寻址方式</span></a></li><li><a class="link" href="/24c/assembly-4/"><span>【汇编语言】流程转移与子程序</span></a></li><li><a class="link" href="/24c/assembly-5/"><span>【汇编语言】标志寄存器</span></a></li><li><a class="link" href="/24c/assembly-6/"><span>【汇编语言】中断及外部设备操作</span></a></li><li><a class="link" href="/24d/crypto-1/"><span>【密码学】流密码</span></a></li><li><a class="link" href="/24d/crypto-2/"><span>【密码学】块密码</span></a></li></ul></div></div><div class="category-card sidebar-card show-list"><div class="category-card-header"><div class="category-name">杂记<!-- --> (<!-- -->4<!-- -->)</div><button class="category-rightarrow"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 1024 1024"><path fill="#50505c" d="m761 532 2-3c9-18 6-40-10-55L400 140a48 48 0 0 0-66 70l317 299-316 305a48 48 0 0 0 67 69l350-338 1-2 2-1c3-3 4-7 6-10z"></path></svg></button></div><div class="category-card-ul-wrapper"><ul class="category-card-ul"><li><a class="link" href="/24b/by-questions/"><span>专业课复习</span></a></li><li><a class="link" href="/24d/about-interactive-multimedia/"><span>关于交互式多媒体</span></a></li><li><a class="link" href="/longtime/hundred-thousand/"><span>十万</span></a></li><li><a class="link" href="/longtime/linux-commands/"><span>三开</span></a></li></ul></div></div><div class="category-card sidebar-card show-list"><div class="category-card-header"><div class="category-name">交互式多媒体<!-- --> (<!-- -->3<!-- -->)</div><button class="category-rightarrow"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 1024 1024"><path fill="#50505c" d="m761 532 2-3c9-18 6-40-10-55L400 140a48 48 0 0 0-66 70l317 299-316 305a48 48 0 0 0 67 69l350-338 1-2 2-1c3-3 4-7 6-10z"></path></svg></button></div><div class="category-card-ul-wrapper"><ul class="category-card-ul"><li><a class="link" href="/24d/about-interactive-multimedia/"><span>关于交互式多媒体</span></a></li><li><a class="link" href="/23c/pattern-recognition-1/"><span>【模式识别】统计决策方法</span></a></li><li><a class="link" href="/23d/css-auto-height-transition/"><span>CSS实现auto高度的过渡动画</span></a></li></ul></div></div></div></div><div id="sidebar-mask"></div></div><script src="/_next/static/chunks/webpack-e16bca635fd7f9f0.js" crossorigin="" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0]);self.__next_f.push([2,null])</script><script>self.__next_f.push([1,"1:HL[\"/_next/static/css/cd6b648520195f61.css\",\"style\",{\"crossOrigin\":\"\"}]\n0:\"$L2\"\n"])</script><script>self.__next_f.push([1,"3:HL[\"/_next/static/css/9ae4a866c3254b07.css\",\"style\",{\"crossOrigin\":\"\"}]\n"])</script><script>self.__next_f.push([1,"4:I[47690,[],\"\"]\n6:I[55329,[\"481\",\"static/chunks/457b8330-b5c9cf3fcf214847.js\",\"954\",\"static/chunks/d3ac728e-0c798b3b8aa3bf53.js\",\"250\",\"static/chunks/250-0ef8476c0fa8ee24.js\",\"612\",\"static/chunks/612-fa632c1349770315.js\",\"551\",\"static/chunks/551-19232c47cd1e883a.js\",\"877\",\"static/chunks/app/%5B...slug%5D/page-d4a52f9ce8b82efb.js\"],\"\"]\n7:I[86510,[\"481\",\"static/chunks/457b8330-b5c9cf3fcf214847.js\",\"250\",\"static/chunks/250-0ef8476c0fa8ee24.js\",\"612\",\"static/chunks/612-fa632c1349770315.js\",\"931\",\"static/chunks/app/page-53cc083014f9456b.js\"],\"PostMeta\"]\n8:\"$Sreact.suspense\"\na:I[30389,[\"481\",\"static/chunks/457b8330-b5c9cf3fcf214847.js\",\"954\",\"static/chunks/d3ac728e-0c798b3b8aa3bf53.js\",\"250\",\"static/chunks/250-0ef8476c0fa8ee24.js\",\"612\",\"static/chunks/612-fa632c1349770315.js\",\"551\",\"static/chunks/551-19232c47cd1e883a.js\",\"877\",\"static/chunks/app/%5B...slug%5D/page-d4a52f9ce8b82efb.js\"],\"\"]\nb:I[5613,[],\"\"]\nd:I[31778,[],\"\"]\ne:I[25694,[\"250\",\"static/chunks/250-0ef8476c0fa8ee24.js\",\"185\",\"static/chunks/app/layout-d8cba6107e479473.js\"],\"GlobalProvider\"]\nf:I[30397,[\"250\",\"static/chunks/250-0ef8476c0fa8ee24.js\",\"185\",\"static/chunks/app/layout-d8cba6107e479473.js\"],\"\"]\n11:I[48955,[],\"\"]\nc:[\"slug\",\"23d/learn-rnn-lstm\",\"c\"]\n12:[]\n"])</script><script>self.__next_f.push([1,"2:[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/cd6b648520195f61.css\",\"precedence\":\"next\",\"crossOrigin\":\"\"}]],[\"$\",\"$L4\",null,{\"buildId\":\"T4ziINvC4qyuYfecqz90F\",\"assetPrefix\":\"\",\"initialCanonicalUrl\":\"/23d/learn-rnn-lstm/\",\"initialTree\":[\"\",{\"children\":[[\"slug\",\"23d/learn-rnn-lstm\",\"c\"],{\"children\":[\"__PAGE__?{\\\"slug\\\":[\\\"23d\\\",\\\"learn-rnn-lstm\\\"]}\",{}]}]},\"$undefined\",\"$undefined\",true],\"initialSeedData\":[\"\",{\"children\":[[\"slug\",\"23d/learn-rnn-lstm\",\"c\"],{\"children\":[\"__PAGE__\",{},[\"$L5\",[[\"$\",\"$L6\",null,{}],[\"$\",\"div\",null,{\"id\":\"post-layout\",\"children\":[false,[\"$\",\"div\",null,{\"id\":\"main\",\"className\":\"center-wrapper\",\"children\":[[\"$\",\"h1\",null,{\"className\":\"post-title\",\"children\":\"学习RNN和LSTM\"}],[\"$\",\"$L7\",null,{\"path\":\"/23d/learn-rnn-lstm/\"}],[\"$\",\"$8\",null,{\"fallback\":[\"$\",\"p\",null,{\"children\":\"Loading component...\"}],\"children\":\"$L9\"}]]}],[\"$\",\"$La\",null,{}]]}]],null]]},[\"$\",\"$Lb\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"$c\",\"children\"],\"loading\":\"$undefined\",\"loadingStyles\":\"$undefined\",\"loadingScripts\":\"$undefined\",\"hasLoading\":false,\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$Ld\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"styles\":[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/9ae4a866c3254b07.css\",\"precedence\":\"next\",\"crossOrigin\":\"\"}]]}]]},[null,[\"$\",\"html\",null,{\"lang\":\"zh-CN\",\"suppressHydrationWarning\":true,\"children\":[[\"$\",\"head\",null,{\"children\":[[\"$\",\"link\",null,{\"rel\":\"icon\",\"href\":\"/favicon.ico\",\"type\":\"image/x-icon\"}],[\"$\",\"script\",null,{\"async\":true,\"src\":\"https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js\"}],[\"$\",\"script\",null,{\"async\":true,\"src\":\"https://www.googletagmanager.com/gtag/js?id=G-45BYSZ6WPY\"}],[\"$\",\"script\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"\\nwindow.dataLayer = window.dataLayer || [];\\nfunction gtag() {\\n    dataLayer.push(arguments);\\n}\\ngtag('js', new Date());\\ngtag('config', 'G-45BYSZ6WPY');\\n\"}}],[\"$\",\"script\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"const a=z=\u003eh.getItem(z),b=(y,z)=\u003eh.setItem(y,z),c=(y,z)=\u003edocument.documentElement.setAttribute(y,z),d='theme',e='dark',f='light',g='class',h=localStorage;a(d)!==e\u0026\u0026a(d)!==f\u0026\u0026b(d,f);a(d)===e?c(g,e):c(g,f);\"}}],[\"$\",\"script\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"\\nif (!Array.prototype.findLast) {\\n    Array.prototype.findLast = function (callback) {\\n        for (let i = this.length - 1; i \u003e= 0; i--) {\\n            if (callback(this[i])) return this[i];\\n        }\\n        return undefined;\\n    };\\n}\\nif (!Array.prototype.findLastIndex) {\\n    Array.prototype.findLastIndex = function (callback) {\\n        for (let i = this.length - 1; i \u003e= 0; i--) {\\n            if (callback(this[i])) return i;\\n        }\\n        return -1;\\n    };\\n}\\n\"}}]]}],[\"$\",\"body\",null,{\"children\":[\"$\",\"$Le\",null,{\"children\":[[\"$\",\"$Lf\",null,{}],[\"$\",\"$Lb\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"loading\":\"$undefined\",\"loadingStyles\":\"$undefined\",\"loadingScripts\":\"$undefined\",\"hasLoading\":false,\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$Ld\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[\"$\",\"div\",null,{\"id\":\"notfound\",\"children\":[[\"$\",\"img\",null,{\"alt\":\"img\",\"src\":\"/images/cry.gif\"}],[\"$\",\"code\",null,{\"id\":\"notfound-404\",\"children\":\"404\"}],[\"$\",\"code\",null,{\"id\":\"notfound-text\",\"children\":\"Page Not Found\"}]]}],\"notFoundStyles\":[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/98e601cf5ba3633d.css\",\"precedence\":\"next\",\"crossOrigin\":\"\"}]],\"styles\":null}]]}]}]]}],null]],\"initialHead\":[false,\"$L10\"],\"globalErrorComponent\":\"$11\",\"missingSlots\":\"$W12\"}]]\n"])</script><script>self.__next_f.push([1,"13:I[74365,[\"481\",\"static/chunks/457b8330-b5c9cf3fcf214847.js\",\"954\",\"static/chunks/d3ac728e-0c798b3b8aa3bf53.js\",\"250\",\"static/chunks/250-0ef8476c0fa8ee24.js\",\"612\",\"static/chunks/612-fa632c1349770315.js\",\"551\",\"static/chunks/551-19232c47cd1e883a.js\",\"877\",\"static/chunks/app/%5B...slug%5D/page-d4a52f9ce8b82efb.js\"],\"\"]\n14:I[62029,[\"481\",\"static/chunks/457b8330-b5c9cf3fcf214847.js\",\"954\",\"static/chunks/d3ac728e-0c798b3b8aa3bf53.js\",\"250\",\"static/chunks/250-0ef8476c0fa8ee24.js\",\"612\",\"static/chunks/612-fa632c1349770315.js\",\"551\",\"static/chunks/551-19232c47cd1e883a.js\",\"877\",\"static/chunks/app/%5B...slug%5D/page-d4a52f9ce8b82efb.js\"],\"\"]\n15:T88c,"])</script><script>self.__next_f.push([1,"\u003cspan class=\"token keyword\"\u003eimport\u003c/span\u003e numpy\n\u003cspan class=\"token keyword\"\u003eimport\u003c/span\u003e torch\n\u003cspan class=\"token keyword\"\u003efrom\u003c/span\u003e torch \u003cspan class=\"token keyword\"\u003eimport\u003c/span\u003e nn\n\u003cspan class=\"token keyword\"\u003eimport\u003c/span\u003e matplotlib\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003epyplot \u003cspan class=\"token keyword\"\u003eas\u003c/span\u003e plt\n\n\u003cspan class=\"token comment\"\u003e#生成加噪声的正弦序列数据\u003c/span\u003e\nxlim\u003cspan class=\"token operator\"\u003e=\u003c/span\u003enumpy\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003elinspace\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token number\"\u003e0\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e\u003cspan class=\"token number\"\u003e36\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e\u003cspan class=\"token number\"\u003e400\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\ny\u003cspan class=\"token operator\"\u003e=\u003c/span\u003enumpy\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003esin\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003exlim\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token operator\"\u003e+\u003c/span\u003enumpy\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003erandom\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003erand\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token operator\"\u003e*\u003c/span\u003exlim\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eshape\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token operator\"\u003e*\u003c/span\u003e\u003cspan class=\"token number\"\u003e0.2\u003c/span\u003e\n\n\u003cspan class=\"token comment\"\u003e#转换dtype和size，保持和后面的训练数据统一\u003c/span\u003e\ny\u003cspan class=\"token operator\"\u003e=\u003c/span\u003ey\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003ereshape\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token operator\"\u003e-\u003c/span\u003e\u003cspan class=\"token number\"\u003e1\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e\u003cspan class=\"token number\"\u003e1\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eastype\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"float32\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\nplt\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eplot\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003exlim\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003ey\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\nplt\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eshow\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n"])</script><script>self.__next_f.push([1,"16:T113e,"])</script><script>self.__next_f.push([1,"\u003cspan class=\"token keyword\"\u003eclass\u003c/span\u003e \u003cspan class=\"token class-name\"\u003eMyRNN\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003enn\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eModule\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n    \u003cspan class=\"token keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"token function\"\u003e__init__\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eself\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003einput_size\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003ehidden_size\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003eoutput_size\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"token builtin\"\u003esuper\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003e__init__\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n        self\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003elinear_ih\u003cspan class=\"token operator\"\u003e=\u003c/span\u003enn\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eLinear\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003einput_size\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003ehidden_size\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n        self\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003elinear_hh\u003cspan class=\"token operator\"\u003e=\u003c/span\u003enn\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eLinear\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003ehidden_size\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003ehidden_size\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n        self\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003elinear_ho\u003cspan class=\"token operator\"\u003e=\u003c/span\u003enn\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eLinear\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003ehidden_size\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003eoutput_size\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n        self\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003etanh\u003cspan class=\"token operator\"\u003e=\u003c/span\u003enn\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eTanh\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"token keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"token function\"\u003eforward\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eself\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003ex\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003eprev_state\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n        curr_state\u003cspan class=\"token operator\"\u003e=\u003c/span\u003eself\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003etanh\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\n            self\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003elinear_ih\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003ex\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token operator\"\u003e+\u003c/span\u003eself\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003elinear_hh\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eprev_state\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n        \u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n        output\u003cspan class=\"token operator\"\u003e=\u003c/span\u003eself\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003elinear_ho\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003ecurr_state\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003ereshape\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token number\"\u003e1\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n        \u003cspan class=\"token keyword\"\u003ereturn\u003c/span\u003e output\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003ecurr_state\n\nhidden_size\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token number\"\u003e12\u003c/span\u003e\nmy_rnn\u003cspan class=\"token operator\"\u003e=\u003c/span\u003eMyRNN\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003einput_size\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token number\"\u003e1\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003ehidden_size\u003cspan class=\"token operator\"\u003e=\u003c/span\u003ehidden_size\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003eoutput_size\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token number\"\u003e1\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\nloss_func\u003cspan class=\"token operator\"\u003e=\u003c/span\u003enn\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eMSELoss\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\noptimizer\u003cspan class=\"token operator\"\u003e=\u003c/span\u003etorch\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eoptim\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eSGD\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003emy_rnn\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eparameters\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003elr\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token number\"\u003e0.01\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n"])</script><script>self.__next_f.push([1,"17:T80b,"])</script><script>self.__next_f.push([1,"\u003cspan class=\"token keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"token function\"\u003etrain\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003etrain_seq\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003etarget\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n    \u003cspan class=\"token comment\"\u003e#初始状态\u003c/span\u003e\n    state\u003cspan class=\"token operator\"\u003e=\u003c/span\u003etorch\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003ezeros\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token number\"\u003e1\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003ehidden_size\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\n    \u003cspan class=\"token keyword\"\u003efor\u003c/span\u003e x \u003cspan class=\"token keyword\"\u003ein\u003c/span\u003e train_seq\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n        output\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003estate\u003cspan class=\"token operator\"\u003e=\u003c/span\u003emy_rnn\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003ex\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003estate\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\n    loss\u003cspan class=\"token operator\"\u003e=\u003c/span\u003eloss_func\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eoutput\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003etarget\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n    optimizer\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003ezero_grad\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n    loss\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003ebackward\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n    optimizer\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003estep\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\n    \u003cspan class=\"token comment\"\u003e#返回损失\u003c/span\u003e\n    \u003cspan class=\"token keyword\"\u003ereturn\u003c/span\u003e loss\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003edetach\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003enumpy\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003ereshape\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token number\"\u003e1\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n"])</script><script>self.__next_f.push([1,"18:T5c4,train_datas\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e[\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e]\u003c/span\u003e\n\u003cspan class=\"token keyword\"\u003efor\u003c/span\u003e i \u003cspan class=\"token keyword\"\u003ein\u003c/span\u003e \u003cspan class=\"token builtin\"\u003erange\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token number\"\u003e320\u003c/span\u003e\u003cspan class=\"token operator\"\u003e-\u003c/span\u003e\u003cspan class=\"token number\"\u003e10\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n    train_seq\u003cspan class=\"token operator\"\u003e=\u003c/span\u003etorch\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003efrom_numpy\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003ey\u003cspan class=\"token punctuation\"\u003e[\u003c/span\u003ei\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003ei\u003cspan class=\"token operator\"\u003e+\u003c/span\u003e\u003cspan class=\"token number\"\u003e10\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e]\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n    target\u003cspan class=\"token operator\"\u003e=\u003c/span\u003etorch\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003efrom_numpy\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003ey\u003cspan class=\"token punctuation\"\u003e[\u003c/span\u003ei\u003cspan class=\"token operator\"\u003e+\u003c/span\u003e\u003cspan class=\"token number\"\u003e10\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e]\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n    train_datas\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eappend\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003etrain_seq\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003etarget\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n19:T52e,metrics\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e[\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e]\u003c/span\u003e\nmy_rnn\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003etrain\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\u003cspan class=\"token keyword\"\u003efor\u003c/span\u003e train_seq\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003etarget \u003cspan class=\"token keyword\"\u003ein\u003c/span\u003e train_datas\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n    loss\u003cspan class=\"token operator\"\u003e=\u003c/span\u003etrain\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003etrain_seq\u003cspan class=\"to"])</script><script>self.__next_f.push([1,"ken punctuation\"\u003e,\u003c/span\u003etarget\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n    metrics\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eappend\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eloss\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\nplt\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003esubplot\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token number\"\u003e211\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\nplt\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eplot\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003emetrics\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003elabel\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"loss\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\nplt\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003elegend\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n1a:T1086,"])</script><script>self.__next_f.push([1,"\u003cspan class=\"token keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"token function\"\u003epred\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003etruth_seq\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n    \u003cspan class=\"token keyword\"\u003ewith\u003c/span\u003e torch\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eno_grad\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n        state\u003cspan class=\"token operator\"\u003e=\u003c/span\u003etorch\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003ezeros\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token number\"\u003e1\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003ehidden_size\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n        \u003cspan class=\"token keyword\"\u003efor\u003c/span\u003e x \u003cspan class=\"token keyword\"\u003ein\u003c/span\u003e truth_seq\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n            output\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003estate\u003cspan class=\"token operator\"\u003e=\u003c/span\u003emy_rnn\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003ex\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003estate\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n        \u003cspan class=\"token keyword\"\u003ereturn\u003c/span\u003e output\n\npreds\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e[\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e]\u003c/span\u003e\n\u003cspan class=\"token keyword\"\u003efor\u003c/span\u003e i \u003cspan class=\"token keyword\"\u003ein\u003c/span\u003e \u003cspan class=\"token builtin\"\u003erange\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token number\"\u003e320\u003c/span\u003e\u003cspan class=\"token operator\"\u003e-\u003c/span\u003e\u003cspan class=\"token number\"\u003e10\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e\u003cspan class=\"token number\"\u003e400\u003c/span\u003e\u003cspan class=\"token operator\"\u003e-\u003c/span\u003e\u003cspan class=\"token number\"\u003e10\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n    truth_seq\u003cspan class=\"token operator\"\u003e=\u003c/span\u003etorch\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003efrom_numpy\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003ey\u003cspan class=\"token punctuation\"\u003e[\u003c/span\u003ei\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003ei\u003cspan class=\"token operator\"\u003e+\u003c/span\u003e\u003cspan class=\"token number\"\u003e10\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e]\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n    preds\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eappend\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003epred\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003etruth_seq\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003enumpy\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\npreds\u003cspan class=\"token operator\"\u003e=\u003c/span\u003enumpy\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003earray\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003epreds\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003ereshape\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token operator\"\u003e-\u003c/span\u003e\u003cspan class=\"token number\"\u003e1\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e\u003cspan class=\"token number\"\u003e1\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\nplt\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003esubplot\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token number\"\u003e212\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\nplt\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eplot\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003exlim\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003ey\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003elabel\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"truth\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\nplt\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eplot\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003exlim\u003cspan class=\"token punctuation\"\u003e[\u003c/span\u003e\u003cspan class=\"token number\"\u003e320\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\u003cspan class=\"token number\"\u003e400\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e]\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003epreds\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"red\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003elabel\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"predict\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\nplt\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003elegend\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\nplt\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eshow\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n"])</script><script>self.__next_f.push([1,"1b:Tcae,"])</script><script>self.__next_f.push([1,"\u003cspan class=\"token keyword\"\u003eclass\u003c/span\u003e \u003cspan class=\"token class-name\"\u003eMyRNN\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003enn\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eModule\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n    \u003cspan class=\"token keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"token function\"\u003e__init__\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eself\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003einput_size\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003ehidden_size\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003eoutput_size\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"token builtin\"\u003esuper\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003e__init__\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n        self\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003elinear_ih\u003cspan class=\"token operator\"\u003e=\u003c/span\u003enn\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eLinear\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003einput_size\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003ehidden_size\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n        self\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003elinear_hh\u003cspan class=\"token operator\"\u003e=\u003c/span\u003enn\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eLinear\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003ehidden_size\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003ehidden_size\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n        self\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003elinear_ho\u003cspan class=\"token operator\"\u003e=\u003c/span\u003enn\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eLinear\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003ehidden_size\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003eoutput_size\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n        self\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003etanh\u003cspan class=\"token operator\"\u003e=\u003c/span\u003enn\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eTanh\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"token keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"token function\"\u003eforward\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eself\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003ex\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003eprev_state\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n        curr_state\u003cspan class=\"token operator\"\u003e=\u003c/span\u003eself\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003etanh\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\n            self\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003elinear_ih\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003ex\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token operator\"\u003e+\u003c/span\u003eself\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003elinear_hh\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eprev_state\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n        \u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n        output\u003cspan class=\"token operator\"\u003e=\u003c/span\u003eself\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003elinear_ho\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003ecurr_state\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003ereshape\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token number\"\u003e1\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n        \u003cspan class=\"token keyword\"\u003ereturn\u003c/span\u003e output\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003ecurr_state\n"])</script><script>self.__next_f.push([1,"1c:Tb25,"])</script><script>self.__next_f.push([1,"\u003cspan class=\"token keyword\"\u003eclass\u003c/span\u003e \u003cspan class=\"token class-name\"\u003eMyRNN\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003enn\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eModule\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n    \u003cspan class=\"token keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"token function\"\u003e__init__\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eself\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003einput_size\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003ehidden_size\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003eoutput_size\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"token builtin\"\u003esuper\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003e__init__\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n        self\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003ernn\u003cspan class=\"token operator\"\u003e=\u003c/span\u003enn\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eRNN\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003einput_size\u003cspan class=\"token operator\"\u003e=\u003c/span\u003einput_size\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003ehidden_size\u003cspan class=\"token operator\"\u003e=\u003c/span\u003ehidden_size\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003ebatch_first\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token boolean\"\u003eTrue\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n        self\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003elinear_ho\u003cspan class=\"token operator\"\u003e=\u003c/span\u003enn\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eLinear\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003ehidden_size\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003eoutput_size\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"token keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"token function\"\u003eforward\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eself\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003eseq\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003einit_state\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n        output_hidden\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003etate\u003cspan class=\"token operator\"\u003e=\u003c/span\u003eself\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003ernn\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eseq\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003einit_state\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n        output\u003cspan class=\"token operator\"\u003e=\u003c/span\u003eself\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003elinear_ho\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eoutput_hidden\u003cspan class=\"token punctuation\"\u003e[\u003c/span\u003e\u003cspan class=\"token operator\"\u003e-\u003c/span\u003e\u003cspan class=\"token number\"\u003e1\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e]\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e \u003cspan class=\"token comment\"\u003e#取最后一个时间点的输出\u003c/span\u003e\n        \u003cspan class=\"token keyword\"\u003ereturn\u003c/span\u003e output\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003estate\n"])</script><script>self.__next_f.push([1,"1d:T45c,\u003cspan class=\"token keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"token function\"\u003etrain\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003etrain_seq\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003etarget\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n    state\u003cspan class=\"token operator\"\u003e=\u003c/span\u003etorch\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003ezeros\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token number\"\u003e1\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003ehidden_size\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"token keyword\"\u003efor\u003c/span\u003e x \u003cspan class=\"token keyword\"\u003ein\u003c/span\u003e train_seq\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n        output\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003estate\u003cspan class=\"token operator\"\u003e=\u003c/span\u003emy_rnn\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003ex\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003estate\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n    loss\u003cspan class=\"token operator\"\u003e=\u003c/span\u003eloss_func\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eoutput\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003etarget\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"token comment\"\u003e# ......\u003c/span\u003e\n1e:T488,\u003cspan class=\"token keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"token function\"\u003epred\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003etruth_seq\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003enet\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n    \u003cspan class=\"token keyword\"\u003ewith\u003c/span\u003e torch\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eno_grad\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n        state\u003cspan class=\"token operator\"\u003e=\u003c/span\u003etorch\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003ezeros\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token number\"\u003e1\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003ehidden_size\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n        \u003cspan class=\"token keyword\"\u003efor\u003c/span\u003e x \u003cspan class=\"token keyword\"\u003ein\u003c/span\u003e truth_seq\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n            output\u003cspan class=\"token punctu"])</script><script>self.__next_f.push([1,"ation\"\u003e,\u003c/span\u003estate\u003cspan class=\"token operator\"\u003e=\u003c/span\u003enet\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003ex\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003estate\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n        \u003cspan class=\"token keyword\"\u003ereturn\u003c/span\u003e output\n1f:T40e,\u003cspan class=\"token keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"token function\"\u003etrain\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003etrain_seq\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003etarget\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n    state\u003cspan class=\"token operator\"\u003e=\u003c/span\u003etorch\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003ezeros\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token number\"\u003e1\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003ehidden_size\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n    output\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e_\u003cspan class=\"token operator\"\u003e=\u003c/span\u003emy_rnn\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003etrain_seq\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003estate\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e \u003cspan class=\"token comment\"\u003e#一次得到输出\u003c/span\u003e\n    loss\u003cspan class=\"token operator\"\u003e=\u003c/span\u003eloss_func\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eoutput\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003etarget\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"token comment\"\u003e# ......\u003c/span\u003e\n20:T40e,\u003cspan class=\"token keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"token function\"\u003epred\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003etruth_seq\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n    \u003cspan class=\"token keyword\"\u003ewith\u003c/span\u003e torch\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eno_grad\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n        state\u003cspan class=\"token operator\"\u003e=\u003c/span\u003etorch\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003ezeros\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token number\"\u003e1\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003ehidden_size\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n        output\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e_\u003cs"])</script><script>self.__next_f.push([1,"pan class=\"token operator\"\u003e=\u003c/span\u003emy_rnn\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003etruth_seq\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003estate\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e \u003cspan class=\"token comment\"\u003e#一次得到输出\u003c/span\u003e\n        \u003cspan class=\"token keyword\"\u003ereturn\u003c/span\u003e output\n21:T536,式子中\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6667em;vertical-align:-0.0833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e⊗\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e表示按位置相乘，\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.03588em;\"\u003eσ\u003c/span\u003e\u003cspan class=\"mopen\"\u003e(\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.04398em;\"\u003ez\u003c/span\u003e\u003cspan class=\"mclose\"\u003e)\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e的每个元素输出范围是\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"\u003e\u003c/span\u003e\u003cspan class=\"mopen\"\u003e[\u003c/span\u003e\u003cspan class=\"mord\"\u003e0\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e1\u003c/span\u003e\u003cspan class=\"mclose\"\u003e]\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e，某个元素接近\u003ccode class=\"x-inline-highlight\"\u003e1\u003c/code\u003e，\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.4306em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003ex\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e对应位置保留的信息就越多，反之就越少。22:T5a2,LSTM的第一步是决定什么应该被遗忘，也就是对上一个\u003cspan class=\"x-inline-strong\"\u003e单元\u003c/span\u003e\u003ccode class=\"x-inline-highlight\"\u003e(cell)\u003c/code\u003e状态信息选择性的遗忘。\u003cbr/\u003e这个操作由遗忘门\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan clas"])</script><script>self.__next_f.push([1,"s=\"mord mathnormal\" style=\"margin-right:0.10764em;\"\u003ef\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.2806em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003et\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e实现，将其\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"\u003e\u003c/span\u003e\u003cspan class=\"mopen\"\u003e[\u003c/span\u003e\u003cspan class=\"mord\"\u003e0\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e1\u003c/span\u003e\u003cspan class=\"mclose\"\u003e]\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e范围的输出按位置与单元上一时刻状态相乘。23:T93e,"])</script><script>self.__next_f.push([1,"当模型看到\u003ccode class=\"x-inline-highlight\"\u003eAlice是一名女教师，……\u003c/code\u003e时，单元状态中可能存储了和主语\u003ccode class=\"x-inline-highlight\"\u003eAlice\u003c/code\u003e和\u003ccode class=\"x-inline-highlight\"\u003e女教师\u003c/code\u003e有关的语义信息，以便在后文输出合适的代词\u003ccode class=\"x-inline-highlight\"\u003e她\u003c/code\u003e；然后，当模型看到\u003ccode class=\"x-inline-highlight\"\u003eAlice是一名女教师，她喜欢给学生讲课；Bob是一位男司机，……\u003c/code\u003e时，我们希望在看到新主语\u003ccode class=\"x-inline-highlight\"\u003eBob\u003c/code\u003e和\u003ccode class=\"x-inline-highlight\"\u003e男司机\u003c/code\u003e之后，忘记此前存储的旧主语的性别语义。也就是对旧单元状态\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.8917em;vertical-align:-0.2083em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.07153em;\"\u003eC\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3011em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003et\u003c/span\u003e\u003cspan class=\"mbin mtight\"\u003e−\u003c/span\u003e\u003cspan class=\"mord mtight\"\u003e1\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.2083em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e乘上较小的\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.10764em;\"\u003ef\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.2806em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003et\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e。"])</script><script>self.__next_f.push([1,"24:T4d3,下一步就是决定要在单元中存入什么新的信息。这一部分有两路：\u003ccode class=\"x-inline-highlight\"\u003etanh\u003c/code\u003e这一路与普通RNN很像，生成一个中间状态；\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.4306em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.03588em;\"\u003eσ\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e这一路被称为输入门\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.8095em;vertical-align:-0.15em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003ei\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.2806em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003et\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e，控制这个中间状态有多少信息被存入单元。25:T6c6,最后是决定新的隐藏状态，这个输出会基于单元状态，但会经过门控单元。输出门\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.5806em;vertical-align:-0.15em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003eo\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.2806em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003et\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/spa"])</script><script>self.__next_f.push([1,"n\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e决定经过\u003ccode class=\"x-inline-highlight\"\u003etanh\u003c/code\u003e的单元状态\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.8333em;vertical-align:-0.15em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.07153em;\"\u003eC\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.2806em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003et\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e有多少被输出到下一时刻的隐藏状态。"])</script><script>self.__next_f.push([1,"9:[[\"$\",\"h2\",null,{\"className\":\"x-h1\",\"children\":\"RNN：一个简单的例子\"}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"传统神经网络每次的输入是独立的，每次输出只依赖于当前的输入；但在某些任务中需要更好的处理序列信息，即前面的输入和后面的输入是有关系的；\u003cspan class=\\\"x-inline-strong\\\"\u003e循环神经网络\u003c/span\u003e\u003ccode class=\\\"x-inline-highlight\\\"\u003e(Recurrent Neural Networks, RNN)\u003c/code\u003e通过使用带自反馈的神经元，能够处理任意长度的序列。\"}}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"下面是一个非常常见的RNN结构描述图。它展示了RNN的自反馈机制和与时间的依赖关系，但是对网络结构的描述容易引起误解：右侧的展开形式并不意味着网络有\u003ccode class=\\\"x-inline-highlight\\\"\u003et\u003c/code\u003e层，而是反映了随着时间增加（有时也可以理解为随着程序中循环的迭代），上一次输出的隐藏状态，和\u003cspan class=\\\"katex\\\"\u003e\u003cspan class=\\\"katex-html\\\" aria-hidden=\\\"true\\\"\u003e\u003cspan class=\\\"base\\\"\u003e\u003cspan class=\\\"strut\\\" style=\\\"height:0.5806em;vertical-align:-0.15em;\\\"\u003e\u003c/span\u003e\u003cspan class=\\\"mord\\\"\u003e\u003cspan class=\\\"mord mathnormal\\\"\u003ex\u003c/span\u003e\u003cspan class=\\\"msupsub\\\"\u003e\u003cspan class=\\\"vlist-t vlist-t2\\\"\u003e\u003cspan class=\\\"vlist-r\\\"\u003e\u003cspan class=\\\"vlist\\\" style=\\\"height:0.2806em;\\\"\u003e\u003cspan style=\\\"top:-2.55em;margin-left:0em;margin-right:0.05em;\\\"\u003e\u003cspan class=\\\"pstrut\\\" style=\\\"height:2.7em;\\\"\u003e\u003c/span\u003e\u003cspan class=\\\"sizing reset-size6 size3 mtight\\\"\u003e\u003cspan class=\\\"mord mathnormal mtight\\\"\u003et\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\\\"vlist-s\\\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\\\"vlist-r\\\"\u003e\u003cspan class=\\\"vlist\\\" style=\\\"height:0.15em;\\\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e共同作为网络的下一次的输入。\"}}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"或者，如果说CNN是从空间维度上堆叠卷积层，不断加深，RNN就是从时间维度上的延展，而其网络真正的参数是很少的。\"}}],[\"$\",\"$L13\",null,{\"src\":\"rnn1.png\",\"width\":\"600px\",\"filterDarkTheme\":true}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"下面以一个简单的正弦序列预测任务出发，结合代码理解RNN网络的部分细节。\"}}],[\"$\",\"h3\",null,{\"className\":\"x-h2\",\"children\":\"预测一个正弦序列\"}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"这个例子中，我们对一个加了噪声的正弦序列进行预测。\"}}],[\"$\",\"div\",null,{\"className\":\"x-codeblock\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-codeblock-header\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-codeblock-header-language\",\"children\":\"Python\"}],[\"$\",\"$L14\",null,{\"className\":\"x-codeblock-header-copy\",\"text\":\"import numpy\\nimport torch\\nfrom torch import nn\\nimport matplotlib.pyplot as plt\\n\\n#生成加噪声的正弦序列数据\\nxlim=numpy.linspace(0,36,400)\\ny=numpy.sin(xlim)+numpy.random.rand(*xlim.shape)*0.2\\n\\n#转换dtype和size，保持和后面的训练数据统一\\ny=y.reshape(-1,1).astype(\\\"float32\\\")\\n\\nplt.plot(xlim,y)\\nplt.show()\\n\"}]]}],[\"$\",\"pre\",null,{\"style\":{\"background\":null},\"children\":[\"$\",\"code\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"$15\"}}]}]]}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"代码中我们在区间\u003cspan class=\\\"katex\\\"\u003e\u003cspan class=\\\"katex-html\\\" aria-hidden=\\\"true\\\"\u003e\u003cspan class=\\\"base\\\"\u003e\u003cspan class=\\\"strut\\\" style=\\\"height:1em;vertical-align:-0.25em;\\\"\u003e\u003c/span\u003e\u003cspan class=\\\"mopen\\\"\u003e[\u003c/span\u003e\u003cspan class=\\\"mord\\\"\u003e0\u003c/span\u003e\u003cspan class=\\\"mpunct\\\"\u003e,\u003c/span\u003e\u003cspan class=\\\"mspace\\\" style=\\\"margin-right:0.1667em;\\\"\u003e\u003c/span\u003e\u003cspan class=\\\"mord\\\"\u003e36\u003c/span\u003e\u003cspan class=\\\"mclose\\\"\u003e]\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e取了\u003ccode class=\\\"x-inline-highlight\\\"\u003e400\u003c/code\u003e点数据，如果把横轴看成时间轴，可以认为数据集中有\u003ccode class=\\\"x-inline-highlight\\\"\u003e400\u003c/code\u003e个连续时间点的数据。\"}}],[\"$\",\"$L13\",null,{\"src\":\"fig1.png\",\"width\":\"600px\",\"filterDarkTheme\":true}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"现在明确一下我们的方案：\"}}],[\"$\",\"div\",null,{\"className\":\"x-oli\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-oli-number\",\"children\":\"1.\"}],[\"$\",\"div\",null,{\"className\":\"x-oli-content-wrapper\",\"children\":[\"$\",\"p\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"使用前\u003ccode class=\\\"x-inline-highlight\\\"\u003e80%\u003c/code\u003e也就是前\u003ccode class=\\\"x-inline-highlight\\\"\u003e320\u003c/code\u003e个数据作为训练集，剩余的作为测试集，观察预测结果。\"}}]}]]}],[\"$\",\"div\",null,{\"className\":\"x-oli\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-oli-number\",\"children\":\"2.\"}],[\"$\",\"div\",null,{\"className\":\"x-oli-content-wrapper\",\"children\":[\"$\",\"p\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"序列长度为\u003ccode class=\\\"x-inline-highlight\\\"\u003e10\u003c/code\u003e，也就是模型根据前\u003ccode class=\\\"x-inline-highlight\\\"\u003e10\u003c/code\u003e个时间点的数据去预测下一个时间点的数据。\"}}]}]]}],[\"$\",\"div\",null,{\"className\":\"x-oli\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-oli-number\",\"children\":\"3.\"}],[\"$\",\"div\",null,{\"className\":\"x-oli-content-wrapper\",\"children\":[\"$\",\"p\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"这个例子中输入特征的维度是\u003ccode class=\\\"x-inline-highlight\\\"\u003e1\u003c/code\u003e，也就是只有\u003ccode class=\\\"x-inline-highlight\\\"\u003ey\u003c/code\u003e值一个指标。此外，也不考虑批量大小。\"}}]}]]}],[\"$\",\"h3\",null,{\"className\":\"x-h2\",\"children\":\"定义RNN网络\"}],[\"$\",\"div\",null,{\"className\":\"x-codeblock\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-codeblock-header\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-codeblock-header-language\",\"children\":\"Python\"}],[\"$\",\"$L14\",null,{\"className\":\"x-codeblock-header-copy\",\"text\":\"class MyRNN(nn.Module):\\n    def __init__(self,input_size,hidden_size,output_size):\\n        super().__init__()\\n        self.linear_ih=nn.Linear(input_size,hidden_size)\\n        self.linear_hh=nn.Linear(hidden_size,hidden_size)\\n        self.linear_ho=nn.Linear(hidden_size,output_size)\\n        self.tanh=nn.Tanh()\\n    def forward(self,x,prev_state):\\n        curr_state=self.tanh(\\n            self.linear_ih(x)+self.linear_hh(prev_state)\\n        )\\n        output=self.linear_ho(curr_state).reshape(1)\\n        return output,curr_state\\n\\nhidden_size=12\\nmy_rnn=MyRNN(input_size=1,hidden_size=hidden_size,output_size=1)\\nloss_func=nn.MSELoss()\\noptimizer=torch.optim.SGD(my_rnn.parameters(),lr=0.01)\\n\"}]]}],[\"$\",\"pre\",null,{\"style\":{\"background\":null},\"children\":[\"$\",\"code\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"$16\"}}]}]]}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"这个是一个简单的RNN结构，从网络参数和结构来看很像一个\u003ccode class=\\\"x-inline-highlight\\\"\u003e输入层-隐藏层-输出层\u003c/code\u003e的感知机，但是多了一步\u003ccode class=\\\"x-inline-highlight\\\"\u003e隐藏层-隐藏层\u003c/code\u003e的连接，RNN的反馈结构就是由此体现的。\"}}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"并且，注意到\u003ccode class=\\\"x-inline-highlight\\\"\u003eforward\u003c/code\u003e函数的输入也需要两个参数：当前时刻输入\u003ccode class=\\\"x-inline-highlight\\\"\u003ex\u003c/code\u003e和前一时刻状态\u003ccode class=\\\"x-inline-highlight\\\"\u003eprev_state\u003c/code\u003e，同时也会把计算后的新状态\u003ccode class=\\\"x-inline-highlight\\\"\u003ecurr_state\u003c/code\u003e和\u003ccode class=\\\"x-inline-highlight\\\"\u003eoutput\u003c/code\u003e一起返回，供下一次计算使用。在这里，经过\u003ccode class=\\\"x-inline-highlight\\\"\u003elinear_ho\u003c/code\u003e后，\u003ccode class=\\\"x-inline-highlight\\\"\u003eoutput\u003c/code\u003e的\u003ccode class=\\\"x-inline-highlight\\\"\u003esize\u003c/code\u003e为\u003ccode class=\\\"x-inline-highlight\\\"\u003e(1,1)\u003c/code\u003e，考虑到它仅仅是一个标量，我们把它\u003ccode class=\\\"x-inline-highlight\\\"\u003eresize\u003c/code\u003e为\u003ccode class=\\\"x-inline-highlight\\\"\u003e(1)\u003c/code\u003e。\"}}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"接下来设置了一些超参数，隐藏层有\u003ccode class=\\\"x-inline-highlight\\\"\u003e12\u003c/code\u003e个神经元，损失函数使用\u003ccode class=\\\"x-inline-highlight\\\"\u003eMSELoss()\u003c/code\u003e。\"}}],[\"$\",\"h3\",null,{\"className\":\"x-h2\",\"children\":\"训练\"}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"首先定义这样的训练函数：它传入一个序列\u003ccode class=\\\"x-inline-highlight\\\"\u003etrain_seq\u003c/code\u003e和目标\u003ccode class=\\\"x-inline-highlight\\\"\u003etarget\u003c/code\u003e。\u003ccode class=\\\"x-inline-highlight\\\"\u003etrain_seq\u003c/code\u003e的\u003ccode class=\\\"x-inline-highlight\\\"\u003esize\u003c/code\u003e应该为\u003ccode class=\\\"x-inline-highlight\\\"\u003e(10,1)\u003c/code\u003e，因为我们用前\u003ccode class=\\\"x-inline-highlight\\\"\u003e10\u003c/code\u003e个时间点的数据去预测下一个，而输入特征维度是\u003ccode class=\\\"x-inline-highlight\\\"\u003e1\u003c/code\u003e；\u003ccode class=\\\"x-inline-highlight\\\"\u003etarget\u003c/code\u003e的\u003ccode class=\\\"x-inline-highlight\\\"\u003esize\u003c/code\u003e应该为\u003ccode class=\\\"x-inline-highlight\\\"\u003e(1)\u003c/code\u003e，因为输出只是一个标量。注意我们循环依次输入\u003ccode class=\\\"x-inline-highlight\\\"\u003etrain_seq\u003c/code\u003e中的\u003ccode class=\\\"x-inline-highlight\\\"\u003e10\u003c/code\u003e个数据，迭代更新\u003ccode class=\\\"x-inline-highlight\\\"\u003estate\u003c/code\u003e，用最后一次的\u003ccode class=\\\"x-inline-highlight\\\"\u003eoutput\u003c/code\u003e作为最终的输出计算损失。\"}}],[\"$\",\"div\",null,{\"className\":\"x-codeblock\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-codeblock-header\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-codeblock-header-language\",\"children\":\"Python\"}],[\"$\",\"$L14\",null,{\"className\":\"x-codeblock-header-copy\",\"text\":\"def train(train_seq,target):\\n    #初始状态\\n    state=torch.zeros(1,hidden_size)\\n\\n    for x in train_seq:\\n        output,state=my_rnn(x,state)\\n\\n    loss=loss_func(output,target)\\n    optimizer.zero_grad()\\n    loss.backward()\\n    optimizer.step()\\n\\n    #返回损失\\n    return loss.detach().numpy().reshape(1)\\n\"}]]}],[\"$\",\"pre\",null,{\"style\":{\"background\":null},\"children\":[\"$\",\"code\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"$17\"}}]}]]}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"下面代码把真实数据划分成：\"}}],[\"$\",\"div\",null,{\"className\":\"x-table-wrapper\",\"children\":[\"$\",\"table\",null,{\"className\":\"x-table\",\"children\":[\"$\",\"tbody\",null,{\"children\":[[\"$\",\"tr\",\"0\",{\"children\":[[\"$\",\"th\",\"0\",{\"className\":null,\"width\":null,\"children\":[\"$\",\"p\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003etrain_seq\u003c/code\u003e\"}}]}],[\"$\",\"th\",\"1\",{\"className\":null,\"width\":null,\"children\":[\"$\",\"p\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003etarget\u003c/code\u003e\"}}]}]]}],[\"$\",\"tr\",\"1\",{\"children\":[[\"$\",\"td\",\"0\",{\"className\":null,\"width\":null,\"children\":[\"$\",\"p\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[0]\u003c/code\u003e,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[1]\u003c/code\u003e,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[2]\u003c/code\u003e, ... ,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[9]\u003c/code\u003e\"}}]}],[\"$\",\"td\",\"1\",{\"className\":null,\"width\":null,\"children\":[\"$\",\"p\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[10]\u003c/code\u003e\"}}]}]]}],[\"$\",\"tr\",\"2\",{\"children\":[[\"$\",\"td\",\"0\",{\"className\":null,\"width\":null,\"children\":[\"$\",\"p\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[1]\u003c/code\u003e,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[2]\u003c/code\u003e,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[3]\u003c/code\u003e, ... ,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[10]\u003c/code\u003e\"}}]}],[\"$\",\"td\",\"1\",{\"className\":null,\"width\":null,\"children\":[\"$\",\"p\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[11]\u003c/code\u003e\"}}]}]]}],[\"$\",\"tr\",\"3\",{\"children\":[[\"$\",\"td\",\"0\",{\"className\":null,\"width\":null,\"children\":[\"$\",\"p\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[2]\u003c/code\u003e,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[3]\u003c/code\u003e,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[4]\u003c/code\u003e, ... ,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[11]\u003c/code\u003e\"}}]}],[\"$\",\"td\",\"1\",{\"className\":null,\"width\":null,\"children\":[\"$\",\"p\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[12]\u003c/code\u003e\"}}]}]]}],[\"$\",\"tr\",\"4\",{\"children\":[[\"$\",\"td\",\"0\",{\"className\":null,\"width\":null,\"children\":[\"$\",\"p\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"...\"}}]}],[\"$\",\"td\",\"1\",{\"className\":null,\"width\":null,\"children\":[\"$\",\"p\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"...\"}}]}]]}],[\"$\",\"tr\",\"5\",{\"children\":[[\"$\",\"td\",\"0\",{\"className\":null,\"width\":null,\"children\":[\"$\",\"p\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[309]\u003c/code\u003e,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[310]\u003c/code\u003e,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[311]\u003c/code\u003e, ... ,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[318]\u003c/code\u003e\"}}]}],[\"$\",\"td\",\"1\",{\"className\":null,\"width\":null,\"children\":[\"$\",\"p\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[319]\u003c/code\u003e\"}}]}]]}]]}]}]}],[\"$\",\"div\",null,{\"className\":\"x-codeblock\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-codeblock-header\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-codeblock-header-language\",\"children\":\"Python\"}],[\"$\",\"$L14\",null,{\"className\":\"x-codeblock-header-copy\",\"text\":\"train_datas=[]\\nfor i in range(320-10):\\n    train_seq=torch.from_numpy(y[i:i+10])\\n    target=torch.from_numpy(y[i+10])\\n    train_datas.append((train_seq,target))\\n\"}]]}],[\"$\",\"pre\",null,{\"style\":{\"background\":null},\"children\":[\"$\",\"code\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"$18\"}}]}]]}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"训练网络，绘制误差：\"}}],[\"$\",\"div\",null,{\"className\":\"x-codeblock\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-codeblock-header\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-codeblock-header-language\",\"children\":\"Python\"}],[\"$\",\"$L14\",null,{\"className\":\"x-codeblock-header-copy\",\"text\":\"metrics=[]\\nmy_rnn.train()\\nfor train_seq,target in train_datas:\\n    loss=train(train_seq,target)\\n    metrics.append(loss)\\n\\nplt.subplot(211)\\nplt.plot(metrics,label=\\\"loss\\\")\\nplt.legend()\\n\"}]]}],[\"$\",\"pre\",null,{\"style\":{\"background\":null},\"children\":[\"$\",\"code\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"$19\"}}]}]]}],[\"$\",\"h3\",null,{\"className\":\"x-h2\",\"children\":\"预测\"}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"这个例子中我们用\u003cspan class=\\\"x-inline-strong\\\"\u003e单步预测\u003c/span\u003e观察模型的效果。在单步预测时，每次预测都全部使用真实值；当然，我们可以这样做是因为验证集中本来就包含了真实的数据，换句话说，我们是在已知\u003ccode class=\\\"x-inline-highlight\\\"\u003et+1\u003c/code\u003e时刻的真实数据的情况下，去看看模型使用\u003ccode class=\\\"x-inline-highlight\\\"\u003et-9\u003c/code\u003e~\u003ccode class=\\\"x-inline-highlight\\\"\u003et\u003c/code\u003e时刻的数据，对\u003ccode class=\\\"x-inline-highlight\\\"\u003et+1\u003c/code\u003e时刻的预测值。\"}}],[\"$\",\"div\",null,{\"className\":\"x-table-wrapper\",\"children\":[\"$\",\"table\",null,{\"className\":\"x-table\",\"children\":[\"$\",\"tbody\",null,{\"children\":[[\"$\",\"tr\",\"0\",{\"children\":[[\"$\",\"th\",\"0\",{\"className\":null,\"width\":null,\"children\":[\"$\",\"p\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003einput\u003c/code\u003e\"}}]}],[\"$\",\"th\",\"1\",{\"className\":null,\"width\":null,\"children\":[\"$\",\"p\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003eprediction\u003c/code\u003e\"}}]}]]}],[\"$\",\"tr\",\"1\",{\"children\":[[\"$\",\"td\",\"0\",{\"className\":null,\"width\":null,\"children\":[\"$\",\"p\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[310]\u003c/code\u003e,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[311]\u003c/code\u003e,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[312]\u003c/code\u003e, ... ,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[319]\u003c/code\u003e\"}}]}],[\"$\",\"td\",\"1\",{\"className\":null,\"width\":null,\"children\":[\"$\",\"p\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003epred[320]\u003c/code\u003e\"}}]}]]}],[\"$\",\"tr\",\"2\",{\"children\":[[\"$\",\"td\",\"0\",{\"className\":null,\"width\":null,\"children\":[\"$\",\"p\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[311]\u003c/code\u003e,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[312]\u003c/code\u003e,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[313]\u003c/code\u003e, ... ,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[320]\u003c/code\u003e\"}}]}],[\"$\",\"td\",\"1\",{\"className\":null,\"width\":null,\"children\":[\"$\",\"p\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003epred[321]\u003c/code\u003e\"}}]}]]}],[\"$\",\"tr\",\"3\",{\"children\":[[\"$\",\"td\",\"0\",{\"className\":null,\"width\":null,\"children\":[\"$\",\"p\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[312]\u003c/code\u003e,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[313]\u003c/code\u003e,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[314]\u003c/code\u003e, ... ,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[321]\u003c/code\u003e\"}}]}],[\"$\",\"td\",\"1\",{\"className\":null,\"width\":null,\"children\":[\"$\",\"p\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003epred[322]\u003c/code\u003e\"}}]}]]}],[\"$\",\"tr\",\"4\",{\"children\":[[\"$\",\"td\",\"0\",{\"className\":null,\"width\":null,\"children\":[\"$\",\"p\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"...\"}}]}],[\"$\",\"td\",\"1\",{\"className\":null,\"width\":null,\"children\":[\"$\",\"p\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"...\"}}]}]]}]]}]}]}],[\"$\",\"div\",null,{\"className\":\"x-codeblock\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-codeblock-header\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-codeblock-header-language\",\"children\":\"Python\"}],[\"$\",\"$L14\",null,{\"className\":\"x-codeblock-header-copy\",\"text\":\"def pred(truth_seq):\\n    with torch.no_grad():\\n        state=torch.zeros(1,hidden_size)\\n        for x in truth_seq:\\n            output,state=my_rnn(x,state)\\n        return output\\n\\npreds=[]\\nfor i in range(320-10,400-10):\\n    truth_seq=torch.from_numpy(y[i:i+10])\\n    preds.append(pred(truth_seq).numpy())\\npreds=numpy.array(preds).reshape(-1,1)\\n\\nplt.subplot(212)\\nplt.plot(xlim,y,label=\\\"truth\\\")\\nplt.plot(xlim[320:400],preds,\\\"red\\\",label=\\\"predict\\\")\\nplt.legend()\\nplt.show()\\n\"}]]}],[\"$\",\"pre\",null,{\"style\":{\"background\":null},\"children\":[\"$\",\"code\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"$1a\"}}]}]]}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"如果我们不只是在测试集上评估模型性能，而是去预测真实生活中的问题，例如未来\u003ccode class=\\\"x-inline-highlight\\\"\u003e7\u003c/code\u003e天的温度；或者假如我们的数据集到\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[319]\u003c/code\u003e就截止了，这时如果想得到后面多个时刻的数据，就需要\u003cspan class=\\\"x-inline-strong\\\"\u003e多步预测\u003c/span\u003e，此时上一时刻的预测会被当做新的输入：\"}}],[\"$\",\"div\",null,{\"className\":\"x-table-wrapper\",\"children\":[\"$\",\"table\",null,{\"className\":\"x-table\",\"children\":[\"$\",\"tbody\",null,{\"children\":[[\"$\",\"tr\",\"0\",{\"children\":[[\"$\",\"th\",\"0\",{\"className\":null,\"width\":null,\"children\":[\"$\",\"p\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003einput\u003c/code\u003e\"}}]}],[\"$\",\"th\",\"1\",{\"className\":null,\"width\":null,\"children\":[\"$\",\"p\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003eprediction\u003c/code\u003e\"}}]}]]}],[\"$\",\"tr\",\"1\",{\"children\":[[\"$\",\"td\",\"0\",{\"className\":null,\"width\":null,\"children\":[\"$\",\"p\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[310]\u003c/code\u003e,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[311]\u003c/code\u003e,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[312]\u003c/code\u003e, ... ,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[319]\u003c/code\u003e\"}}]}],[\"$\",\"td\",\"1\",{\"className\":null,\"width\":null,\"children\":[\"$\",\"p\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003epred[320]\u003c/code\u003e\"}}]}]]}],[\"$\",\"tr\",\"2\",{\"children\":[[\"$\",\"td\",\"0\",{\"className\":null,\"width\":null,\"children\":[\"$\",\"p\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[311]\u003c/code\u003e,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[312]\u003c/code\u003e,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[313]\u003c/code\u003e, ... ,\u003ccode class=\\\"x-inline-highlight\\\"\u003epred[320]\u003c/code\u003e\"}}]}],[\"$\",\"td\",\"1\",{\"className\":null,\"width\":null,\"children\":[\"$\",\"p\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003epred[321]\u003c/code\u003e\"}}]}]]}],[\"$\",\"tr\",\"3\",{\"children\":[[\"$\",\"td\",\"0\",{\"className\":null,\"width\":null,\"children\":[\"$\",\"p\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[312]\u003c/code\u003e,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[313]\u003c/code\u003e,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[314]\u003c/code\u003e, ... ,\u003ccode class=\\\"x-inline-highlight\\\"\u003epred[320]\u003c/code\u003e,\u003ccode class=\\\"x-inline-highlight\\\"\u003epred[321]\u003c/code\u003e\"}}]}],[\"$\",\"td\",\"1\",{\"className\":null,\"width\":null,\"children\":[\"$\",\"p\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003epred[322]\u003c/code\u003e\"}}]}]]}],[\"$\",\"tr\",\"4\",{\"children\":[[\"$\",\"td\",\"0\",{\"className\":null,\"width\":null,\"children\":[\"$\",\"p\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"...\"}}]}],[\"$\",\"td\",\"1\",{\"className\":null,\"width\":null,\"children\":[\"$\",\"p\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"...\"}}]}]]}]]}]}]}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"多步预测会导致误差的累积。\"}}],[\"$\",\"h3\",null,{\"className\":\"x-h2\",\"children\":\"看看效果\"}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"如果不执行训练步骤的代码，使用初始随机参数的模型预测结果是：\"}}],[\"$\",\"$L13\",null,{\"src\":\"fig2.png\",\"width\":\"600px\",\"filterDarkTheme\":true}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"经过训练后，每次训练的\u003ccode class=\\\"x-inline-highlight\\\"\u003eloss\u003c/code\u003e和最终的预测：\"}}],[\"$\",\"$L13\",null,{\"src\":\"fig3.png\",\"width\":\"600px\",\"filterDarkTheme\":true}],[\"$\",\"h3\",null,{\"className\":\"x-h2\",\"children\":\"使用torch.nn.RNN\"}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"使用\u003ccode class=\\\"x-inline-highlight\\\"\u003etorch.nn.RNN\u003c/code\u003e模块时，与上面例子中手动实现的RNN有几处细小的区别，下面给出了使用\u003ccode class=\\\"x-inline-highlight\\\"\u003etorch.nn.RNN\u003c/code\u003e时需要做出的修改：\"}}],[\"$\",\"div\",null,{\"className\":\"x-oli\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-oli-number\",\"children\":\"1.\"}],[\"$\",\"div\",null,{\"className\":\"x-oli-content-wrapper\",\"children\":[[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"定义模型时，不再需要显式指定\u003ccode class=\\\"x-inline-highlight\\\"\u003elinear_ih\u003c/code\u003e和\u003ccode class=\\\"x-inline-highlight\\\"\u003elinear_hh\u003c/code\u003e两层，将由\u003ccode class=\\\"x-inline-highlight\\\"\u003enn.RNN\u003c/code\u003e模块实现；\u003ccode class=\\\"x-inline-highlight\\\"\u003enn.RNN\u003c/code\u003e模块没有定义输出层，因此输出层\u003ccode class=\\\"x-inline-highlight\\\"\u003elinear_ho\u003c/code\u003e需要设置。\u003cbr/\u003e在\u003ccode class=\\\"x-inline-highlight\\\"\u003eforward\u003c/code\u003e函数中，手动实现时为了直观展示出RNN的迭代过程，只进行了一次隐藏状态的更新；而对于输入序列迭代更新隐藏状态是在训练和预测时实现的。而\u003ccode class=\\\"x-inline-highlight\\\"\u003enn.RNN\u003c/code\u003e模块的一次\u003ccode class=\\\"x-inline-highlight\\\"\u003eforward\u003c/code\u003e就已经完成了迭代更新，其输入是整个序列\u003ccode class=\\\"x-inline-highlight\\\"\u003eseq\u003c/code\u003e和\u003ccode class=\\\"x-inline-highlight\\\"\u003eprev_state\u003c/code\u003e，返回值是\u003ccode class=\\\"x-inline-highlight\\\"\u003eoutput_hidden,curr_state\u003c/code\u003e，对于不考虑批量大小的数据，它们的\u003ccode class=\\\"x-inline-highlight\\\"\u003esize\u003c/code\u003e为：\"}}],[\"$\",\"div\",null,{\"className\":\"x-uli\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-uli-marker\",\"children\":[\"$\",\"div\",null,{\"className\":\"x-uli-marker-dot\"}]}],[\"$\",\"div\",null,{\"className\":\"x-uli-content-wrapper\",\"children\":[\"$\",\"p\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003eseq\u003c/code\u003e: \u003ccode class=\\\"x-inline-highlight\\\"\u003e(sequence_length, input_size)\u003c/code\u003e\"}}]}]]}],[\"$\",\"div\",null,{\"className\":\"x-uli\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-uli-marker\",\"children\":[\"$\",\"div\",null,{\"className\":\"x-uli-marker-dot\"}]}],[\"$\",\"div\",null,{\"className\":\"x-uli-content-wrapper\",\"children\":[\"$\",\"p\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003einit_state\u003c/code\u003e: \u003ccode class=\\\"x-inline-highlight\\\"\u003e(1, hidden_size)\u003c/code\u003e\"}}]}]]}],[\"$\",\"div\",null,{\"className\":\"x-uli\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-uli-marker\",\"children\":[\"$\",\"div\",null,{\"className\":\"x-uli-marker-dot\"}]}],[\"$\",\"div\",null,{\"className\":\"x-uli-content-wrapper\",\"children\":[\"$\",\"p\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003eoutput_hidden\u003c/code\u003e: \u003ccode class=\\\"x-inline-highlight\\\"\u003e(sequence_length, hidden_size)\u003c/code\u003e\"}}]}]]}],[\"$\",\"div\",null,{\"className\":\"x-uli\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-uli-marker\",\"children\":[\"$\",\"div\",null,{\"className\":\"x-uli-marker-dot\"}]}],[\"$\",\"div\",null,{\"className\":\"x-uli-content-wrapper\",\"children\":[\"$\",\"p\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003estate\u003c/code\u003e: \u003ccode class=\\\"x-inline-highlight\\\"\u003e(1, hidden_size)\u003c/code\u003e\"}}]}]]}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"最后在我们定义的\u003ccode class=\\\"x-inline-highlight\\\"\u003eMyRNN\u003c/code\u003e模块中，用\u003ccode class=\\\"x-inline-highlight\\\"\u003eoutput_hidden\u003c/code\u003e的最后一个时间点的输出，经过输出层得到最终的\u003ccode class=\\\"x-inline-highlight\\\"\u003eoutput\u003c/code\u003e。\"}}]]}]]}],[\"$\",\"div\",null,{\"className\":\"x-highlightblock highlight-background-gray\",\"children\":[[\"$\",\"h4\",null,{\"className\":\"x-h3\",\"children\":\"手动实现\"}],[\"$\",\"div\",null,{\"className\":\"x-codeblock\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-codeblock-header\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-codeblock-header-language\",\"children\":\"Python\"}],[\"$\",\"$L14\",null,{\"className\":\"x-codeblock-header-copy\",\"text\":\"class MyRNN(nn.Module):\\n    def __init__(self,input_size,hidden_size,output_size):\\n        super().__init__()\\n        self.linear_ih=nn.Linear(input_size,hidden_size)\\n        self.linear_hh=nn.Linear(hidden_size,hidden_size)\\n        self.linear_ho=nn.Linear(hidden_size,output_size)\\n        self.tanh=nn.Tanh()\\n    def forward(self,x,prev_state):\\n        curr_state=self.tanh(\\n            self.linear_ih(x)+self.linear_hh(prev_state)\\n        )\\n        output=self.linear_ho(curr_state).reshape(1)\\n        return output,curr_state\\n\"}]]}],[\"$\",\"pre\",null,{\"style\":{\"background\":null},\"children\":[\"$\",\"code\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"$1b\"}}]}]]}],[\"$\",\"h4\",null,{\"className\":\"x-h3\",\"children\":\"使用torch.nn.RNN\"}],[\"$\",\"div\",null,{\"className\":\"x-codeblock\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-codeblock-header\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-codeblock-header-language\",\"children\":\"Python\"}],[\"$\",\"$L14\",null,{\"className\":\"x-codeblock-header-copy\",\"text\":\"class MyRNN(nn.Module):\\n    def __init__(self,input_size,hidden_size,output_size):\\n        super().__init__()\\n        self.rnn=nn.RNN(input_size=input_size,hidden_size=hidden_size,batch_first=True)\\n        self.linear_ho=nn.Linear(hidden_size,output_size)\\n    def forward(self,seq,init_state):\\n        output_hidden,tate=self.rnn(seq,init_state)\\n        output=self.linear_ho(output_hidden[-1,:]) #取最后一个时间点的输出\\n        return output,state\\n\"}]]}],[\"$\",\"pre\",null,{\"style\":{\"background\":null},\"children\":[\"$\",\"code\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"$1c\"}}]}]]}]]}],[\"$\",\"div\",null,{\"className\":\"x-oli\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-oli-number\",\"children\":\"2.\"}],[\"$\",\"div\",null,{\"className\":\"x-oli-content-wrapper\",\"children\":[\"$\",\"p\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"训练和预测时，也不需要再遍历序列，迭代的过程已经在\u003ccode class=\\\"x-inline-highlight\\\"\u003enn.RNN\u003c/code\u003e模块内部实现。\"}}]}]]}],[\"$\",\"div\",null,{\"className\":\"x-highlightblock highlight-background-gray\",\"children\":[[\"$\",\"h4\",null,{\"className\":\"x-h3\",\"children\":\"手动实现\"}],[\"$\",\"div\",null,{\"className\":\"x-codeblock\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-codeblock-header\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-codeblock-header-language\",\"children\":\"Python\"}],[\"$\",\"$L14\",null,{\"className\":\"x-codeblock-header-copy\",\"text\":\"def train(train_seq,target):\\n    state=torch.zeros(1,hidden_size)\\n    for x in train_seq:\\n        output,state=my_rnn(x,state)\\n    loss=loss_func(output,target)\\n    # ......\\n\"}]]}],[\"$\",\"pre\",null,{\"style\":{\"background\":null},\"children\":[\"$\",\"code\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"$1d\"}}]}]]}],[\"$\",\"div\",null,{\"className\":\"x-codeblock\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-codeblock-header\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-codeblock-header-language\",\"children\":\"Python\"}],[\"$\",\"$L14\",null,{\"className\":\"x-codeblock-header-copy\",\"text\":\"def pred(truth_seq,net):\\n    with torch.no_grad():\\n        state=torch.zeros(1,hidden_size)\\n        for x in truth_seq:\\n            output,state=net(x,state)\\n        return output\\n\"}]]}],[\"$\",\"pre\",null,{\"style\":{\"background\":null},\"children\":[\"$\",\"code\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"$1e\"}}]}]]}],[\"$\",\"h4\",null,{\"className\":\"x-h3\",\"children\":\"使用torch.nn.RNN\"}],[\"$\",\"div\",null,{\"className\":\"x-codeblock\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-codeblock-header\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-codeblock-header-language\",\"children\":\"Python\"}],[\"$\",\"$L14\",null,{\"className\":\"x-codeblock-header-copy\",\"text\":\"def train(train_seq,target):\\n    state=torch.zeros(1,hidden_size)\\n    output,_=my_rnn(train_seq,state) #一次得到输出\\n    loss=loss_func(output,target)\\n    # ......\\n\"}]]}],[\"$\",\"pre\",null,{\"style\":{\"background\":null},\"children\":[\"$\",\"code\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"$1f\"}}]}]]}],[\"$\",\"div\",null,{\"className\":\"x-codeblock\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-codeblock-header\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-codeblock-header-language\",\"children\":\"Python\"}],[\"$\",\"$L14\",null,{\"className\":\"x-codeblock-header-copy\",\"text\":\"def pred(truth_seq):\\n    with torch.no_grad():\\n        state=torch.zeros(1,hidden_size)\\n        output,_=my_rnn(truth_seq,state) #一次得到输出\\n        return output\\n\"}]]}],[\"$\",\"pre\",null,{\"style\":{\"background\":null},\"children\":[\"$\",\"code\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"$20\"}}]}]]}]]}],[\"$\",\"h3\",null,{\"className\":\"x-h2\",\"children\":\"FAQ\"}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"初次了解RNN时，我在一些问题上困惑了很久。这个版块是对它们的再次整理。（尽管有些已经包含在上述例子中了！）\"}}],[\"$\",\"h4\",null,{\"className\":\"x-h3\",\"children\":\"用10步预测下1步，为什么 input_size 不是10，而是1？\"}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003einput_size\u003c/code\u003e与序列长度并非同一个概念。用前\u003ccode class=\\\"x-inline-highlight\\\"\u003e10\u003c/code\u003e个时间点的数据去预测下一个，这里的\u003ccode class=\\\"x-inline-highlight\\\"\u003e10\u003c/code\u003e是序列长度；而\u003ccode class=\\\"x-inline-highlight\\\"\u003einput_size\u003c/code\u003e是输入特征的维度。由于这个例子较为简单，只是用历史的\u003ccode class=\\\"x-inline-highlight\\\"\u003ey\u003c/code\u003e值预测新的\u003ccode class=\\\"x-inline-highlight\\\"\u003ey\u003c/code\u003e值，因此特征只有\u003ccode class=\\\"x-inline-highlight\\\"\u003e1\u003c/code\u003e维。\"}}],[\"$\",\"h4\",null,{\"className\":\"x-h3\",\"children\":\"什么时候 input_size 不是1？\"}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"例如我们在预测未来气温时，历史气温数据并不是唯一的参考，还可能参考历史的风速、气压、天气情况等等，此时输入数据将会是一个\u003ccode class=\\\"x-inline-highlight\\\"\u003einput_size\u003c/code\u003e维的向量。\"}}],[\"$\",\"h4\",null,{\"className\":\"x-h3\",\"children\":\"hidden_size=12，12是在哪里体现的？\"}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003e12\u003c/code\u003e只是模型的超参数，和MLP中隐藏层大小一样，并没有太多的物理含义。\"}}],[\"$\",\"h4\",null,{\"className\":\"x-h3\",\"children\":\"训练时，每次迭代用哪些数据？应该遍历几遍数据集？每个 epoch 会使用哪些数据进行参数优化？\"}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"在训练一个CNN网络时（例如一个图片分类网络），策略通常是：\"}}],[\"$\",\"div\",null,{\"className\":\"x-oli\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-oli-number\",\"children\":\"1.\"}],[\"$\",\"div\",null,{\"className\":\"x-oli-content-wrapper\",\"children\":[\"$\",\"p\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"指定超参数\u003ccode class=\\\"x-inline-highlight\\\"\u003enum_epoch\u003c/code\u003e，在每个\u003ccode class=\\\"x-inline-highlight\\\"\u003eepoch\u003c/code\u003e中随机遍历训练集中的所有图像进行参数优化；\"}}]}]]}],[\"$\",\"div\",null,{\"className\":\"x-oli\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-oli-number\",\"children\":\"2.\"}],[\"$\",\"div\",null,{\"className\":\"x-oli-content-wrapper\",\"children\":[\"$\",\"p\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"重复执行\u003ccode class=\\\"x-inline-highlight\\\"\u003enum_epoch\u003c/code\u003e次。\"}}]}]]}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"然而对于RNN来说这个概念似乎并不清晰，例如上述例子的训练策略是：\"}}],[\"$\",\"div\",null,{\"className\":\"x-oli\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-oli-number\",\"children\":\"1.\"}],[\"$\",\"div\",null,{\"className\":\"x-oli-content-wrapper\",\"children\":[\"$\",\"p\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"从\u003ccode class=\\\"x-inline-highlight\\\"\u003e0\u003c/code\u003e到\u003ccode class=\\\"x-inline-highlight\\\"\u003e(训练集大小 - 序列长度)\u003c/code\u003e依次遍历起始时间\u003ccode class=\\\"x-inline-highlight\\\"\u003et\u003c/code\u003e；\"}}]}]]}],[\"$\",\"div\",null,{\"className\":\"x-oli\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-oli-number\",\"children\":\"2.\"}],[\"$\",\"div\",null,{\"className\":\"x-oli-content-wrapper\",\"children\":[\"$\",\"p\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"对于每个起始时间\u003ccode class=\\\"x-inline-highlight\\\"\u003et\u003c/code\u003e，将\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[t]\u003c/code\u003e~\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[t+9]\u003c/code\u003e为输入，\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[t+10]\u003c/code\u003e为真值作为一组训练样本。\"}}]}]]}],[\"$\",\"div\",null,{\"className\":\"x-oli\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-oli-number\",\"children\":\"3.\"}],[\"$\",\"div\",null,{\"className\":\"x-oli-content-wrapper\",\"children\":[\"$\",\"p\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"第\u003ccode class=\\\"x-inline-highlight\\\"\u003e1\u003c/code\u003e步只遍历了一次！\"}}]}]]}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"或者：\"}}],[\"$\",\"div\",null,{\"className\":\"x-oli\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-oli-number\",\"children\":\"1.\"}],[\"$\",\"div\",null,{\"className\":\"x-oli-content-wrapper\",\"children\":[\"$\",\"p\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"...\"}}]}]]}],[\"$\",\"div\",null,{\"className\":\"x-oli\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-oli-number\",\"children\":\"2.\"}],[\"$\",\"div\",null,{\"className\":\"x-oli-content-wrapper\",\"children\":[\"$\",\"p\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"...\"}}]}]]}],[\"$\",\"div\",null,{\"className\":\"x-oli\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-oli-number\",\"children\":\"3.\"}],[\"$\",\"div\",null,{\"className\":\"x-oli-content-wrapper\",\"children\":[\"$\",\"p\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"前两步同上，但多次遍历训练集。\"}}]}]]}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"另一个常用的策略是：\"}}],[\"$\",\"div\",null,{\"className\":\"x-oli\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-oli-number\",\"children\":\"1.\"}],[\"$\",\"div\",null,{\"className\":\"x-oli-content-wrapper\",\"children\":[\"$\",\"p\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"指定超参数：训练轮次\u003ccode class=\\\"x-inline-highlight\\\"\u003enum_iter\u003c/code\u003e；\"}}]}]]}],[\"$\",\"div\",null,{\"className\":\"x-oli\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-oli-number\",\"children\":\"2.\"}],[\"$\",\"div\",null,{\"className\":\"x-oli-content-wrapper\",\"children\":[\"$\",\"p\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"重复执行\u003ccode class=\\\"x-inline-highlight\\\"\u003enum_iter\u003c/code\u003e次，每次随机抽取一个起始时间\u003ccode class=\\\"x-inline-highlight\\\"\u003et\u003c/code\u003e，并且将\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[t]\u003c/code\u003e~\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[t+9]\u003c/code\u003e为输入，\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[t+10]\u003c/code\u003e为真值作为一组训练样本。\"}}]}]]}],[\"$\",\"h2\",null,{\"className\":\"x-h1\",\"children\":\"LSTM：一篇很好的博客\"}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"以下的内容和插图总结或翻译自这篇的英文博客：\u003ca href=\\\"https://colah.github.io/posts/2015-08-Understanding-LSTMs/\\\" target=\\\"_blank\\\" rel=\\\"noreferrer\\\" class=\\\"x-inline-link\\\"\u003eUnderstanding LSTM Networks\u003c/a\u003e\"}}],[\"$\",\"h3\",null,{\"className\":\"x-h2\",\"children\":\"长期依赖问题\"}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"RNN可以利用先前的信息理解当前的任务，这点非常不错；有时我们只需要短期的信息，例如一个语言模型预测下面的句子：\u003cbr/\u003e\u003ccode class=\\\"x-inline-highlight\\\"\u003e天空中飘着一朵白色的【云】\u003c/code\u003e，这很简单。但有些时候我们需要更多背景信息，例如：\u003cbr/\u003e\u003ccode class=\\\"x-inline-highlight\\\"\u003e我出生在法国，…… ，我可以说流利的【法语】\u003c/code\u003e，这个情况下，随着前后文距离变大，RNN对长期依赖关系的学习会变得困难。\"}}],[\"$\",\"h3\",null,{\"className\":\"x-h2\",\"children\":\"LSTM\"}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003cspan class=\\\"x-inline-strong\\\"\u003e长短期记忆网络\u003c/span\u003e\u003ccode class=\\\"x-inline-highlight\\\"\u003e(Long Short-Term Memory, LSTM)\u003c/code\u003e是一种特殊的RNN，可以学习长期依赖。以RNN为例，循环神经网络随时间展开通常具有如下的示意图：\"}}],[\"$\",\"$L13\",null,{\"src\":\"rnn2.png\",\"width\":\"600px\",\"filterDarkTheme\":true}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"对于RNN来说，利用历史状态和输入得到新的状态，只经过一个简单的\u003ccode class=\\\"x-inline-highlight\\\"\u003etanh\u003c/code\u003e激活层，而对于LSTM来说，它的示意图略显复杂：\"}}],[\"$\",\"$L13\",null,{\"src\":\"lstm1.png\",\"width\":\"600px\",\"filterDarkTheme\":true}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"在上图中，每条线表示一个向量，粉红色圆圈表示逐点式操作，黄色的方框是神经网络的层。这看起来很眼晕，不过我们接下来会一点点的解释图里的内容。\"}}],[\"$\",\"h3\",null,{\"className\":\"x-h2\",\"children\":\"门控单元\"}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"下面的结构称为门控单元：\"}}],[\"$\",\"$L13\",null,{\"src\":\"lstm2.png\",\"width\":\"100px\",\"filterDarkTheme\":true}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"门控单元控制信息量通过的多少，通过向量\u003cspan class=\\\"katex\\\"\u003e\u003cspan class=\\\"katex-html\\\" aria-hidden=\\\"true\\\"\u003e\u003cspan class=\\\"base\\\"\u003e\u003cspan class=\\\"strut\\\" style=\\\"height:0.4306em;\\\"\u003e\u003c/span\u003e\u003cspan class=\\\"mord mathnormal\\\" style=\\\"margin-right:0.04398em;\\\"\u003ez\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e来控制\u003cspan class=\\\"katex\\\"\u003e\u003cspan class=\\\"katex-html\\\" aria-hidden=\\\"true\\\"\u003e\u003cspan class=\\\"base\\\"\u003e\u003cspan class=\\\"strut\\\" style=\\\"height:0.4306em;\\\"\u003e\u003c/span\u003e\u003cspan class=\\\"mord mathnormal\\\"\u003ex\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e通过的信息量：\"}}],[\"$\",\"div\",null,{\"className\":\"x-formula\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003cspan class=\\\"katex\\\"\u003e\u003cspan class=\\\"katex-html\\\" aria-hidden=\\\"true\\\"\u003e\u003cspan class=\\\"base\\\"\u003e\u003cspan class=\\\"strut\\\" style=\\\"height:0.4306em;\\\"\u003e\u003c/span\u003e\u003cspan class=\\\"mord mathnormal\\\"\u003eo\u003c/span\u003e\u003cspan class=\\\"mspace\\\" style=\\\"margin-right:0.2778em;\\\"\u003e\u003c/span\u003e\u003cspan class=\\\"mrel\\\"\u003e=\u003c/span\u003e\u003cspan class=\\\"mspace\\\" style=\\\"margin-right:0.2778em;\\\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\\\"base\\\"\u003e\u003cspan class=\\\"strut\\\" style=\\\"height:1em;vertical-align:-0.25em;\\\"\u003e\u003c/span\u003e\u003cspan class=\\\"mord mathnormal\\\" style=\\\"margin-right:0.03588em;\\\"\u003eσ\u003c/span\u003e\u003cspan class=\\\"mopen\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"mord mathnormal\\\" style=\\\"margin-right:0.04398em;\\\"\u003ez\u003c/span\u003e\u003cspan class=\\\"mclose\\\"\u003e)\u003c/span\u003e\u003cspan class=\\\"mspace\\\" style=\\\"margin-right:0.2222em;\\\"\u003e\u003c/span\u003e\u003cspan class=\\\"mbin\\\"\u003e⊗\u003c/span\u003e\u003cspan class=\\\"mspace\\\" style=\\\"margin-right:0.2222em;\\\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\\\"base\\\"\u003e\u003cspan class=\\\"strut\\\" style=\\\"height:0.4306em;\\\"\u003e\u003c/span\u003e\u003cspan class=\\\"mord mathnormal\\\"\u003ex\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\"}}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"$21\"}}],[\"$\",\"h3\",null,{\"className\":\"x-h2\",\"children\":\"逐部分分析LSTM\"}],[\"$\",\"h4\",null,{\"className\":\"x-h3\",\"children\":\"遗忘门\"}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"$22\"}}],[\"$\",\"$L13\",null,{\"src\":\"lstm3.png\",\"width\":\"600px\",\"filterDarkTheme\":true}],[\"$\",\"div\",null,{\"className\":\"x-highlightblock highlight-background-gray\",\"children\":[[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"举一个概念性的例子：\"}}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"考虑一个语言模型，输入一个句子：\u003ccode class=\\\"x-inline-highlight\\\"\u003eAlice是一名女教师，她喜欢给学生讲课；Bob是一位男司机，他喝酒上瘾。\u003c/code\u003e\"}}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"$23\"}}]]}],[\"$\",\"h4\",null,{\"className\":\"x-h3\",\"children\":\"输入门\"}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"$24\"}}],[\"$\",\"$L13\",null,{\"src\":\"lstm4.png\",\"width\":\"600px\",\"filterDarkTheme\":true}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"经历这两步之后，便可以相加得到新的单元状态：\"}}],[\"$\",\"$L13\",null,{\"src\":\"lstm5.png\",\"width\":\"600px\",\"filterDarkTheme\":true}],[\"$\",\"div\",null,{\"className\":\"x-highlightblock highlight-background-gray\",\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"同理，当模型看到\u003ccode class=\\\"x-inline-highlight\\\"\u003eBob是一位男司机\u003c/code\u003e时，我们可能会想丢掉此前的语义信息\u003ccode class=\\\"x-inline-highlight\\\"\u003e女性\u003c/code\u003e，并把新的语义信息\u003ccode class=\\\"x-inline-highlight\\\"\u003e男性\u003c/code\u003e存入单元状态，使得后文输出正确的代词\u003ccode class=\\\"x-inline-highlight\\\"\u003e他\u003c/code\u003e。\"}}]}],[\"$\",\"h4\",null,{\"className\":\"x-h3\",\"children\":\"输出门\"}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"$25\"}}],[\"$\",\"$L13\",null,{\"src\":\"lstm6.png\",\"width\":\"600px\",\"filterDarkTheme\":true}],[\"$\",\"div\",null,{\"className\":\"x-highlightblock highlight-background-gray\",\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"当看到\u003ccode class=\\\"x-inline-highlight\\\"\u003eBob是一位男司机，他……\u003c/code\u003e时，由于出现了主语\u003ccode class=\\\"x-inline-highlight\\\"\u003e他\u003c/code\u003e，模型可能会输出和\u003ccode class=\\\"x-inline-highlight\\\"\u003e谓语动词\u003c/code\u003e有关的语义信息。\"}}]}]]\n"])</script><script>self.__next_f.push([1,"10:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}],[\"$\",\"meta\",\"1\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"2\",{\"children\":\"学习RNN和LSTM - 铃木的网络日记\"}],[\"$\",\"link\",\"3\",{\"rel\":\"canonical\",\"href\":\"https://1kuzus.github.io/23d/learn-rnn-lstm/\"}]]\n5:null\n"])</script><script>self.__next_f.push([1,""])</script></body></html>