<!DOCTYPE html><html lang="zh-CN"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="stylesheet" href="/_next/static/css/e43a733539111c31.css" crossorigin="" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/803fe687e7e31b6c.css" crossorigin="" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/2ca3ce358f319fca.css" crossorigin="" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-f1f308b83e7ce1fe.js" crossorigin=""/><script src="/_next/static/chunks/fd9d1056-ef431402238f9d90.js" async="" crossorigin=""></script><script src="/_next/static/chunks/69-ae9cebba1b3d8b52.js" async="" crossorigin=""></script><script src="/_next/static/chunks/main-app-00b9bbd3f4a844ac.js" async="" crossorigin=""></script><script src="/_next/static/chunks/202-fbcb7cc54bf4f9f2.js" async=""></script><script src="/_next/static/chunks/452-25327cca6690da96.js" async=""></script><script src="/_next/static/chunks/app/(blogs)/23d/learn-rnn-lstm/page-908ed6f1f5b7890e.js" async=""></script><script src="/_next/static/chunks/792-a494ddef3d40c017.js" async=""></script><script src="/_next/static/chunks/app/(blogs)/layout-c2ed809937fec3d8.js" async=""></script><script src="/_next/static/chunks/app/layout-fee515b4ccc2d098.js" async=""></script><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-45BYSZ6WPY"></script><script async="" src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><link rel="icon" href="favicon.ico"/><title>学习RNN和LSTM - 铃木的网络日记</title><link rel="canonical" href="https://1kuzus.github.io/23d/learn-rnn-lstm/"/><script>
window.dataLayer = window.dataLayer || [];
function gtag() {
    dataLayer.push(arguments);
}
gtag('js', new Date());
gtag('config', 'G-45BYSZ6WPY');
if (!localStorage.getItem('theme')) localStorage.setItem('theme', 'light');
document.documentElement.setAttribute('class', localStorage.getItem('theme'));
</script><script>const a=z=>h.getItem(z),b=(y,z)=>h.setItem(y,z),c=(y,z)=>document.documentElement.setAttribute(y,z),d='theme',e='dark',f='light',g='class',h=localStorage;a(d)!==e&&a(d)!==f&&b(d,f);a(d)===e?c(g,e):c(g,f);</script><script src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js" crossorigin="" noModule=""></script></head><body><div id="header" class=""><div id="header-left-wrapper"><a href="/"><div id="header-logo-bg"><svg viewBox="0 0 1560 1560" width="36px" height="36px" xmlns="http://www.w3.org/2000/svg"><g fill-rule="evenodd"><path d="M644 97h272.529L1189 780H916.471z" fill="#00A8C4"></path><path d="M98 97h272.84L780 1120.73 1189.162 97H1462L916.438 1462H643.562z" fill="#30303C"></path><path d="M98 1462L643.3 97H916L370.7 1462z" fill="#00F8FF"></path></g></svg></div></a><div id="header-archive"><h3 id="header-archive-text">归档</h3><div class="header-archive-rightarrow"><svg viewBox="0 0 1024 1024" width="16px" height="16px" xmlns="http://www.w3.org/2000/svg"><path d="M761.056 532.128c.512-.992 1.344-1.824 1.792-2.848 8.8-18.304 5.92-40.704-9.664-55.424L399.936 139.744c-19.264-18.208-49.632-17.344-67.872 1.888-18.208 19.264-17.376 49.632 1.888 67.872l316.96 299.84L335.2 813.632c-19.072 18.4-19.648 48.768-1.248 67.872 9.408 9.792 21.984 14.688 34.56 14.688 12 0 24-4.48 33.312-13.44l350.048-337.376c.672-.672.928-1.6 1.6-2.304.512-.48 1.056-.832 1.568-1.344 2.72-2.848 4.16-6.336 6.016-9.6z" fill="#50505c"></path></svg></div></div></div><div id="header-right-wrapper"><div id="header-theme-bg"><div id="header-dark-theme-icon"><svg viewBox="0 0 1024 1024" width="20px" height="20px" xmlns="http://www.w3.org/2000/svg"><path fill="#FCFCFC" d="M524.8 938.667h-4.267a439.893 439.893 0 01-313.173-134.4 446.293 446.293 0 01-11.093-597.334A432.213 432.213 0 01366.933 90.027a42.667 42.667 0 0145.227 9.386 42.667 42.667 0 0110.24 42.667 358.4 358.4 0 0082.773 375.893 361.387 361.387 0 00376.747 82.774 42.667 42.667 0 0154.187 55.04 433.493 433.493 0 01-99.84 154.88 438.613 438.613 0 01-311.467 128z"></path></svg></div><div id="header-light-theme-icon"><svg viewBox="0 0 1024 1024" width="20px" height="20px" xmlns="http://www.w3.org/2000/svg"><path fill="#FCFCFC" d="M512 61.44c13.312 0 25.252 7.639 29.942 19.17l27.566 67.972c11.92 29.348-4.178 62.075-35.943 73.094A65.946 65.946 0 01512 225.28c-33.935 0-61.44-25.416-61.44-56.77 0-6.8 1.331-13.558 3.912-19.928l27.586-67.973C486.728 69.08 498.647 61.44 512 61.44zm0 901.12c-13.332 0-25.272-7.639-29.942-19.17l-27.586-67.972a52.961 52.961 0 01-3.912-19.927c0-31.335 27.505-56.771 61.44-56.771a66.28 66.28 0 0121.565 3.604c31.765 11.019 47.862 43.746 35.943 73.114l-27.566 67.953c-4.69 11.53-16.63 19.169-29.942 19.169zM962.56 512c0 13.312-7.639 25.252-19.17 29.942l-67.972 27.566c-29.348 11.92-62.075-4.178-73.094-35.943A65.946 65.946 0 01798.72 512c0-33.935 25.416-61.44 56.77-61.44 6.8 0 13.558 1.331 19.928 3.912l67.973 27.586c11.53 4.67 19.169 16.589 19.169 29.942zm-901.12 0c0-13.332 7.639-25.272 19.17-29.942l67.972-27.586a52.9 52.9 0 0119.927-3.912c31.335 0 56.771 27.505 56.771 61.44a66.28 66.28 0 01-3.604 21.565c-11.019 31.765-43.746 47.862-73.114 35.943l-67.953-27.566C69.08 537.252 61.44 525.312 61.44 512zm131.953-318.587c9.42-9.42 23.265-12.452 34.734-7.618l67.563 28.549c29.184 12.35 40.94 46.858 26.256 77.107a65.946 65.946 0 01-12.698 17.817c-23.982 23.983-61.399 25.457-83.558 3.277a52.961 52.961 0 01-11.346-16.855l-28.55-67.543c-4.853-11.469-1.822-25.313 7.599-34.734zm637.194 637.194c-9.42 9.421-23.265 12.452-34.734 7.598l-67.543-28.549a52.961 52.961 0 01-16.876-11.325c-22.16-22.18-20.685-59.597 3.298-83.579a65.946 65.946 0 0117.817-12.698c30.25-14.684 64.758-2.928 77.107 26.256l28.55 67.563c4.833 11.47 1.802 25.293-7.62 34.734zm0-637.214c9.42 9.42 12.452 23.265 7.618 34.734l-28.549 67.563c-12.35 29.184-46.858 40.94-77.107 26.256a65.946 65.946 0 01-17.817-12.698c-23.983-23.982-25.457-61.399-3.277-83.558 4.792-4.834 10.506-8.663 16.855-11.346l67.543-28.55c11.469-4.853 25.313-1.822 34.734 7.599zM193.393 830.587c-9.421-9.42-12.452-23.265-7.598-34.734l28.549-67.543a52.618 52.618 0 0111.325-16.876c22.18-22.16 59.597-20.685 83.579 3.298a65.842 65.842 0 0112.698 17.817c14.684 30.25 2.928 64.758-26.256 77.107l-67.563 28.55c-11.47 4.833-25.293 1.802-34.734-7.62zM512 737.28c-124.416 0-225.28-100.864-225.28-225.28S387.584 286.72 512 286.72 737.28 387.584 737.28 512 636.416 737.28 512 737.28z"></path></svg></div></div><a href="https://github.com/1kuzus/1kuzus.github.io" target="_blank" rel="noreferrer"><div id="header-github-bg"><svg viewBox="0 0 1024 1024" width="36px" height="36px" xmlns="http://www.w3.org/2000/svg"><path d="M411.306667 831.146667c3.413333-5.12 6.826667-10.24 6.826666-11.946667v-69.973333c-105.813333 22.186667-128-44.373333-128-44.373334-17.066667-44.373333-42.666667-56.32-42.666666-56.32-34.133333-23.893333 3.413333-23.893333 3.413333-23.893333 37.546667 3.413333 58.026667 39.253333 58.026667 39.253333 34.133333 58.026667 88.746667 40.96 110.933333 32.426667 3.413333-23.893333 13.653333-40.96 23.893333-51.2-85.333333-10.24-174.08-42.666667-174.08-187.733333 0-40.96 15.36-75.093333 39.253334-102.4-3.413333-10.24-17.066667-47.786667 3.413333-100.693334 0 0 32.426667-10.24 104.106667 39.253334 30.72-8.533333 63.146667-11.946667 95.573333-11.946667 32.426667 0 64.853333 5.12 95.573333 11.946667 73.386667-49.493333 104.106667-39.253333 104.106667-39.253334 20.48 52.906667 8.533333 90.453333 3.413333 100.693334 23.893333 27.306667 39.253333 59.733333 39.253334 102.4 0 145.066667-88.746667 177.493333-174.08 187.733333 13.653333 11.946667 25.6 34.133333 25.6 69.973333v104.106667c0 3.413333 1.706667 6.826667 6.826666 11.946667 5.12 6.826667 3.413333 18.773333-3.413333 23.893333-3.413333 1.706667-6.826667 3.413333-10.24 3.413333h-174.08c-10.24 0-17.066667-6.826667-17.066667-17.066666 0-5.12 1.706667-8.533333 3.413334-10.24z" fill="#FCFCFC"></path></svg></div></a></div></div><div id="blog-layout"><div id="main"><h1 class="x-title">学习RNN和LSTM</h1><h2 class="x-h1"><span>RNN：一个简单的例子</span></h2><p class="x-p">传统神经网络每次的输入是独立的，每次输出只依赖于当前的输入；但在某些任务中需要更好的处理序列信息，即前面的输入和后面的输入是有关系的；<span class="x-inline-strong">循环神经网络</span><code class="x-inline-highlight">(Recurrent Neural Networks, RNN)</code>通过使用带自反馈的神经元，能够处理任意长度的序列。</p><p class="x-p">下面是一个非常常见的RNN结构描述图。它展示了RNN的自反馈机制和与时间的依赖关系，但是对网络结构的描述容易引起误解：右侧的展开形式并不意味着网络有<code class="x-inline-highlight">t</code>层，而是反映了随着时间增加（有时也可以理解为随着程序中循环的迭代），上一次输出的隐藏状态，和<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>共同作为网络的下一次的输入。</p><p class="x-p">或者，如果说CNN是从空间维度上堆叠卷积层，不断加深，RNN就是从时间维度上的延展，而其网络真正的参数是很少的。</p><div class="x-image-wrapper x-image-invert"><img alt="img" loading="lazy" width="2706" height="711" decoding="async" data-nimg="1" style="color:transparent;width:600px;height:auto" src="/_next/static/media/rnn1.ad2f936d.png"/></div><p class="x-p">下面以一个简单的正弦序列预测任务出发，结合代码理解RNN网络的部分细节。</p><h3 class="x-h2"><span>预测一个正弦序列</span></h3><p class="x-p">这个例子中，我们对一个加了噪声的正弦序列进行预测。</p><div class="x-codeblock"><pre><code><span class="token keyword">import</span> numpy
<span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt

<span class="token comment">#生成加噪声的正弦序列数据</span>
xlim<span class="token operator">=</span>numpy<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">36</span><span class="token punctuation">,</span><span class="token number">400</span><span class="token punctuation">)</span>
y<span class="token operator">=</span>numpy<span class="token punctuation">.</span>sin<span class="token punctuation">(</span>xlim<span class="token punctuation">)</span><span class="token operator">+</span>numpy<span class="token punctuation">.</span>random<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token operator">*</span>xlim<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token operator">*</span><span class="token number">0.2</span>

<span class="token comment">#转换dtype和size，保持和后面的训练数据统一</span>
y<span class="token operator">=</span>y<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token string">"float32"</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>xlim<span class="token punctuation">,</span>y<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div><p class="x-p">代码中我们在区间<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">36</span><span class="mclose">]</span></span></span></span>取了<code class="x-inline-highlight">400</code>点数据，如果把横轴看成时间轴，可以认为数据集中有<code class="x-inline-highlight">400</code>个连续时间点的数据。</p><div class="x-image-wrapper x-image-invert"><img alt="img" loading="lazy" width="840" height="266" decoding="async" data-nimg="1" style="color:transparent;width:600px;height:auto" src="/_next/static/media/fig1.2b0c9266.png"/></div><p class="x-p no-margin-bottom">现在明确一下我们的方案：</p><div class="x-oli"><div class="x-oli-number">3.</div><div class="x-oli-content-wrapper"><p class="x-p">使用前<code class="x-inline-highlight">80%</code>也就是前<code class="x-inline-highlight">320</code>个数据作为训练集，剩余的作为测试集，观察预测结果。</p></div></div><div class="x-oli"><div class="x-oli-number">4.</div><div class="x-oli-content-wrapper"><p class="x-p">序列长度为<code class="x-inline-highlight">10</code>，也就是模型根据前<code class="x-inline-highlight">10</code>个时间点的数据去预测下一个时间点的数据。</p></div></div><div class="x-oli"><div class="x-oli-number">5.</div><div class="x-oli-content-wrapper"><p class="x-p">这个例子中输入特征的维度是<code class="x-inline-highlight">1</code>，也就是只有<code class="x-inline-highlight">y</code>值一个指标。此外，也不考虑批量大小。</p></div></div><h3 class="x-h2"><span>定义RNN网络</span></h3><div class="x-codeblock"><pre><code><span class="token keyword">class</span> <span class="token class-name">MyRNN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>input_size<span class="token punctuation">,</span>hidden_size<span class="token punctuation">,</span>output_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>linear_ih<span class="token operator">=</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>input_size<span class="token punctuation">,</span>hidden_size<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>linear_hh<span class="token operator">=</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_size<span class="token punctuation">,</span>hidden_size<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>linear_ho<span class="token operator">=</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_size<span class="token punctuation">,</span>output_size<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>tanh<span class="token operator">=</span>nn<span class="token punctuation">.</span>Tanh<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">,</span>prev_state<span class="token punctuation">)</span><span class="token punctuation">:</span>
        curr_state<span class="token operator">=</span>self<span class="token punctuation">.</span>tanh<span class="token punctuation">(</span>
            self<span class="token punctuation">.</span>linear_ih<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token operator">+</span>self<span class="token punctuation">.</span>linear_hh<span class="token punctuation">(</span>prev_state<span class="token punctuation">)</span>
        <span class="token punctuation">)</span>
        output<span class="token operator">=</span>self<span class="token punctuation">.</span>linear_ho<span class="token punctuation">(</span>curr_state<span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> output<span class="token punctuation">,</span>curr_state

hidden_size<span class="token operator">=</span><span class="token number">12</span>
my_rnn<span class="token operator">=</span>MyRNN<span class="token punctuation">(</span>input_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>hidden_size<span class="token operator">=</span>hidden_size<span class="token punctuation">,</span>output_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
loss_func<span class="token operator">=</span>nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
optimizer<span class="token operator">=</span>torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>my_rnn<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span>
</code></pre></div><p class="x-p">这个是一个简单的RNN结构，从网络参数和结构来看很像一个<code class="x-inline-highlight">输入层-隐藏层-输出层</code>的感知机，但是多了一步<code class="x-inline-highlight">隐藏层-隐藏层</code>的连接，RNN的反馈结构就是由此体现的。</p><p class="x-p">并且，注意到<code class="x-inline-highlight">forward</code>函数的输入也需要两个参数：当前时刻输入<code class="x-inline-highlight">x</code>和前一时刻状态<code class="x-inline-highlight">prev_state</code>，同时也会把计算后的新状态<code class="x-inline-highlight">curr_state</code>和<code class="x-inline-highlight">output</code>一起返回，供下一次计算使用。在这里，经过<code class="x-inline-highlight">linear_ho</code>后，<code class="x-inline-highlight">output</code>的<code class="x-inline-highlight">size</code>为<code class="x-inline-highlight">(1,1)</code>，考虑到它仅仅是一个标量，我们把它<code class="x-inline-highlight">resize</code>为<code class="x-inline-highlight">(1)</code>。</p><p class="x-p">接下来设置了一些超参数，隐藏层有<code class="x-inline-highlight">12</code>个神经元，损失函数使用<code class="x-inline-highlight">MSELoss()</code>。</p><h3 class="x-h2"><span>训练</span></h3><p class="x-p">首先定义这样的训练函数：它传入一个序列<code class="x-inline-highlight">train_seq</code>和目标<code class="x-inline-highlight">target</code>。<code class="x-inline-highlight">train_seq</code>的<code class="x-inline-highlight">size</code>应该为<code class="x-inline-highlight">(10,1)</code>，因为我们用前<code class="x-inline-highlight">10</code>个时间点的数据去预测下一个，而输入特征维度是<code class="x-inline-highlight">1</code>；<code class="x-inline-highlight">target</code>的<code class="x-inline-highlight">size</code>应该为<code class="x-inline-highlight">(1)</code>，因为输出只是一个标量。注意我们循环依次输入<code class="x-inline-highlight">train_seq</code>中的<code class="x-inline-highlight">10</code>个数据，迭代更新<code class="x-inline-highlight">state</code>，用最后一次的<code class="x-inline-highlight">output</code>作为最终的输出计算损失。</p><div class="x-codeblock"><pre><code><span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>train_seq<span class="token punctuation">,</span>target<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment">#初始状态</span>
    state<span class="token operator">=</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>hidden_size<span class="token punctuation">)</span>

    <span class="token keyword">for</span> x <span class="token keyword">in</span> train_seq<span class="token punctuation">:</span>
        output<span class="token punctuation">,</span>state<span class="token operator">=</span>my_rnn<span class="token punctuation">(</span>x<span class="token punctuation">,</span>state<span class="token punctuation">)</span>

    loss<span class="token operator">=</span>loss_func<span class="token punctuation">(</span>output<span class="token punctuation">,</span>target<span class="token punctuation">)</span>
    optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
    optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment">#返回损失</span>
    <span class="token keyword">return</span> loss<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
</code></pre></div><p class="x-p">下面代码把真实数据划分成：</p><table class="x-table"><tbody><tr><th><p class="x-p"><code class="x-inline-highlight">train_seq</code></p></th><th><p class="x-p"><code class="x-inline-highlight">target</code></p></th></tr><tr><td><p class="x-p"><code class="x-inline-highlight">y[0]</code>,<code class="x-inline-highlight">y[1]</code>,<code class="x-inline-highlight">y[2]</code>, ... ,<code class="x-inline-highlight">y[9]</code></p></td><td><p class="x-p"><code class="x-inline-highlight">y[10]</code></p></td></tr><tr><td><p class="x-p"><code class="x-inline-highlight">y[1]</code>,<code class="x-inline-highlight">y[2]</code>,<code class="x-inline-highlight">y[3]</code>, ... ,<code class="x-inline-highlight">y[10]</code></p></td><td><p class="x-p"><code class="x-inline-highlight">y[11]</code></p></td></tr><tr><td><p class="x-p"><code class="x-inline-highlight">y[2]</code>,<code class="x-inline-highlight">y[3]</code>,<code class="x-inline-highlight">y[4]</code>, ... ,<code class="x-inline-highlight">y[11]</code></p></td><td><p class="x-p"><code class="x-inline-highlight">y[12]</code></p></td></tr><tr><td>...</td><td>...</td></tr><tr><td><p class="x-p"><code class="x-inline-highlight">y[309]</code>,<code class="x-inline-highlight">y[310]</code>,<code class="x-inline-highlight">y[311]</code>, ... ,<code class="x-inline-highlight">y[318]</code></p></td><td><p class="x-p"><code class="x-inline-highlight">y[319]</code></p></td></tr></tbody></table><div class="x-codeblock"><pre><code>train_datas<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">320</span><span class="token operator">-</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    train_seq<span class="token operator">=</span>torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>y<span class="token punctuation">[</span>i<span class="token punctuation">:</span>i<span class="token operator">+</span><span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    target<span class="token operator">=</span>torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>y<span class="token punctuation">[</span>i<span class="token operator">+</span><span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    train_datas<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span>train_seq<span class="token punctuation">,</span>target<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre></div><p class="x-p">训练网络，绘制误差：</p><div class="x-codeblock"><pre><code>metrics<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>
my_rnn<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> train_seq<span class="token punctuation">,</span>target <span class="token keyword">in</span> train_datas<span class="token punctuation">:</span>
    loss<span class="token operator">=</span>train<span class="token punctuation">(</span>train_seq<span class="token punctuation">,</span>target<span class="token punctuation">)</span>
    metrics<span class="token punctuation">.</span>append<span class="token punctuation">(</span>loss<span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">211</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>metrics<span class="token punctuation">,</span>label<span class="token operator">=</span><span class="token string">"loss"</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div><h3 class="x-h2"><span>预测</span></h3><p class="x-p">这个例子中我们用<span class="x-inline-strong">单步预测</span>观察模型的效果。在单步预测时，每次预测都全部使用真实值；当然，我们可以这样做是因为验证集中本来就包含了真实的数据，换句话说，我们是在已知<code class="x-inline-highlight">t+1</code>时刻的真实数据的情况下，去看看模型使用<code class="x-inline-highlight">t-9</code>~<code class="x-inline-highlight">t</code>时刻的数据，对<code class="x-inline-highlight">t+1</code>时刻的预测值。</p><table class="x-table"><tbody><tr><th><p class="x-p"><code class="x-inline-highlight">input</code></p></th><th><p class="x-p"><code class="x-inline-highlight">prediction</code></p></th></tr><tr><td><p class="x-p"><code class="x-inline-highlight">y[310]</code>,<code class="x-inline-highlight">y[311]</code>,<code class="x-inline-highlight">y[312]</code>, ... ,<code class="x-inline-highlight">y[319]</code></p></td><td><p class="x-p"><code class="x-inline-highlight">pred[320]</code></p></td></tr><tr><td><p class="x-p"><code class="x-inline-highlight">y[311]</code>,<code class="x-inline-highlight">y[312]</code>,<code class="x-inline-highlight">y[313]</code>, ... ,<code class="x-inline-highlight">y[320]</code></p></td><td><p class="x-p"><code class="x-inline-highlight">pred[321]</code></p></td></tr><tr><td><p class="x-p"><code class="x-inline-highlight">y[312]</code>,<code class="x-inline-highlight">y[313]</code>,<code class="x-inline-highlight">y[314]</code>, ... ,<code class="x-inline-highlight">y[321]</code></p></td><td><p class="x-p"><code class="x-inline-highlight">pred[322]</code></p></td></tr><tr><td>...</td><td>...</td></tr></tbody></table><div class="x-codeblock"><pre><code><span class="token keyword">def</span> <span class="token function">pred</span><span class="token punctuation">(</span>truth_seq<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        state<span class="token operator">=</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>hidden_size<span class="token punctuation">)</span>
        <span class="token keyword">for</span> x <span class="token keyword">in</span> truth_seq<span class="token punctuation">:</span>
            output<span class="token punctuation">,</span>state<span class="token operator">=</span>my_rnn<span class="token punctuation">(</span>x<span class="token punctuation">,</span>state<span class="token punctuation">)</span>
        <span class="token keyword">return</span> output

preds<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">320</span><span class="token operator">-</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">400</span><span class="token operator">-</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    truth_seq<span class="token operator">=</span>torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>y<span class="token punctuation">[</span>i<span class="token punctuation">:</span>i<span class="token operator">+</span><span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    preds<span class="token punctuation">.</span>append<span class="token punctuation">(</span>pred<span class="token punctuation">(</span>truth_seq<span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
preds<span class="token operator">=</span>numpy<span class="token punctuation">.</span>array<span class="token punctuation">(</span>preds<span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">212</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>xlim<span class="token punctuation">,</span>y<span class="token punctuation">,</span>label<span class="token operator">=</span><span class="token string">"truth"</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>xlim<span class="token punctuation">[</span><span class="token number">320</span><span class="token punctuation">:</span><span class="token number">400</span><span class="token punctuation">]</span><span class="token punctuation">,</span>preds<span class="token punctuation">,</span><span class="token string">"red"</span><span class="token punctuation">,</span>label<span class="token operator">=</span><span class="token string">"predict"</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div><p class="x-p">如果我们不只是在测试集上评估模型性能，而是去预测真实生活中的问题，例如未来<code class="x-inline-highlight">7</code>天的温度；或者假如我们的数据集到<code class="x-inline-highlight">y[319]</code>就截止了，这时如果想得到后面多个时刻的数据，就需要<span class="x-inline-strong">多步预测</span>，此时上一时刻的预测会被当做新的输入：</p><table class="x-table"><tbody><tr><th><p class="x-p"><code class="x-inline-highlight">input</code></p></th><th><p class="x-p"><code class="x-inline-highlight">prediction</code></p></th></tr><tr><td><p class="x-p"><code class="x-inline-highlight">y[310]</code>,<code class="x-inline-highlight">y[311]</code>,<code class="x-inline-highlight">y[312]</code>, ... ,<code class="x-inline-highlight">y[319]</code></p></td><td><p class="x-p"><code class="x-inline-highlight">pred[320]</code></p></td></tr><tr><td><p class="x-p"><code class="x-inline-highlight">y[311]</code>,<code class="x-inline-highlight">y[312]</code>,<code class="x-inline-highlight">y[313]</code>, ... ,<code class="x-inline-highlight">pred[320]</code></p></td><td><p class="x-p"><code class="x-inline-highlight">pred[321]</code></p></td></tr><tr><td><p class="x-p"><code class="x-inline-highlight">y[312]</code>,<code class="x-inline-highlight">y[313]</code>,<code class="x-inline-highlight">y[314]</code>, ... ,<code class="x-inline-highlight">pred[320]</code>,<code class="x-inline-highlight">pred[321]</code></p></td><td><p class="x-p"><code class="x-inline-highlight">pred[322]</code></p></td></tr><tr><td>...</td><td>...</td></tr></tbody></table><p class="x-p">多步预测会导致误差的累积。</p><h3 class="x-h2"><span>看看效果</span></h3><p class="x-p">如果不执行训练步骤的代码，使用初始随机参数的模型预测结果是：</p><div class="x-image-wrapper x-image-invert"><img alt="img" loading="lazy" width="840" height="261" decoding="async" data-nimg="1" style="color:transparent;width:600px;height:auto" src="/_next/static/media/fig2.51ee0782.png"/></div><p class="x-p">经过训练后，每次训练的<code class="x-inline-highlight">loss</code>和最终的预测：</p><div class="x-image-wrapper x-image-invert"><img alt="img" loading="lazy" width="840" height="543" decoding="async" data-nimg="1" style="color:transparent;width:600px;height:auto" src="/_next/static/media/fig3.6f6f5b35.png"/></div><h3 class="x-h2"><span>使用torch.nn.RNN</span></h3><p class="x-p">使用<code class="x-inline-highlight">torch.nn.RNN</code>模块时，与上面例子中手动实现的RNN有几处细小的区别，下面给出了使用<code class="x-inline-highlight">torch.nn.RNN</code>时需要做出的修改：</p><div class="x-oli"><div class="x-oli-number">1.</div><div class="x-oli-content-wrapper"><p class="x-p no-margin-bottom">定义模型时，不再需要显式指定<code class="x-inline-highlight">linear_ih</code>和<code class="x-inline-highlight">linear_hh</code>两层，将由<code class="x-inline-highlight">nn.RNN</code>模块实现；<code class="x-inline-highlight">nn.RNN</code>模块没有定义输出层，因此输出层<code class="x-inline-highlight">linear_ho</code>需要设置。<br/> 在<code class="x-inline-highlight">forward</code>函数中，手动实现时为了直观展示出RNN的迭代过程，只进行了一次隐藏状态的更新；而对于输入序列迭代更新隐藏状态是在训练和预测时实现的。而<code class="x-inline-highlight">nn.RNN</code>模块的一次<code class="x-inline-highlight">forward</code>就已经完成了迭代更新，其输入是整个序列<code class="x-inline-highlight">seq</code>和<code class="x-inline-highlight">prev_state</code>，返回值是<code class="x-inline-highlight">output_hidden,curr_state</code>，对于不考虑批量大小的数据，它们的<code class="x-inline-highlight">size</code>为：</p><div class="x-uli"><div class="x-uli-marker"><div class="x-uli-marker-dot"></div></div><div class="x-uli-content-wrapper"><p class="x-p"><code class="x-inline-highlight">seq</code>: <code class="x-inline-highlight">(sequence_length, input_size)</code></p></div></div><div class="x-uli"><div class="x-uli-marker"><div class="x-uli-marker-dot"></div></div><div class="x-uli-content-wrapper"><p class="x-p"><code class="x-inline-highlight">init_state</code>: <code class="x-inline-highlight">(1, hidden_size)</code></p></div></div><div class="x-uli"><div class="x-uli-marker"><div class="x-uli-marker-dot"></div></div><div class="x-uli-content-wrapper"><p class="x-p"><code class="x-inline-highlight">output_hidden</code>: <code class="x-inline-highlight">(sequence_length, hidden_size)</code></p></div></div><div class="x-uli"><div class="x-uli-marker"><div class="x-uli-marker-dot"></div></div><div class="x-uli-content-wrapper"><p class="x-p"><code class="x-inline-highlight">state</code>: <code class="x-inline-highlight">(1, hidden_size)</code></p></div></div><p class="x-p">最后在我们定义的<code class="x-inline-highlight">MyRNN</code>模块中，用<code class="x-inline-highlight">output_hidden</code>的最后一个时间点的输出，经过输出层得到最终的<code class="x-inline-highlight">output</code>。</p></div></div><div class="x-highlightblock highlight-background-gray"><h4 class="x-h3">手动实现</h4><div class="x-codeblock"><pre><code><span class="token keyword">class</span> <span class="token class-name">MyRNN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>input_size<span class="token punctuation">,</span>hidden_size<span class="token punctuation">,</span>output_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>linear_ih<span class="token operator">=</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>input_size<span class="token punctuation">,</span>hidden_size<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>linear_hh<span class="token operator">=</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_size<span class="token punctuation">,</span>hidden_size<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>linear_ho<span class="token operator">=</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_size<span class="token punctuation">,</span>output_size<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>tanh<span class="token operator">=</span>nn<span class="token punctuation">.</span>Tanh<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">,</span>prev_state<span class="token punctuation">)</span><span class="token punctuation">:</span>
        curr_state<span class="token operator">=</span>self<span class="token punctuation">.</span>tanh<span class="token punctuation">(</span>
            self<span class="token punctuation">.</span>linear_ih<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token operator">+</span>self<span class="token punctuation">.</span>linear_hh<span class="token punctuation">(</span>prev_state<span class="token punctuation">)</span>
        <span class="token punctuation">)</span>
        output<span class="token operator">=</span>self<span class="token punctuation">.</span>linear_ho<span class="token punctuation">(</span>curr_state<span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> output<span class="token punctuation">,</span>curr_state
</code></pre></div><h4 class="x-h3">使用torch.nn.RNN</h4><div class="x-codeblock"><pre><code><span class="token keyword">class</span> <span class="token class-name">MyRNN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>input_size<span class="token punctuation">,</span>hidden_size<span class="token punctuation">,</span>output_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>rnn<span class="token operator">=</span>nn<span class="token punctuation">.</span>RNN<span class="token punctuation">(</span>input_size<span class="token operator">=</span>input_size<span class="token punctuation">,</span>hidden_size<span class="token operator">=</span>hidden_size<span class="token punctuation">,</span>batch_first<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>linear_ho<span class="token operator">=</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_size<span class="token punctuation">,</span>output_size<span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>seq<span class="token punctuation">,</span>init_state<span class="token punctuation">)</span><span class="token punctuation">:</span>
        output_hidden<span class="token punctuation">,</span>tate<span class="token operator">=</span>self<span class="token punctuation">.</span>rnn<span class="token punctuation">(</span>seq<span class="token punctuation">,</span>init_state<span class="token punctuation">)</span>
        output<span class="token operator">=</span>self<span class="token punctuation">.</span>linear_ho<span class="token punctuation">(</span>output_hidden<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment">#取最后一个时间点的输出</span>
        <span class="token keyword">return</span> output<span class="token punctuation">,</span>state
</code></pre></div></div><div class="x-oli"><div class="x-oli-number">2.</div><div class="x-oli-content-wrapper"><p class="x-p">训练和预测时，也不需要再遍历序列，迭代的过程已经在<code class="x-inline-highlight">nn.RNN</code>模块内部实现。</p></div></div><div class="x-highlightblock highlight-background-gray"><h4 class="x-h3">手动实现</h4><div class="x-codeblock"><pre><code><span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>train_seq<span class="token punctuation">,</span>target<span class="token punctuation">)</span><span class="token punctuation">:</span>
    state<span class="token operator">=</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>hidden_size<span class="token punctuation">)</span>
    <span class="token keyword">for</span> x <span class="token keyword">in</span> train_seq<span class="token punctuation">:</span>
        output<span class="token punctuation">,</span>state<span class="token operator">=</span>my_rnn<span class="token punctuation">(</span>x<span class="token punctuation">,</span>state<span class="token punctuation">)</span>
    loss<span class="token operator">=</span>loss_func<span class="token punctuation">(</span>output<span class="token punctuation">,</span>target<span class="token punctuation">)</span>
    <span class="token comment"># ......</span>
</code></pre></div><div class="x-codeblock"><pre><code><span class="token keyword">def</span> <span class="token function">pred</span><span class="token punctuation">(</span>truth_seq<span class="token punctuation">,</span>net<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        state<span class="token operator">=</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>hidden_size<span class="token punctuation">)</span>
        <span class="token keyword">for</span> x <span class="token keyword">in</span> truth_seq<span class="token punctuation">:</span>
            output<span class="token punctuation">,</span>state<span class="token operator">=</span>net<span class="token punctuation">(</span>x<span class="token punctuation">,</span>state<span class="token punctuation">)</span>
        <span class="token keyword">return</span> output
</code></pre></div><h4 class="x-h3">使用torch.nn.RNN</h4><div class="x-codeblock"><pre><code><span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>train_seq<span class="token punctuation">,</span>target<span class="token punctuation">)</span><span class="token punctuation">:</span>
    state<span class="token operator">=</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>hidden_size<span class="token punctuation">)</span>
    output<span class="token punctuation">,</span>_<span class="token operator">=</span>my_rnn<span class="token punctuation">(</span>train_seq<span class="token punctuation">,</span>state<span class="token punctuation">)</span> <span class="token comment">#一次得到输出</span>
    loss<span class="token operator">=</span>loss_func<span class="token punctuation">(</span>output<span class="token punctuation">,</span>target<span class="token punctuation">)</span>
    <span class="token comment"># ......</span>
</code></pre></div><div class="x-codeblock"><pre><code><span class="token keyword">def</span> <span class="token function">pred</span><span class="token punctuation">(</span>truth_seq<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        state<span class="token operator">=</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>hidden_size<span class="token punctuation">)</span>
        output<span class="token punctuation">,</span>_<span class="token operator">=</span>my_rnn<span class="token punctuation">(</span>truth_seq<span class="token punctuation">,</span>state<span class="token punctuation">)</span> <span class="token comment">#一次得到输出</span>
        <span class="token keyword">return</span> output
</code></pre></div></div><h3 class="x-h2"><span>FAQ</span></h3><p class="x-p">初次了解RNN时，我在一些问题上困惑了很久。这个版块是对它们的再次整理。（尽管有些已经包含在上述例子中了！）</p><h4 class="x-h3">用10步预测下1步，为什么 input_size 不是10，而是1？</h4><p class="x-p"><code class="x-inline-highlight">input_size</code>与序列长度并非同一个概念。用前<code class="x-inline-highlight">10</code>个时间点的数据去预测下一个，这里的<code class="x-inline-highlight">10</code>是序列长度；而<code class="x-inline-highlight">input_size</code>是输入特征的维度。由于这个例子较为简单，只是用历史的<code class="x-inline-highlight">y</code>值预测新的<code class="x-inline-highlight">y</code>值，因此特征只有<code class="x-inline-highlight">1</code>维。</p><h4 class="x-h3">什么时候 input_size 不是1？</h4><p class="x-p">例如我们在预测未来气温时，历史气温数据并不是唯一的参考，还可能参考历史的风速、气压、天气情况等等，此时输入数据将会是一个<code class="x-inline-highlight">input_size</code>维的向量。</p><h4 class="x-h3">hidden_size=12，12是在哪里体现的？</h4><p class="x-p"><code class="x-inline-highlight">12</code>只是模型的超参数，和MLP中隐藏层大小一样，并没有太多的物理含义。</p><h4 class="x-h3">训练时，每次迭代用哪些数据？应该遍历几遍数据集？每个 epoch 会使用哪些数据进行参数优化？</h4><p class="x-p no-margin-bottom">在训练一个CNN网络时（例如一个图片分类网络），策略通常是：</p><div class="x-oli"><div class="x-oli-number">1.</div><div class="x-oli-content-wrapper"><p class="x-p">指定超参数<code class="x-inline-highlight">num_epoch</code>，在每个<code class="x-inline-highlight">epoch</code>中随机遍历训练集中的所有图像进行参数优化；</p></div></div><div class="x-oli"><div class="x-oli-number">2.</div><div class="x-oli-content-wrapper"><p class="x-p">重复执行<code class="x-inline-highlight">num_epoch</code>次。</p></div></div><p class="x-p with-margin-top no-margin-bottom">然而对于RNN来说这个概念似乎并不清晰，例如上述例子的训练策略是：</p><div class="x-oli"><div class="x-oli-number">1.</div><div class="x-oli-content-wrapper"><p class="x-p">从<code class="x-inline-highlight">0</code>到<code class="x-inline-highlight">(训练集大小 - 序列长度)</code>依次遍历起始时间<code class="x-inline-highlight">t</code>；</p></div></div><div class="x-oli"><div class="x-oli-number">2.</div><div class="x-oli-content-wrapper"><p class="x-p">对于每个起始时间<code class="x-inline-highlight">t</code>，将<code class="x-inline-highlight">y[t]</code>~<code class="x-inline-highlight">y[t+9]</code>为输入，<code class="x-inline-highlight">y[t+10]</code>为真值作为一组训练样本。</p></div></div><div class="x-oli"><div class="x-oli-number">3.</div><div class="x-oli-content-wrapper"><p class="x-p">第<code class="x-inline-highlight">1</code>步只遍历了一次！</p></div></div><p class="x-p with-margin-top no-margin-bottom">或者：</p><p class="x-p no-margin-bottom">...</p><div class="x-oli"><div class="x-oli-number">3.</div><div class="x-oli-content-wrapper"><p class="x-p">前两步同上，但多次遍历训练集。</p></div></div><p class="x-p with-margin-top no-margin-bottom">另一个常用的策略是：</p><div class="x-oli"><div class="x-oli-number">1.</div><div class="x-oli-content-wrapper"><p class="x-p">指定超参数：训练轮次<code class="x-inline-highlight">num_iter</code>；</p></div></div><div class="x-oli"><div class="x-oli-number">2.</div><div class="x-oli-content-wrapper"><p class="x-p">重复执行<code class="x-inline-highlight">num_iter</code>次，每次随机抽取一个起始时间<code class="x-inline-highlight">t</code>，并且将<code class="x-inline-highlight">y[t]</code>~<code class="x-inline-highlight">y[t+9]</code>为输入，<code class="x-inline-highlight">y[t+10]</code>为真值作为一组训练样本。</p></div></div><h2 class="x-h1"><span>LSTM：一篇很好的博客</span></h2><p class="x-p">以下的内容和插图总结或翻译自这篇的英文博客：<a href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/" target="_blank" rel="noreferrer" class="x-inline-link">Understanding LSTM Networks</a></p><h3 class="x-h2"><span>长期依赖问题</span></h3><p class="x-p">RNN可以利用先前的信息理解当前的任务，这点非常不错；有时我们只需要短期的信息，例如一个语言模型预测下面的句子：<br/> <code class="x-inline-highlight">天空中飘着一朵白色的【云】</code>，这很简单。但有些时候我们需要更多背景信息，例如：<br/><code class="x-inline-highlight">我出生在法国，…… ，我可以说流利的【法语】</code>，这个情况下，随着前后文距离变大，RNN对长期依赖关系的学习会变得困难。</p><h3 class="x-h2"><span>LSTM</span></h3><p class="x-p"><span class="x-inline-strong">长短期记忆网络</span><code class="x-inline-highlight">(Long Short-Term Memory, LSTM)</code>是一种特殊的RNN，可以学习长期依赖。以RNN为例，循环神经网络随时间展开通常具有如下的示意图：</p><div class="x-image-wrapper x-image-invert"><img alt="img" loading="lazy" width="2242" height="839" decoding="async" data-nimg="1" style="color:transparent;width:600px;height:auto" src="/_next/static/media/rnn2.d1dd71bb.png"/></div><p class="x-p">对于RNN来说，利用历史状态和输入得到新的状态，只经过一个简单的<code class="x-inline-highlight">tanh</code>激活层，而对于LSTM来说，它的示意图略显复杂：</p><div class="x-image-wrapper x-image-invert"><img alt="img" loading="lazy" width="2233" height="839" decoding="async" data-nimg="1" style="color:transparent;width:600px;height:auto" src="/_next/static/media/lstm1.83284ab3.png"/></div><p class="x-p">在上图中，每条线表示一个向量，粉红色圆圈表示逐点式操作，黄色的方框是神经网络的层。这看起来很眼晕，不过我们接下来会一点点的解释图里的内容。</p><h3 class="x-h2"><span>门控单元</span></h3><p class="x-p">下面的结构称为门控单元：</p><div class="x-image-wrapper x-image-invert"><img alt="img" loading="lazy" width="198" height="242" decoding="async" data-nimg="1" style="color:transparent;width:100px;height:auto" src="/_next/static/media/lstm2.96d0a9a3.png"/></div><p class="x-p">门控单元控制信息量通过的多少，通过向量<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span></span></span></span>来控制<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">x</span></span></span></span>通过的信息量：</p><div class="x-formula"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">o</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⊗</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">x</span></span></span></span></div><p class="x-p">式子中<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em;"></span><span class="mord">⊗</span></span></span></span>表示按位置相乘，<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mclose">)</span></span></span></span>的每个元素输出范围是<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">1</span><span class="mclose">]</span></span></span></span>，某个元素接近<code class="x-inline-highlight">1</code>，<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">x</span></span></span></span>对应位置保留的信息就越多，反之就越少。</p><h3 class="x-h2"><span>逐部分分析LSTM</span></h3><h4 class="x-h3">遗忘门</h4><p class="x-p">LSTM的第一步是决定什么应该被遗忘，也就是对上一个<span class="x-inline-strong">单元</span><code class="x-inline-highlight">(cell)</code>状态信息选择性的遗忘。<br/> 这个操作由遗忘门<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>实现，将其<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">1</span><span class="mclose">]</span></span></span></span>范围的输出按位置与单元上一时刻状态相乘。</p><div class="x-image-wrapper x-image-invert"><img alt="img" loading="lazy" width="1826" height="564" decoding="async" data-nimg="1" style="color:transparent;width:600px;height:auto" src="/_next/static/media/lstm3.ac9b9ff5.png"/></div><div class="x-highlightblock highlight-background-gray"><p class="x-p">举一个概念性的例子：</p><p class="x-p">考虑一个语言模型，输入一个句子：<code class="x-inline-highlight">Alice是一名女教师，她喜欢给学生讲课；Bob是一位男司机，他喝酒上瘾。</code></p><p class="x-p">当模型看到<code class="x-inline-highlight">Alice是一名女教师，……</code>时，单元状态中可能存储了和主语<code class="x-inline-highlight">Alice</code>和<code class="x-inline-highlight">女教师</code>有关的语义信息，以便在后文输出合适的代词<code class="x-inline-highlight">她</code>；然后，当模型看到<code class="x-inline-highlight">Alice是一名女教师，她喜欢给学生讲课；Bob是一位男司机，……</code>时，我们希望在看到新主语<code class="x-inline-highlight">Bob</code>和<code class="x-inline-highlight">男司机</code>之后，忘记此前存储的旧主语的性别语义。也就是对旧单元状态<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8917em;vertical-align:-0.2083em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em;"><span></span></span></span></span></span></span></span></span></span>乘上较小的<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>。</p></div><h4 class="x-h3">输入门</h4><p class="x-p">下一步就是决定要在单元中存入什么新的信息。这一部分有两路：<code class="x-inline-highlight">tanh</code>这一路与普通RNN很像，生成一个中间状态；<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span></span></span></span>这一路被称为输入门<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8095em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，控制这个中间状态有多少信息被存入单元。</p><div class="x-image-wrapper x-image-invert"><img alt="img" loading="lazy" width="1826" height="564" decoding="async" data-nimg="1" style="color:transparent;width:600px;height:auto" src="/_next/static/media/lstm4.00cef2df.png"/></div><p class="x-p">经历这两步之后，便可以相加得到新的单元状态：</p><div class="x-image-wrapper x-image-invert"><img alt="img" loading="lazy" width="1826" height="564" decoding="async" data-nimg="1" style="color:transparent;width:600px;height:auto" src="/_next/static/media/lstm5.3f95c1ad.png"/></div><div class="x-highlightblock highlight-background-gray"><p class="x-p">同理，当模型看到<code class="x-inline-highlight">Bob是一位男司机</code>时，我们可能会想丢掉此前的语义信息<code class="x-inline-highlight">女性</code>，并把新的语义信息<code class="x-inline-highlight">男性</code>存入单元状态，使得后文输出正确的代词<code class="x-inline-highlight">他</code>。</p></div><h4 class="x-h3">输出门</h4><p class="x-p">最后是决定新的隐藏状态，这个输出会基于单元状态，但会经过门控单元。输出门<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">o</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>决定经过<code class="x-inline-highlight">tanh</code>的单元状态<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>有多少被输出到下一时刻的隐藏状态。</p><div class="x-image-wrapper x-image-invert"><img alt="img" loading="lazy" width="1826" height="564" decoding="async" data-nimg="1" style="color:transparent;width:600px;height:auto" src="/_next/static/media/lstm6.7eca3c69.png"/></div><div class="x-highlightblock highlight-background-gray"><p class="x-p">当看到<code class="x-inline-highlight">Bob是一位男司机，他……</code>时，由于出现了主语<code class="x-inline-highlight">他</code>，模型可能会输出和<code class="x-inline-highlight">谓语动词</code>有关的语义信息。</p></div></div><div id="sidebar"><div class="sidebar-list show-list"><div class="sidebar-list-head"><h3 class="sidebar-list-category">网络杂识 (4)</h3><div class="sidebar-list-category-rightarrow"><svg viewBox="0 0 1024 1024" width="16px" height="16px" xmlns="http://www.w3.org/2000/svg"><path d="M761.056 532.128c.512-.992 1.344-1.824 1.792-2.848 8.8-18.304 5.92-40.704-9.664-55.424L399.936 139.744c-19.264-18.208-49.632-17.344-67.872 1.888-18.208 19.264-17.376 49.632 1.888 67.872l316.96 299.84L335.2 813.632c-19.072 18.4-19.648 48.768-1.248 67.872 9.408 9.792 21.984 14.688 34.56 14.688 12 0 24-4.48 33.312-13.44l350.048-337.376c.672-.672.928-1.6 1.6-2.304.512-.48 1.056-.832 1.568-1.344 2.72-2.848 4.16-6.336 6.016-9.6z" fill="#50505c"></path></svg></div></div><div class="sidebar-list-ul-wrapper"><ul class="sidebar-list-ul"><li class="sidebar-list-li"><a class="sidebar-list-link" href="/23d/database-3nf/"><span class="sidebar-list-title">数据库设计三大范式</span></a></li><li class="sidebar-list-li"><a class="sidebar-list-link" href="/23d/github-linguist-vendored/"><span class="sidebar-list-title">不统计Github仓库某个目录下的语言</span></a></li><li class="sidebar-list-li"><a class="sidebar-list-link" href="/24a/deepl-shortcut-setting/"><span class="sidebar-list-title">解决：DeepL该快捷键已被使用</span></a></li><li class="sidebar-list-li"><a class="sidebar-list-link" href="/24a/git-merge-allow-unrelated-histories/"><span class="sidebar-list-title">记录：使用--allow-unrelated-histories</span></a></li></ul></div></div><div class="sidebar-list show-list"><div class="sidebar-list-head"><h3 class="sidebar-list-category">算法 (8)</h3><div class="sidebar-list-category-rightarrow"><svg viewBox="0 0 1024 1024" width="16px" height="16px" xmlns="http://www.w3.org/2000/svg"><path d="M761.056 532.128c.512-.992 1.344-1.824 1.792-2.848 8.8-18.304 5.92-40.704-9.664-55.424L399.936 139.744c-19.264-18.208-49.632-17.344-67.872 1.888-18.208 19.264-17.376 49.632 1.888 67.872l316.96 299.84L335.2 813.632c-19.072 18.4-19.648 48.768-1.248 67.872 9.408 9.792 21.984 14.688 34.56 14.688 12 0 24-4.48 33.312-13.44l350.048-337.376c.672-.672.928-1.6 1.6-2.304.512-.48 1.056-.832 1.568-1.344 2.72-2.848 4.16-6.336 6.016-9.6z" fill="#50505c"></path></svg></div></div><div class="sidebar-list-ul-wrapper"><ul class="sidebar-list-ul"><li class="sidebar-list-li"><a class="sidebar-list-link" href="/24a/cpp-stl/"><span class="sidebar-list-title">C++中STL的基本使用</span></a></li><li class="sidebar-list-li"><a class="sidebar-list-link" href="/24a/csp-2016-04/"><span class="sidebar-list-title">CSP 201604 T1-T4题解</span></a></li><li class="sidebar-list-li"><a class="sidebar-list-link" href="/24a/csp-2018-03/"><span class="sidebar-list-title">CSP 201803 T1-T4题解</span></a></li><li class="sidebar-list-li"><a class="sidebar-list-link" href="/24a/csp-2020-06/"><span class="sidebar-list-title">CSP 202006 T1-T4题解</span></a></li><li class="sidebar-list-li"><a class="sidebar-list-link" href="/24a/csp-2020-09/"><span class="sidebar-list-title">CSP 202009 T1-T4题解</span></a></li><li class="sidebar-list-li"><a class="sidebar-list-link" href="/24a/csp-2020-12/"><span class="sidebar-list-title">CSP 202012 T1-T5题解</span></a></li><li class="sidebar-list-li"><a class="sidebar-list-link" href="/24a/csp-2023-05/"><span class="sidebar-list-title">CSP 202305 T1-T4题解</span></a></li><li class="sidebar-list-li"><a class="sidebar-list-link" href="/24a/csp-2023-09/"><span class="sidebar-list-title">CSP 202309 T1-T4题解</span></a></li></ul></div></div><div class="sidebar-list show-list"><div class="sidebar-list-head"><h3 class="sidebar-list-category">深度学习 (5)</h3><div class="sidebar-list-category-rightarrow"><svg viewBox="0 0 1024 1024" width="16px" height="16px" xmlns="http://www.w3.org/2000/svg"><path d="M761.056 532.128c.512-.992 1.344-1.824 1.792-2.848 8.8-18.304 5.92-40.704-9.664-55.424L399.936 139.744c-19.264-18.208-49.632-17.344-67.872 1.888-18.208 19.264-17.376 49.632 1.888 67.872l316.96 299.84L335.2 813.632c-19.072 18.4-19.648 48.768-1.248 67.872 9.408 9.792 21.984 14.688 34.56 14.688 12 0 24-4.48 33.312-13.44l350.048-337.376c.672-.672.928-1.6 1.6-2.304.512-.48 1.056-.832 1.568-1.344 2.72-2.848 4.16-6.336 6.016-9.6z" fill="#50505c"></path></svg></div></div><div class="sidebar-list-ul-wrapper"><ul class="sidebar-list-ul"><li class="sidebar-list-li"><a class="sidebar-list-link" href="/longtime/papers/"><span class="sidebar-list-title">论文速记</span></a></li><li class="sidebar-list-li"><a class="sidebar-list-link" href="/23d/r2plus1d/"><span class="sidebar-list-title">行为识别R(2+1)D网络</span></a></li><li class="sidebar-list-li"><a class="sidebar-list-link" href="/23d/object-detection-map/"><span class="sidebar-list-title">目标检测评价指标mAP</span></a></li><li class="sidebar-list-li active"><a class="sidebar-list-link" href="/23d/learn-rnn-lstm/"><span class="sidebar-list-title">学习RNN和LSTM</span></a></li><li class="sidebar-list-li"><a class="sidebar-list-link" href="/24a/reproduce-nerf-rpn/"><span class="sidebar-list-title">记录：复现NeRF-RPN代码</span></a></li></ul></div></div><div class="sidebar-list show-list"><div class="sidebar-list-head"><h3 class="sidebar-list-category">Python学习 (2)</h3><div class="sidebar-list-category-rightarrow"><svg viewBox="0 0 1024 1024" width="16px" height="16px" xmlns="http://www.w3.org/2000/svg"><path d="M761.056 532.128c.512-.992 1.344-1.824 1.792-2.848 8.8-18.304 5.92-40.704-9.664-55.424L399.936 139.744c-19.264-18.208-49.632-17.344-67.872 1.888-18.208 19.264-17.376 49.632 1.888 67.872l316.96 299.84L335.2 813.632c-19.072 18.4-19.648 48.768-1.248 67.872 9.408 9.792 21.984 14.688 34.56 14.688 12 0 24-4.48 33.312-13.44l350.048-337.376c.672-.672.928-1.6 1.6-2.304.512-.48 1.056-.832 1.568-1.344 2.72-2.848 4.16-6.336 6.016-9.6z" fill="#50505c"></path></svg></div></div><div class="sidebar-list-ul-wrapper"><ul class="sidebar-list-ul"><li class="sidebar-list-li"><a class="sidebar-list-link" href="/24a/torch-numpy-topk/"><span class="sidebar-list-title">在pytorch和numpy中取top-k值和索引</span></a></li><li class="sidebar-list-li"><a class="sidebar-list-link" href="/24a/object-oriented-programming-python/"><span class="sidebar-list-title">Python面向对象编程</span></a></li></ul></div></div><div class="sidebar-list show-list"><div class="sidebar-list-head"><h3 class="sidebar-list-category">前端与JavaScript (2)</h3><div class="sidebar-list-category-rightarrow"><svg viewBox="0 0 1024 1024" width="16px" height="16px" xmlns="http://www.w3.org/2000/svg"><path d="M761.056 532.128c.512-.992 1.344-1.824 1.792-2.848 8.8-18.304 5.92-40.704-9.664-55.424L399.936 139.744c-19.264-18.208-49.632-17.344-67.872 1.888-18.208 19.264-17.376 49.632 1.888 67.872l316.96 299.84L335.2 813.632c-19.072 18.4-19.648 48.768-1.248 67.872 9.408 9.792 21.984 14.688 34.56 14.688 12 0 24-4.48 33.312-13.44l350.048-337.376c.672-.672.928-1.6 1.6-2.304.512-.48 1.056-.832 1.568-1.344 2.72-2.848 4.16-6.336 6.016-9.6z" fill="#50505c"></path></svg></div></div><div class="sidebar-list-ul-wrapper"><ul class="sidebar-list-ul"><li class="sidebar-list-li"><a class="sidebar-list-link" href="/23c/js-array/"><span class="sidebar-list-title">JavaScript数组常用方法</span></a></li><li class="sidebar-list-li"><a class="sidebar-list-link" href="/23d/css-auto-height-transition/"><span class="sidebar-list-title">CSS实现auto高度的过渡动画</span></a></li></ul></div></div><div class="sidebar-list show-list"><div class="sidebar-list-head"><h3 class="sidebar-list-category">课程 (11)</h3><div class="sidebar-list-category-rightarrow"><svg viewBox="0 0 1024 1024" width="16px" height="16px" xmlns="http://www.w3.org/2000/svg"><path d="M761.056 532.128c.512-.992 1.344-1.824 1.792-2.848 8.8-18.304 5.92-40.704-9.664-55.424L399.936 139.744c-19.264-18.208-49.632-17.344-67.872 1.888-18.208 19.264-17.376 49.632 1.888 67.872l316.96 299.84L335.2 813.632c-19.072 18.4-19.648 48.768-1.248 67.872 9.408 9.792 21.984 14.688 34.56 14.688 12 0 24-4.48 33.312-13.44l350.048-337.376c.672-.672.928-1.6 1.6-2.304.512-.48 1.056-.832 1.568-1.344 2.72-2.848 4.16-6.336 6.016-9.6z" fill="#50505c"></path></svg></div></div><div class="sidebar-list-ul-wrapper"><ul class="sidebar-list-ul"><li class="sidebar-list-li"><a class="sidebar-list-link" href="/23c/pattern-recognition-1/"><span class="sidebar-list-title">【模式识别】统计决策方法</span></a></li><li class="sidebar-list-li"><a class="sidebar-list-link" href="/23c/pattern-recognition-2/"><span class="sidebar-list-title">【模式识别】参数估计</span></a></li><li class="sidebar-list-li"><a class="sidebar-list-link" href="/23c/pattern-recognition-3/"><span class="sidebar-list-title">【模式识别】非参数估计</span></a></li><li class="sidebar-list-li"><a class="sidebar-list-link" href="/23d/pattern-recognition-4/"><span class="sidebar-list-title">【模式识别】线性学习器与线性分类器</span></a></li><li class="sidebar-list-li"><a class="sidebar-list-link" href="/23d/protocols/"><span class="sidebar-list-title">【计算机网络】协议总结</span></a></li><li class="sidebar-list-li"><a class="sidebar-list-link" href="/24a/machine-learning-exercises/"><span class="sidebar-list-title">【机器学习】习题</span></a></li><li class="sidebar-list-li"><a class="sidebar-list-link" href="/24a/games101-01-transformation/"><span class="sidebar-list-title">【GAMES101】Transformation</span></a></li><li class="sidebar-list-li"><a class="sidebar-list-link" href="/24a/games101-02-rasterization/"><span class="sidebar-list-title">【GAMES101】Rasterization</span></a></li><li class="sidebar-list-li"><a class="sidebar-list-link" href="/24a/games101-03-shading/"><span class="sidebar-list-title">【GAMES101】Shading</span></a></li><li class="sidebar-list-li"><a class="sidebar-list-link" href="/24a/games101-04-geometry/"><span class="sidebar-list-title">【GAMES101】Geometry</span></a></li><li class="sidebar-list-li"><a class="sidebar-list-link" href="/24a/games101-05-ray-tracing/"><span class="sidebar-list-title">【GAMES101】Ray Tracing</span></a></li></ul></div></div><div class="sidebar-list show-list"><div class="sidebar-list-head"><h3 class="sidebar-list-category">其他 (2)</h3><div class="sidebar-list-category-rightarrow"><svg viewBox="0 0 1024 1024" width="16px" height="16px" xmlns="http://www.w3.org/2000/svg"><path d="M761.056 532.128c.512-.992 1.344-1.824 1.792-2.848 8.8-18.304 5.92-40.704-9.664-55.424L399.936 139.744c-19.264-18.208-49.632-17.344-67.872 1.888-18.208 19.264-17.376 49.632 1.888 67.872l316.96 299.84L335.2 813.632c-19.072 18.4-19.648 48.768-1.248 67.872 9.408 9.792 21.984 14.688 34.56 14.688 12 0 24-4.48 33.312-13.44l350.048-337.376c.672-.672.928-1.6 1.6-2.304.512-.48 1.056-.832 1.568-1.344 2.72-2.848 4.16-6.336 6.016-9.6z" fill="#50505c"></path></svg></div></div><div class="sidebar-list-ul-wrapper"><ul class="sidebar-list-ul"><li class="sidebar-list-li"><a class="sidebar-list-link" href="/longtime/demo/"><span class="sidebar-list-title">示例</span></a></li><li class="sidebar-list-li"><a class="sidebar-list-link" href="/longtime/updates/"><span class="sidebar-list-title">更新日志</span></a></li></ul></div></div></div><div id="sidebar-mask"></div></div><script src="/_next/static/chunks/webpack-f1f308b83e7ce1fe.js" crossorigin="" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0]);self.__next_f.push([2,null])</script><script>self.__next_f.push([1,"1:HL[\"/_next/static/css/e43a733539111c31.css\",\"style\",{\"crossOrigin\":\"\"}]\n0:\"$L2\"\n"])</script><script>self.__next_f.push([1,"3:HL[\"/_next/static/css/803fe687e7e31b6c.css\",\"style\",{\"crossOrigin\":\"\"}]\n4:HL[\"/_next/static/css/2ca3ce358f319fca.css\",\"style\",{\"crossOrigin\":\"\"}]\n"])</script><script>self.__next_f.push([1,"5:I[7690,[],\"\"]\n7:I[4500,[\"202\",\"static/chunks/202-fbcb7cc54bf4f9f2.js\",\"452\",\"static/chunks/452-25327cca6690da96.js\",\"443\",\"static/chunks/app/(blogs)/23d/learn-rnn-lstm/page-908ed6f1f5b7890e.js\"],\"\"]\n8:I[4365,[\"202\",\"static/chunks/202-fbcb7cc54bf4f9f2.js\",\"452\",\"static/chunks/452-25327cca6690da96.js\",\"443\",\"static/chunks/app/(blogs)/23d/learn-rnn-lstm/page-908ed6f1f5b7890e.js\"],\"\"]\n1a:I[5613,[],\"\"]\n1b:I[1778,[],\"\"]\n1c:I[9806,[\"792\",\"static/chunks/792-a494ddef3d40c017.js\",\"135\",\"static/chunks/app/(blogs)/layout-c2ed809937fec3d8.js\"],\"\"]\n1d:I[3393,[\"792\",\"static/chunks/792-a494ddef3d40c017.js\",\"135\",\"static/chunks/app/(blogs)/layout-c2ed809937fec3d8.js\"],\"\"]\n1e:I[5694,[\"792\",\"static/chunks/792-a494ddef3d40c017.js\",\"185\",\"static/chunks/app/layout-fee515b4ccc2d098.js\"],\"GlobalProvider\"]\n1f:I[397,[\"792\",\"static/chunks/792-a494ddef3d40c017.js\",\"185\",\"static/chunks/app/layout-fee515b4ccc2d098.js\"],\"\"]\n21:I[8955,[],\"\"]\n9:T88c,"])</script><script>self.__next_f.push([1,"\u003cspan class=\"token keyword\"\u003eimport\u003c/span\u003e numpy\n\u003cspan class=\"token keyword\"\u003eimport\u003c/span\u003e torch\n\u003cspan class=\"token keyword\"\u003efrom\u003c/span\u003e torch \u003cspan class=\"token keyword\"\u003eimport\u003c/span\u003e nn\n\u003cspan class=\"token keyword\"\u003eimport\u003c/span\u003e matplotlib\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003epyplot \u003cspan class=\"token keyword\"\u003eas\u003c/span\u003e plt\n\n\u003cspan class=\"token comment\"\u003e#生成加噪声的正弦序列数据\u003c/span\u003e\nxlim\u003cspan class=\"token operator\"\u003e=\u003c/span\u003enumpy\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003elinspace\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token number\"\u003e0\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e\u003cspan class=\"token number\"\u003e36\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e\u003cspan class=\"token number\"\u003e400\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\ny\u003cspan class=\"token operator\"\u003e=\u003c/span\u003enumpy\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003esin\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003exlim\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token operator\"\u003e+\u003c/span\u003enumpy\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003erandom\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003erand\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token operator\"\u003e*\u003c/span\u003exlim\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eshape\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token operator\"\u003e*\u003c/span\u003e\u003cspan class=\"token number\"\u003e0.2\u003c/span\u003e\n\n\u003cspan class=\"token comment\"\u003e#转换dtype和size，保持和后面的训练数据统一\u003c/span\u003e\ny\u003cspan class=\"token operator\"\u003e=\u003c/span\u003ey\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003ereshape\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token operator\"\u003e-\u003c/span\u003e\u003cspan class=\"token number\"\u003e1\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e\u003cspan class=\"token number\"\u003e1\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eastype\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"float32\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\nplt\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eplot\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003exlim\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003ey\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\nplt\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eshow\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n"])</script><script>self.__next_f.push([1,"a:T113e,"])</script><script>self.__next_f.push([1,"\u003cspan class=\"token keyword\"\u003eclass\u003c/span\u003e \u003cspan class=\"token class-name\"\u003eMyRNN\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003enn\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eModule\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n    \u003cspan class=\"token keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"token function\"\u003e__init__\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eself\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003einput_size\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003ehidden_size\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003eoutput_size\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"token builtin\"\u003esuper\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003e__init__\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n        self\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003elinear_ih\u003cspan class=\"token operator\"\u003e=\u003c/span\u003enn\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eLinear\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003einput_size\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003ehidden_size\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n        self\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003elinear_hh\u003cspan class=\"token operator\"\u003e=\u003c/span\u003enn\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eLinear\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003ehidden_size\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003ehidden_size\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n        self\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003elinear_ho\u003cspan class=\"token operator\"\u003e=\u003c/span\u003enn\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eLinear\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003ehidden_size\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003eoutput_size\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n        self\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003etanh\u003cspan class=\"token operator\"\u003e=\u003c/span\u003enn\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eTanh\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"token keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"token function\"\u003eforward\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eself\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003ex\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003eprev_state\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n        curr_state\u003cspan class=\"token operator\"\u003e=\u003c/span\u003eself\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003etanh\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\n            self\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003elinear_ih\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003ex\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token operator\"\u003e+\u003c/span\u003eself\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003elinear_hh\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eprev_state\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n        \u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n        output\u003cspan class=\"token operator\"\u003e=\u003c/span\u003eself\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003elinear_ho\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003ecurr_state\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003ereshape\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token number\"\u003e1\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n        \u003cspan class=\"token keyword\"\u003ereturn\u003c/span\u003e output\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003ecurr_state\n\nhidden_size\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token number\"\u003e12\u003c/span\u003e\nmy_rnn\u003cspan class=\"token operator\"\u003e=\u003c/span\u003eMyRNN\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003einput_size\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token number\"\u003e1\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003ehidden_size\u003cspan class=\"token operator\"\u003e=\u003c/span\u003ehidden_size\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003eoutput_size\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token number\"\u003e1\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\nloss_func\u003cspan class=\"token operator\"\u003e=\u003c/span\u003enn\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eMSELoss\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\noptimizer\u003cspan class=\"token operator\"\u003e=\u003c/span\u003etorch\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eoptim\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eSGD\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003emy_rnn\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eparameters\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003elr\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token number\"\u003e0.01\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n"])</script><script>self.__next_f.push([1,"b:T80b,"])</script><script>self.__next_f.push([1,"\u003cspan class=\"token keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"token function\"\u003etrain\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003etrain_seq\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003etarget\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n    \u003cspan class=\"token comment\"\u003e#初始状态\u003c/span\u003e\n    state\u003cspan class=\"token operator\"\u003e=\u003c/span\u003etorch\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003ezeros\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token number\"\u003e1\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003ehidden_size\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\n    \u003cspan class=\"token keyword\"\u003efor\u003c/span\u003e x \u003cspan class=\"token keyword\"\u003ein\u003c/span\u003e train_seq\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n        output\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003estate\u003cspan class=\"token operator\"\u003e=\u003c/span\u003emy_rnn\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003ex\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003estate\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\n    loss\u003cspan class=\"token operator\"\u003e=\u003c/span\u003eloss_func\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eoutput\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003etarget\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n    optimizer\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003ezero_grad\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n    loss\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003ebackward\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n    optimizer\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003estep\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\n    \u003cspan class=\"token comment\"\u003e#返回损失\u003c/span\u003e\n    \u003cspan class=\"token keyword\"\u003ereturn\u003c/span\u003e loss\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003edetach\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003enumpy\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003ereshape\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token number\"\u003e1\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n"])</script><script>self.__next_f.push([1,"c:T5c4,train_datas\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e[\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e]\u003c/span\u003e\n\u003cspan class=\"token keyword\"\u003efor\u003c/span\u003e i \u003cspan class=\"token keyword\"\u003ein\u003c/span\u003e \u003cspan class=\"token builtin\"\u003erange\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token number\"\u003e320\u003c/span\u003e\u003cspan class=\"token operator\"\u003e-\u003c/span\u003e\u003cspan class=\"token number\"\u003e10\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n    train_seq\u003cspan class=\"token operator\"\u003e=\u003c/span\u003etorch\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003efrom_numpy\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003ey\u003cspan class=\"token punctuation\"\u003e[\u003c/span\u003ei\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003ei\u003cspan class=\"token operator\"\u003e+\u003c/span\u003e\u003cspan class=\"token number\"\u003e10\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e]\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n    target\u003cspan class=\"token operator\"\u003e=\u003c/span\u003etorch\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003efrom_numpy\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003ey\u003cspan class=\"token punctuation\"\u003e[\u003c/span\u003ei\u003cspan class=\"token operator\"\u003e+\u003c/span\u003e\u003cspan class=\"token number\"\u003e10\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e]\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n    train_datas\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eappend\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003etrain_seq\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003etarget\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\nd:T52e,metrics\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e[\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e]\u003c/span\u003e\nmy_rnn\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003etrain\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\u003cspan class=\"token keyword\"\u003efor\u003c/span\u003e train_seq\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003etarget \u003cspan class=\"token keyword\"\u003ein\u003c/span\u003e train_datas\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n    loss\u003cspan class=\"token operator\"\u003e=\u003c/span\u003etrain\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003etrain_seq\u003cspan class=\"toke"])</script><script>self.__next_f.push([1,"n punctuation\"\u003e,\u003c/span\u003etarget\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n    metrics\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eappend\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eloss\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\nplt\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003esubplot\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token number\"\u003e211\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\nplt\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eplot\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003emetrics\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003elabel\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"loss\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\nplt\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003elegend\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\ne:T1086,"])</script><script>self.__next_f.push([1,"\u003cspan class=\"token keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"token function\"\u003epred\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003etruth_seq\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n    \u003cspan class=\"token keyword\"\u003ewith\u003c/span\u003e torch\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eno_grad\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n        state\u003cspan class=\"token operator\"\u003e=\u003c/span\u003etorch\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003ezeros\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token number\"\u003e1\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003ehidden_size\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n        \u003cspan class=\"token keyword\"\u003efor\u003c/span\u003e x \u003cspan class=\"token keyword\"\u003ein\u003c/span\u003e truth_seq\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n            output\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003estate\u003cspan class=\"token operator\"\u003e=\u003c/span\u003emy_rnn\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003ex\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003estate\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n        \u003cspan class=\"token keyword\"\u003ereturn\u003c/span\u003e output\n\npreds\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e[\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e]\u003c/span\u003e\n\u003cspan class=\"token keyword\"\u003efor\u003c/span\u003e i \u003cspan class=\"token keyword\"\u003ein\u003c/span\u003e \u003cspan class=\"token builtin\"\u003erange\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token number\"\u003e320\u003c/span\u003e\u003cspan class=\"token operator\"\u003e-\u003c/span\u003e\u003cspan class=\"token number\"\u003e10\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e\u003cspan class=\"token number\"\u003e400\u003c/span\u003e\u003cspan class=\"token operator\"\u003e-\u003c/span\u003e\u003cspan class=\"token number\"\u003e10\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n    truth_seq\u003cspan class=\"token operator\"\u003e=\u003c/span\u003etorch\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003efrom_numpy\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003ey\u003cspan class=\"token punctuation\"\u003e[\u003c/span\u003ei\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003ei\u003cspan class=\"token operator\"\u003e+\u003c/span\u003e\u003cspan class=\"token number\"\u003e10\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e]\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n    preds\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eappend\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003epred\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003etruth_seq\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003enumpy\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\npreds\u003cspan class=\"token operator\"\u003e=\u003c/span\u003enumpy\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003earray\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003epreds\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003ereshape\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token operator\"\u003e-\u003c/span\u003e\u003cspan class=\"token number\"\u003e1\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e\u003cspan class=\"token number\"\u003e1\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\nplt\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003esubplot\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token number\"\u003e212\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\nplt\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eplot\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003exlim\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003ey\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003elabel\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"truth\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\nplt\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eplot\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003exlim\u003cspan class=\"token punctuation\"\u003e[\u003c/span\u003e\u003cspan class=\"token number\"\u003e320\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\u003cspan class=\"token number\"\u003e400\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e]\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003epreds\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"red\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003elabel\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"predict\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\nplt\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003elegend\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\nplt\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eshow\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n"])</script><script>self.__next_f.push([1,"f:Tcae,"])</script><script>self.__next_f.push([1,"\u003cspan class=\"token keyword\"\u003eclass\u003c/span\u003e \u003cspan class=\"token class-name\"\u003eMyRNN\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003enn\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eModule\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n    \u003cspan class=\"token keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"token function\"\u003e__init__\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eself\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003einput_size\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003ehidden_size\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003eoutput_size\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"token builtin\"\u003esuper\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003e__init__\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n        self\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003elinear_ih\u003cspan class=\"token operator\"\u003e=\u003c/span\u003enn\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eLinear\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003einput_size\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003ehidden_size\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n        self\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003elinear_hh\u003cspan class=\"token operator\"\u003e=\u003c/span\u003enn\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eLinear\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003ehidden_size\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003ehidden_size\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n        self\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003elinear_ho\u003cspan class=\"token operator\"\u003e=\u003c/span\u003enn\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eLinear\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003ehidden_size\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003eoutput_size\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n        self\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003etanh\u003cspan class=\"token operator\"\u003e=\u003c/span\u003enn\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eTanh\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"token keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"token function\"\u003eforward\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eself\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003ex\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003eprev_state\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n        curr_state\u003cspan class=\"token operator\"\u003e=\u003c/span\u003eself\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003etanh\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\n            self\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003elinear_ih\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003ex\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token operator\"\u003e+\u003c/span\u003eself\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003elinear_hh\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eprev_state\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n        \u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n        output\u003cspan class=\"token operator\"\u003e=\u003c/span\u003eself\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003elinear_ho\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003ecurr_state\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003ereshape\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token number\"\u003e1\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n        \u003cspan class=\"token keyword\"\u003ereturn\u003c/span\u003e output\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003ecurr_state\n"])</script><script>self.__next_f.push([1,"10:Tb25,"])</script><script>self.__next_f.push([1,"\u003cspan class=\"token keyword\"\u003eclass\u003c/span\u003e \u003cspan class=\"token class-name\"\u003eMyRNN\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003enn\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eModule\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n    \u003cspan class=\"token keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"token function\"\u003e__init__\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eself\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003einput_size\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003ehidden_size\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003eoutput_size\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n        \u003cspan class=\"token builtin\"\u003esuper\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003e__init__\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n        self\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003ernn\u003cspan class=\"token operator\"\u003e=\u003c/span\u003enn\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eRNN\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003einput_size\u003cspan class=\"token operator\"\u003e=\u003c/span\u003einput_size\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003ehidden_size\u003cspan class=\"token operator\"\u003e=\u003c/span\u003ehidden_size\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003ebatch_first\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token boolean\"\u003eTrue\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n        self\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003elinear_ho\u003cspan class=\"token operator\"\u003e=\u003c/span\u003enn\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eLinear\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003ehidden_size\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003eoutput_size\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"token keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"token function\"\u003eforward\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eself\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003eseq\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003einit_state\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n        output_hidden\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003etate\u003cspan class=\"token operator\"\u003e=\u003c/span\u003eself\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003ernn\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eseq\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003einit_state\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n        output\u003cspan class=\"token operator\"\u003e=\u003c/span\u003eself\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003elinear_ho\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eoutput_hidden\u003cspan class=\"token punctuation\"\u003e[\u003c/span\u003e\u003cspan class=\"token operator\"\u003e-\u003c/span\u003e\u003cspan class=\"token number\"\u003e1\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e]\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e \u003cspan class=\"token comment\"\u003e#取最后一个时间点的输出\u003c/span\u003e\n        \u003cspan class=\"token keyword\"\u003ereturn\u003c/span\u003e output\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003estate\n"])</script><script>self.__next_f.push([1,"11:T45c,\u003cspan class=\"token keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"token function\"\u003etrain\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003etrain_seq\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003etarget\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n    state\u003cspan class=\"token operator\"\u003e=\u003c/span\u003etorch\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003ezeros\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token number\"\u003e1\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003ehidden_size\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"token keyword\"\u003efor\u003c/span\u003e x \u003cspan class=\"token keyword\"\u003ein\u003c/span\u003e train_seq\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n        output\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003estate\u003cspan class=\"token operator\"\u003e=\u003c/span\u003emy_rnn\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003ex\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003estate\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n    loss\u003cspan class=\"token operator\"\u003e=\u003c/span\u003eloss_func\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eoutput\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003etarget\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"token comment\"\u003e# ......\u003c/span\u003e\n12:T488,\u003cspan class=\"token keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"token function\"\u003epred\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003etruth_seq\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003enet\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n    \u003cspan class=\"token keyword\"\u003ewith\u003c/span\u003e torch\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eno_grad\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n        state\u003cspan class=\"token operator\"\u003e=\u003c/span\u003etorch\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003ezeros\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token number\"\u003e1\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003ehidden_size\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n        \u003cspan class=\"token keyword\"\u003efor\u003c/span\u003e x \u003cspan class=\"token keyword\"\u003ein\u003c/span\u003e truth_seq\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n            output\u003cspan class=\"token punctu"])</script><script>self.__next_f.push([1,"ation\"\u003e,\u003c/span\u003estate\u003cspan class=\"token operator\"\u003e=\u003c/span\u003enet\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003ex\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003estate\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n        \u003cspan class=\"token keyword\"\u003ereturn\u003c/span\u003e output\n13:T40e,\u003cspan class=\"token keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"token function\"\u003etrain\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003etrain_seq\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003etarget\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n    state\u003cspan class=\"token operator\"\u003e=\u003c/span\u003etorch\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003ezeros\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token number\"\u003e1\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003ehidden_size\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n    output\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e_\u003cspan class=\"token operator\"\u003e=\u003c/span\u003emy_rnn\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003etrain_seq\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003estate\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e \u003cspan class=\"token comment\"\u003e#一次得到输出\u003c/span\u003e\n    loss\u003cspan class=\"token operator\"\u003e=\u003c/span\u003eloss_func\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eoutput\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003etarget\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"token comment\"\u003e# ......\u003c/span\u003e\n14:T40e,\u003cspan class=\"token keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"token function\"\u003epred\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003etruth_seq\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n    \u003cspan class=\"token keyword\"\u003ewith\u003c/span\u003e torch\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eno_grad\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n        state\u003cspan class=\"token operator\"\u003e=\u003c/span\u003etorch\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003ezeros\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token number\"\u003e1\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003ehidden_size\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n        output\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e_\u003cs"])</script><script>self.__next_f.push([1,"pan class=\"token operator\"\u003e=\u003c/span\u003emy_rnn\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003etruth_seq\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003estate\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e \u003cspan class=\"token comment\"\u003e#一次得到输出\u003c/span\u003e\n        \u003cspan class=\"token keyword\"\u003ereturn\u003c/span\u003e output\n15:T536,式子中\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6667em;vertical-align:-0.0833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e⊗\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e表示按位置相乘，\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.03588em;\"\u003eσ\u003c/span\u003e\u003cspan class=\"mopen\"\u003e(\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.04398em;\"\u003ez\u003c/span\u003e\u003cspan class=\"mclose\"\u003e)\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e的每个元素输出范围是\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"\u003e\u003c/span\u003e\u003cspan class=\"mopen\"\u003e[\u003c/span\u003e\u003cspan class=\"mord\"\u003e0\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e1\u003c/span\u003e\u003cspan class=\"mclose\"\u003e]\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e，某个元素接近\u003ccode class=\"x-inline-highlight\"\u003e1\u003c/code\u003e，\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.4306em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003ex\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e对应位置保留的信息就越多，反之就越少。16:T5a3,LSTM的第一步是决定什么应该被遗忘，也就是对上一个\u003cspan class=\"x-inline-strong\"\u003e单元\u003c/span\u003e\u003ccode class=\"x-inline-highlight\"\u003e(cell)\u003c/code\u003e状态信息选择性的遗忘。\u003cbr/\u003e 这个操作由遗忘门\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan cla"])</script><script>self.__next_f.push([1,"ss=\"mord mathnormal\" style=\"margin-right:0.10764em;\"\u003ef\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.2806em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003et\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e实现，将其\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"\u003e\u003c/span\u003e\u003cspan class=\"mopen\"\u003e[\u003c/span\u003e\u003cspan class=\"mord\"\u003e0\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e1\u003c/span\u003e\u003cspan class=\"mclose\"\u003e]\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e范围的输出按位置与单元上一时刻状态相乘。17:T93e,"])</script><script>self.__next_f.push([1,"当模型看到\u003ccode class=\"x-inline-highlight\"\u003eAlice是一名女教师，……\u003c/code\u003e时，单元状态中可能存储了和主语\u003ccode class=\"x-inline-highlight\"\u003eAlice\u003c/code\u003e和\u003ccode class=\"x-inline-highlight\"\u003e女教师\u003c/code\u003e有关的语义信息，以便在后文输出合适的代词\u003ccode class=\"x-inline-highlight\"\u003e她\u003c/code\u003e；然后，当模型看到\u003ccode class=\"x-inline-highlight\"\u003eAlice是一名女教师，她喜欢给学生讲课；Bob是一位男司机，……\u003c/code\u003e时，我们希望在看到新主语\u003ccode class=\"x-inline-highlight\"\u003eBob\u003c/code\u003e和\u003ccode class=\"x-inline-highlight\"\u003e男司机\u003c/code\u003e之后，忘记此前存储的旧主语的性别语义。也就是对旧单元状态\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.8917em;vertical-align:-0.2083em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.07153em;\"\u003eC\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3011em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003et\u003c/span\u003e\u003cspan class=\"mbin mtight\"\u003e−\u003c/span\u003e\u003cspan class=\"mord mtight\"\u003e1\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.2083em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e乘上较小的\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.10764em;\"\u003ef\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.2806em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003et\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e。"])</script><script>self.__next_f.push([1,"18:T4d3,下一步就是决定要在单元中存入什么新的信息。这一部分有两路：\u003ccode class=\"x-inline-highlight\"\u003etanh\u003c/code\u003e这一路与普通RNN很像，生成一个中间状态；\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.4306em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.03588em;\"\u003eσ\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e这一路被称为输入门\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.8095em;vertical-align:-0.15em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003ei\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.2806em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003et\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e，控制这个中间状态有多少信息被存入单元。19:T6c6,最后是决定新的隐藏状态，这个输出会基于单元状态，但会经过门控单元。输出门\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.5806em;vertical-align:-0.15em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003eo\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.2806em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003et\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/spa"])</script><script>self.__next_f.push([1,"n\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e决定经过\u003ccode class=\"x-inline-highlight\"\u003etanh\u003c/code\u003e的单元状态\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.8333em;vertical-align:-0.15em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.07153em;\"\u003eC\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.2806em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003et\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e有多少被输出到下一时刻的隐藏状态。22:[]\n"])</script><script>self.__next_f.push([1,"2:[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/e43a733539111c31.css\",\"precedence\":\"next\",\"crossOrigin\":\"\"}]],[\"$\",\"$L5\",null,{\"buildId\":\"6fR_4UqCdtahxiXgtOcEq\",\"assetPrefix\":\"\",\"initialCanonicalUrl\":\"/23d/learn-rnn-lstm/\",\"initialTree\":[\"\",{\"children\":[\"(blogs)\",{\"children\":[\"23d\",{\"children\":[\"learn-rnn-lstm\",{\"children\":[\"__PAGE__\",{}]}]}]}]},\"$undefined\",\"$undefined\",true],\"initialSeedData\":[\"\",{\"children\":[\"(blogs)\",{\"children\":[\"23d\",{\"children\":[\"learn-rnn-lstm\",{\"children\":[\"__PAGE__\",{},[\"$L6\",[[\"$\",\"h1\",null,{\"className\":\"x-title\",\"children\":\"学习RNN和LSTM\"}],[\"$\",\"h2\",null,{\"className\":\"x-h1\",\"children\":[\"$\",\"$L7\",null,{\"excludeFromContents\":\"$undefined\",\"children\":\"RNN：一个简单的例子\"}]}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"传统神经网络每次的输入是独立的，每次输出只依赖于当前的输入；但在某些任务中需要更好的处理序列信息，即前面的输入和后面的输入是有关系的；\u003cspan class=\\\"x-inline-strong\\\"\u003e循环神经网络\u003c/span\u003e\u003ccode class=\\\"x-inline-highlight\\\"\u003e(Recurrent Neural Networks, RNN)\u003c/code\u003e通过使用带自反馈的神经元，能够处理任意长度的序列。\"}}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"下面是一个非常常见的RNN结构描述图。它展示了RNN的自反馈机制和与时间的依赖关系，但是对网络结构的描述容易引起误解：右侧的展开形式并不意味着网络有\u003ccode class=\\\"x-inline-highlight\\\"\u003et\u003c/code\u003e层，而是反映了随着时间增加（有时也可以理解为随着程序中循环的迭代），上一次输出的隐藏状态，和\u003cspan class=\\\"katex\\\"\u003e\u003cspan class=\\\"katex-html\\\" aria-hidden=\\\"true\\\"\u003e\u003cspan class=\\\"base\\\"\u003e\u003cspan class=\\\"strut\\\" style=\\\"height:0.5806em;vertical-align:-0.15em;\\\"\u003e\u003c/span\u003e\u003cspan class=\\\"mord\\\"\u003e\u003cspan class=\\\"mord mathnormal\\\"\u003ex\u003c/span\u003e\u003cspan class=\\\"msupsub\\\"\u003e\u003cspan class=\\\"vlist-t vlist-t2\\\"\u003e\u003cspan class=\\\"vlist-r\\\"\u003e\u003cspan class=\\\"vlist\\\" style=\\\"height:0.2806em;\\\"\u003e\u003cspan style=\\\"top:-2.55em;margin-left:0em;margin-right:0.05em;\\\"\u003e\u003cspan class=\\\"pstrut\\\" style=\\\"height:2.7em;\\\"\u003e\u003c/span\u003e\u003cspan class=\\\"sizing reset-size6 size3 mtight\\\"\u003e\u003cspan class=\\\"mord mathnormal mtight\\\"\u003et\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\\\"vlist-s\\\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\\\"vlist-r\\\"\u003e\u003cspan class=\\\"vlist\\\" style=\\\"height:0.15em;\\\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e共同作为网络的下一次的输入。\"}}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"或者，如果说CNN是从空间维度上堆叠卷积层，不断加深，RNN就是从时间维度上的延展，而其网络真正的参数是很少的。\"}}],[\"$\",\"$L8\",null,{\"src\":\"rnn1.png\",\"width\":\"600px\",\"invertInDarkTheme\":true}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"下面以一个简单的正弦序列预测任务出发，结合代码理解RNN网络的部分细节。\"}}],[\"$\",\"h3\",null,{\"className\":\"x-h2\",\"children\":[\"$\",\"$L7\",null,{\"excludeFromContents\":\"$undefined\",\"children\":\"预测一个正弦序列\"}]}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"这个例子中，我们对一个加了噪声的正弦序列进行预测。\"}}],[\"$\",\"div\",null,{\"className\":\"x-codeblock\",\"children\":[\"$\",\"pre\",null,{\"style\":{\"background\":null},\"children\":[\"$\",\"code\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"$9\"}}]}]}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"代码中我们在区间\u003cspan class=\\\"katex\\\"\u003e\u003cspan class=\\\"katex-html\\\" aria-hidden=\\\"true\\\"\u003e\u003cspan class=\\\"base\\\"\u003e\u003cspan class=\\\"strut\\\" style=\\\"height:1em;vertical-align:-0.25em;\\\"\u003e\u003c/span\u003e\u003cspan class=\\\"mopen\\\"\u003e[\u003c/span\u003e\u003cspan class=\\\"mord\\\"\u003e0\u003c/span\u003e\u003cspan class=\\\"mpunct\\\"\u003e,\u003c/span\u003e\u003cspan class=\\\"mspace\\\" style=\\\"margin-right:0.1667em;\\\"\u003e\u003c/span\u003e\u003cspan class=\\\"mord\\\"\u003e36\u003c/span\u003e\u003cspan class=\\\"mclose\\\"\u003e]\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e取了\u003ccode class=\\\"x-inline-highlight\\\"\u003e400\u003c/code\u003e点数据，如果把横轴看成时间轴，可以认为数据集中有\u003ccode class=\\\"x-inline-highlight\\\"\u003e400\u003c/code\u003e个连续时间点的数据。\"}}],[\"$\",\"$L8\",null,{\"src\":\"fig1.png\",\"width\":\"600px\",\"invertInDarkTheme\":true}],[\"$\",\"p\",null,{\"className\":\"x-p no-margin-bottom\",\"dangerouslySetInnerHTML\":{\"__html\":\"现在明确一下我们的方案：\"}}],[\"$\",\"div\",null,{\"className\":\"x-oli\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-oli-number\",\"children\":\"3.\"}],[\"$\",\"div\",null,{\"className\":\"x-oli-content-wrapper\",\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"使用前\u003ccode class=\\\"x-inline-highlight\\\"\u003e80%\u003c/code\u003e也就是前\u003ccode class=\\\"x-inline-highlight\\\"\u003e320\u003c/code\u003e个数据作为训练集，剩余的作为测试集，观察预测结果。\"}}]}]]}],[\"$\",\"div\",null,{\"className\":\"x-oli\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-oli-number\",\"children\":\"4.\"}],[\"$\",\"div\",null,{\"className\":\"x-oli-content-wrapper\",\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"序列长度为\u003ccode class=\\\"x-inline-highlight\\\"\u003e10\u003c/code\u003e，也就是模型根据前\u003ccode class=\\\"x-inline-highlight\\\"\u003e10\u003c/code\u003e个时间点的数据去预测下一个时间点的数据。\"}}]}]]}],[\"$\",\"div\",null,{\"className\":\"x-oli\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-oli-number\",\"children\":\"5.\"}],[\"$\",\"div\",null,{\"className\":\"x-oli-content-wrapper\",\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"这个例子中输入特征的维度是\u003ccode class=\\\"x-inline-highlight\\\"\u003e1\u003c/code\u003e，也就是只有\u003ccode class=\\\"x-inline-highlight\\\"\u003ey\u003c/code\u003e值一个指标。此外，也不考虑批量大小。\"}}]}]]}],[\"$\",\"h3\",null,{\"className\":\"x-h2\",\"children\":[\"$\",\"$L7\",null,{\"excludeFromContents\":\"$undefined\",\"children\":\"定义RNN网络\"}]}],[\"$\",\"div\",null,{\"className\":\"x-codeblock\",\"children\":[\"$\",\"pre\",null,{\"style\":{\"background\":null},\"children\":[\"$\",\"code\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"$a\"}}]}]}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"这个是一个简单的RNN结构，从网络参数和结构来看很像一个\u003ccode class=\\\"x-inline-highlight\\\"\u003e输入层-隐藏层-输出层\u003c/code\u003e的感知机，但是多了一步\u003ccode class=\\\"x-inline-highlight\\\"\u003e隐藏层-隐藏层\u003c/code\u003e的连接，RNN的反馈结构就是由此体现的。\"}}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"并且，注意到\u003ccode class=\\\"x-inline-highlight\\\"\u003eforward\u003c/code\u003e函数的输入也需要两个参数：当前时刻输入\u003ccode class=\\\"x-inline-highlight\\\"\u003ex\u003c/code\u003e和前一时刻状态\u003ccode class=\\\"x-inline-highlight\\\"\u003eprev_state\u003c/code\u003e，同时也会把计算后的新状态\u003ccode class=\\\"x-inline-highlight\\\"\u003ecurr_state\u003c/code\u003e和\u003ccode class=\\\"x-inline-highlight\\\"\u003eoutput\u003c/code\u003e一起返回，供下一次计算使用。在这里，经过\u003ccode class=\\\"x-inline-highlight\\\"\u003elinear_ho\u003c/code\u003e后，\u003ccode class=\\\"x-inline-highlight\\\"\u003eoutput\u003c/code\u003e的\u003ccode class=\\\"x-inline-highlight\\\"\u003esize\u003c/code\u003e为\u003ccode class=\\\"x-inline-highlight\\\"\u003e(1,1)\u003c/code\u003e，考虑到它仅仅是一个标量，我们把它\u003ccode class=\\\"x-inline-highlight\\\"\u003eresize\u003c/code\u003e为\u003ccode class=\\\"x-inline-highlight\\\"\u003e(1)\u003c/code\u003e。\"}}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"接下来设置了一些超参数，隐藏层有\u003ccode class=\\\"x-inline-highlight\\\"\u003e12\u003c/code\u003e个神经元，损失函数使用\u003ccode class=\\\"x-inline-highlight\\\"\u003eMSELoss()\u003c/code\u003e。\"}}],[\"$\",\"h3\",null,{\"className\":\"x-h2\",\"children\":[\"$\",\"$L7\",null,{\"excludeFromContents\":\"$undefined\",\"children\":\"训练\"}]}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"首先定义这样的训练函数：它传入一个序列\u003ccode class=\\\"x-inline-highlight\\\"\u003etrain_seq\u003c/code\u003e和目标\u003ccode class=\\\"x-inline-highlight\\\"\u003etarget\u003c/code\u003e。\u003ccode class=\\\"x-inline-highlight\\\"\u003etrain_seq\u003c/code\u003e的\u003ccode class=\\\"x-inline-highlight\\\"\u003esize\u003c/code\u003e应该为\u003ccode class=\\\"x-inline-highlight\\\"\u003e(10,1)\u003c/code\u003e，因为我们用前\u003ccode class=\\\"x-inline-highlight\\\"\u003e10\u003c/code\u003e个时间点的数据去预测下一个，而输入特征维度是\u003ccode class=\\\"x-inline-highlight\\\"\u003e1\u003c/code\u003e；\u003ccode class=\\\"x-inline-highlight\\\"\u003etarget\u003c/code\u003e的\u003ccode class=\\\"x-inline-highlight\\\"\u003esize\u003c/code\u003e应该为\u003ccode class=\\\"x-inline-highlight\\\"\u003e(1)\u003c/code\u003e，因为输出只是一个标量。注意我们循环依次输入\u003ccode class=\\\"x-inline-highlight\\\"\u003etrain_seq\u003c/code\u003e中的\u003ccode class=\\\"x-inline-highlight\\\"\u003e10\u003c/code\u003e个数据，迭代更新\u003ccode class=\\\"x-inline-highlight\\\"\u003estate\u003c/code\u003e，用最后一次的\u003ccode class=\\\"x-inline-highlight\\\"\u003eoutput\u003c/code\u003e作为最终的输出计算损失。\"}}],[\"$\",\"div\",null,{\"className\":\"x-codeblock\",\"children\":[\"$\",\"pre\",null,{\"style\":{\"background\":null},\"children\":[\"$\",\"code\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"$b\"}}]}]}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"下面代码把真实数据划分成：\"}}],[\"$\",\"table\",null,{\"className\":\"x-table\",\"children\":[\"$\",\"tbody\",null,{\"children\":[[\"$\",\"tr\",null,{\"children\":[[\"$\",\"th\",null,{\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003etrain_seq\u003c/code\u003e\"}}]}],[\"$\",\"th\",null,{\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003etarget\u003c/code\u003e\"}}]}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[0]\u003c/code\u003e,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[1]\u003c/code\u003e,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[2]\u003c/code\u003e, ... ,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[9]\u003c/code\u003e\"}}]}],[\"$\",\"td\",null,{\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[10]\u003c/code\u003e\"}}]}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[1]\u003c/code\u003e,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[2]\u003c/code\u003e,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[3]\u003c/code\u003e, ... ,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[10]\u003c/code\u003e\"}}]}],[\"$\",\"td\",null,{\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[11]\u003c/code\u003e\"}}]}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[2]\u003c/code\u003e,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[3]\u003c/code\u003e,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[4]\u003c/code\u003e, ... ,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[11]\u003c/code\u003e\"}}]}],[\"$\",\"td\",null,{\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[12]\u003c/code\u003e\"}}]}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":\"...\"}],[\"$\",\"td\",null,{\"children\":\"...\"}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[309]\u003c/code\u003e,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[310]\u003c/code\u003e,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[311]\u003c/code\u003e, ... ,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[318]\u003c/code\u003e\"}}]}],[\"$\",\"td\",null,{\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[319]\u003c/code\u003e\"}}]}]]}]]}]}],[\"$\",\"div\",null,{\"className\":\"x-codeblock\",\"children\":[\"$\",\"pre\",null,{\"style\":{\"background\":null},\"children\":[\"$\",\"code\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"$c\"}}]}]}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"训练网络，绘制误差：\"}}],[\"$\",\"div\",null,{\"className\":\"x-codeblock\",\"children\":[\"$\",\"pre\",null,{\"style\":{\"background\":null},\"children\":[\"$\",\"code\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"$d\"}}]}]}],[\"$\",\"h3\",null,{\"className\":\"x-h2\",\"children\":[\"$\",\"$L7\",null,{\"excludeFromContents\":\"$undefined\",\"children\":\"预测\"}]}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"这个例子中我们用\u003cspan class=\\\"x-inline-strong\\\"\u003e单步预测\u003c/span\u003e观察模型的效果。在单步预测时，每次预测都全部使用真实值；当然，我们可以这样做是因为验证集中本来就包含了真实的数据，换句话说，我们是在已知\u003ccode class=\\\"x-inline-highlight\\\"\u003et+1\u003c/code\u003e时刻的真实数据的情况下，去看看模型使用\u003ccode class=\\\"x-inline-highlight\\\"\u003et-9\u003c/code\u003e~\u003ccode class=\\\"x-inline-highlight\\\"\u003et\u003c/code\u003e时刻的数据，对\u003ccode class=\\\"x-inline-highlight\\\"\u003et+1\u003c/code\u003e时刻的预测值。\"}}],[\"$\",\"table\",null,{\"className\":\"x-table\",\"children\":[\"$\",\"tbody\",null,{\"children\":[[\"$\",\"tr\",null,{\"children\":[[\"$\",\"th\",null,{\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003einput\u003c/code\u003e\"}}]}],[\"$\",\"th\",null,{\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003eprediction\u003c/code\u003e\"}}]}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[310]\u003c/code\u003e,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[311]\u003c/code\u003e,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[312]\u003c/code\u003e, ... ,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[319]\u003c/code\u003e\"}}]}],[\"$\",\"td\",null,{\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003epred[320]\u003c/code\u003e\"}}]}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[311]\u003c/code\u003e,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[312]\u003c/code\u003e,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[313]\u003c/code\u003e, ... ,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[320]\u003c/code\u003e\"}}]}],[\"$\",\"td\",null,{\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003epred[321]\u003c/code\u003e\"}}]}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[312]\u003c/code\u003e,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[313]\u003c/code\u003e,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[314]\u003c/code\u003e, ... ,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[321]\u003c/code\u003e\"}}]}],[\"$\",\"td\",null,{\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003epred[322]\u003c/code\u003e\"}}]}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":\"...\"}],[\"$\",\"td\",null,{\"children\":\"...\"}]]}]]}]}],[\"$\",\"div\",null,{\"className\":\"x-codeblock\",\"children\":[\"$\",\"pre\",null,{\"style\":{\"background\":null},\"children\":[\"$\",\"code\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"$e\"}}]}]}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"如果我们不只是在测试集上评估模型性能，而是去预测真实生活中的问题，例如未来\u003ccode class=\\\"x-inline-highlight\\\"\u003e7\u003c/code\u003e天的温度；或者假如我们的数据集到\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[319]\u003c/code\u003e就截止了，这时如果想得到后面多个时刻的数据，就需要\u003cspan class=\\\"x-inline-strong\\\"\u003e多步预测\u003c/span\u003e，此时上一时刻的预测会被当做新的输入：\"}}],[\"$\",\"table\",null,{\"className\":\"x-table\",\"children\":[\"$\",\"tbody\",null,{\"children\":[[\"$\",\"tr\",null,{\"children\":[[\"$\",\"th\",null,{\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003einput\u003c/code\u003e\"}}]}],[\"$\",\"th\",null,{\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003eprediction\u003c/code\u003e\"}}]}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[310]\u003c/code\u003e,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[311]\u003c/code\u003e,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[312]\u003c/code\u003e, ... ,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[319]\u003c/code\u003e\"}}]}],[\"$\",\"td\",null,{\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003epred[320]\u003c/code\u003e\"}}]}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[311]\u003c/code\u003e,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[312]\u003c/code\u003e,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[313]\u003c/code\u003e, ... ,\u003ccode class=\\\"x-inline-highlight\\\"\u003epred[320]\u003c/code\u003e\"}}]}],[\"$\",\"td\",null,{\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003epred[321]\u003c/code\u003e\"}}]}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[312]\u003c/code\u003e,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[313]\u003c/code\u003e,\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[314]\u003c/code\u003e, ... ,\u003ccode class=\\\"x-inline-highlight\\\"\u003epred[320]\u003c/code\u003e,\u003ccode class=\\\"x-inline-highlight\\\"\u003epred[321]\u003c/code\u003e\"}}]}],[\"$\",\"td\",null,{\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003epred[322]\u003c/code\u003e\"}}]}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":\"...\"}],[\"$\",\"td\",null,{\"children\":\"...\"}]]}]]}]}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"多步预测会导致误差的累积。\"}}],[\"$\",\"h3\",null,{\"className\":\"x-h2\",\"children\":[\"$\",\"$L7\",null,{\"excludeFromContents\":\"$undefined\",\"children\":\"看看效果\"}]}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"如果不执行训练步骤的代码，使用初始随机参数的模型预测结果是：\"}}],[\"$\",\"$L8\",null,{\"src\":\"fig2.png\",\"width\":\"600px\",\"invertInDarkTheme\":true}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"经过训练后，每次训练的\u003ccode class=\\\"x-inline-highlight\\\"\u003eloss\u003c/code\u003e和最终的预测：\"}}],[\"$\",\"$L8\",null,{\"src\":\"fig3.png\",\"width\":\"600px\",\"invertInDarkTheme\":true}],[\"$\",\"h3\",null,{\"className\":\"x-h2\",\"children\":[\"$\",\"$L7\",null,{\"excludeFromContents\":\"$undefined\",\"children\":\"使用torch.nn.RNN\"}]}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"使用\u003ccode class=\\\"x-inline-highlight\\\"\u003etorch.nn.RNN\u003c/code\u003e模块时，与上面例子中手动实现的RNN有几处细小的区别，下面给出了使用\u003ccode class=\\\"x-inline-highlight\\\"\u003etorch.nn.RNN\u003c/code\u003e时需要做出的修改：\"}}],[\"$\",\"div\",null,{\"className\":\"x-oli\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-oli-number\",\"children\":\"1.\"}],[\"$\",\"div\",null,{\"className\":\"x-oli-content-wrapper\",\"children\":[[\"$\",\"p\",null,{\"className\":\"x-p no-margin-bottom\",\"dangerouslySetInnerHTML\":{\"__html\":\"定义模型时，不再需要显式指定\u003ccode class=\\\"x-inline-highlight\\\"\u003elinear_ih\u003c/code\u003e和\u003ccode class=\\\"x-inline-highlight\\\"\u003elinear_hh\u003c/code\u003e两层，将由\u003ccode class=\\\"x-inline-highlight\\\"\u003enn.RNN\u003c/code\u003e模块实现；\u003ccode class=\\\"x-inline-highlight\\\"\u003enn.RNN\u003c/code\u003e模块没有定义输出层，因此输出层\u003ccode class=\\\"x-inline-highlight\\\"\u003elinear_ho\u003c/code\u003e需要设置。\u003cbr/\u003e 在\u003ccode class=\\\"x-inline-highlight\\\"\u003eforward\u003c/code\u003e函数中，手动实现时为了直观展示出RNN的迭代过程，只进行了一次隐藏状态的更新；而对于输入序列迭代更新隐藏状态是在训练和预测时实现的。而\u003ccode class=\\\"x-inline-highlight\\\"\u003enn.RNN\u003c/code\u003e模块的一次\u003ccode class=\\\"x-inline-highlight\\\"\u003eforward\u003c/code\u003e就已经完成了迭代更新，其输入是整个序列\u003ccode class=\\\"x-inline-highlight\\\"\u003eseq\u003c/code\u003e和\u003ccode class=\\\"x-inline-highlight\\\"\u003eprev_state\u003c/code\u003e，返回值是\u003ccode class=\\\"x-inline-highlight\\\"\u003eoutput_hidden,curr_state\u003c/code\u003e，对于不考虑批量大小的数据，它们的\u003ccode class=\\\"x-inline-highlight\\\"\u003esize\u003c/code\u003e为：\"}}],[\"$\",\"div\",null,{\"className\":\"x-uli\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-uli-marker\",\"children\":[\"$\",\"div\",null,{\"className\":\"x-uli-marker-dot\"}]}],[\"$\",\"div\",null,{\"className\":\"x-uli-content-wrapper\",\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003eseq\u003c/code\u003e: \u003ccode class=\\\"x-inline-highlight\\\"\u003e(sequence_length, input_size)\u003c/code\u003e\"}}]}]]}],[\"$\",\"div\",null,{\"className\":\"x-uli\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-uli-marker\",\"children\":[\"$\",\"div\",null,{\"className\":\"x-uli-marker-dot\"}]}],[\"$\",\"div\",null,{\"className\":\"x-uli-content-wrapper\",\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003einit_state\u003c/code\u003e: \u003ccode class=\\\"x-inline-highlight\\\"\u003e(1, hidden_size)\u003c/code\u003e\"}}]}]]}],[\"$\",\"div\",null,{\"className\":\"x-uli\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-uli-marker\",\"children\":[\"$\",\"div\",null,{\"className\":\"x-uli-marker-dot\"}]}],[\"$\",\"div\",null,{\"className\":\"x-uli-content-wrapper\",\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003eoutput_hidden\u003c/code\u003e: \u003ccode class=\\\"x-inline-highlight\\\"\u003e(sequence_length, hidden_size)\u003c/code\u003e\"}}]}]]}],[\"$\",\"div\",null,{\"className\":\"x-uli\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-uli-marker\",\"children\":[\"$\",\"div\",null,{\"className\":\"x-uli-marker-dot\"}]}],[\"$\",\"div\",null,{\"className\":\"x-uli-content-wrapper\",\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003estate\u003c/code\u003e: \u003ccode class=\\\"x-inline-highlight\\\"\u003e(1, hidden_size)\u003c/code\u003e\"}}]}]]}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"最后在我们定义的\u003ccode class=\\\"x-inline-highlight\\\"\u003eMyRNN\u003c/code\u003e模块中，用\u003ccode class=\\\"x-inline-highlight\\\"\u003eoutput_hidden\u003c/code\u003e的最后一个时间点的输出，经过输出层得到最终的\u003ccode class=\\\"x-inline-highlight\\\"\u003eoutput\u003c/code\u003e。\"}}]]}]]}],[\"$\",\"div\",null,{\"className\":\"x-highlightblock highlight-background-gray\",\"children\":[[\"$\",\"h4\",null,{\"className\":\"x-h3\",\"children\":\"手动实现\"}],[\"$\",\"div\",null,{\"className\":\"x-codeblock\",\"children\":[\"$\",\"pre\",null,{\"style\":{\"background\":null},\"children\":[\"$\",\"code\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"$f\"}}]}]}],[\"$\",\"h4\",null,{\"className\":\"x-h3\",\"children\":\"使用torch.nn.RNN\"}],[\"$\",\"div\",null,{\"className\":\"x-codeblock\",\"children\":[\"$\",\"pre\",null,{\"style\":{\"background\":null},\"children\":[\"$\",\"code\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"$10\"}}]}]}]]}],[\"$\",\"div\",null,{\"className\":\"x-oli\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-oli-number\",\"children\":\"2.\"}],[\"$\",\"div\",null,{\"className\":\"x-oli-content-wrapper\",\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"训练和预测时，也不需要再遍历序列，迭代的过程已经在\u003ccode class=\\\"x-inline-highlight\\\"\u003enn.RNN\u003c/code\u003e模块内部实现。\"}}]}]]}],[\"$\",\"div\",null,{\"className\":\"x-highlightblock highlight-background-gray\",\"children\":[[\"$\",\"h4\",null,{\"className\":\"x-h3\",\"children\":\"手动实现\"}],[\"$\",\"div\",null,{\"className\":\"x-codeblock\",\"children\":[\"$\",\"pre\",null,{\"style\":{\"background\":null},\"children\":[\"$\",\"code\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"$11\"}}]}]}],[\"$\",\"div\",null,{\"className\":\"x-codeblock\",\"children\":[\"$\",\"pre\",null,{\"style\":{\"background\":null},\"children\":[\"$\",\"code\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"$12\"}}]}]}],[\"$\",\"h4\",null,{\"className\":\"x-h3\",\"children\":\"使用torch.nn.RNN\"}],[\"$\",\"div\",null,{\"className\":\"x-codeblock\",\"children\":[\"$\",\"pre\",null,{\"style\":{\"background\":null},\"children\":[\"$\",\"code\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"$13\"}}]}]}],[\"$\",\"div\",null,{\"className\":\"x-codeblock\",\"children\":[\"$\",\"pre\",null,{\"style\":{\"background\":null},\"children\":[\"$\",\"code\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"$14\"}}]}]}]]}],[\"$\",\"h3\",null,{\"className\":\"x-h2\",\"children\":[\"$\",\"$L7\",null,{\"excludeFromContents\":\"$undefined\",\"children\":\"FAQ\"}]}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"初次了解RNN时，我在一些问题上困惑了很久。这个版块是对它们的再次整理。（尽管有些已经包含在上述例子中了！）\"}}],[\"$\",\"h4\",null,{\"className\":\"x-h3\",\"children\":\"用10步预测下1步，为什么 input_size 不是10，而是1？\"}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003einput_size\u003c/code\u003e与序列长度并非同一个概念。用前\u003ccode class=\\\"x-inline-highlight\\\"\u003e10\u003c/code\u003e个时间点的数据去预测下一个，这里的\u003ccode class=\\\"x-inline-highlight\\\"\u003e10\u003c/code\u003e是序列长度；而\u003ccode class=\\\"x-inline-highlight\\\"\u003einput_size\u003c/code\u003e是输入特征的维度。由于这个例子较为简单，只是用历史的\u003ccode class=\\\"x-inline-highlight\\\"\u003ey\u003c/code\u003e值预测新的\u003ccode class=\\\"x-inline-highlight\\\"\u003ey\u003c/code\u003e值，因此特征只有\u003ccode class=\\\"x-inline-highlight\\\"\u003e1\u003c/code\u003e维。\"}}],[\"$\",\"h4\",null,{\"className\":\"x-h3\",\"children\":\"什么时候 input_size 不是1？\"}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"例如我们在预测未来气温时，历史气温数据并不是唯一的参考，还可能参考历史的风速、气压、天气情况等等，此时输入数据将会是一个\u003ccode class=\\\"x-inline-highlight\\\"\u003einput_size\u003c/code\u003e维的向量。\"}}],[\"$\",\"h4\",null,{\"className\":\"x-h3\",\"children\":\"hidden_size=12，12是在哪里体现的？\"}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003ccode class=\\\"x-inline-highlight\\\"\u003e12\u003c/code\u003e只是模型的超参数，和MLP中隐藏层大小一样，并没有太多的物理含义。\"}}],[\"$\",\"h4\",null,{\"className\":\"x-h3\",\"children\":\"训练时，每次迭代用哪些数据？应该遍历几遍数据集？每个 epoch 会使用哪些数据进行参数优化？\"}],[\"$\",\"p\",null,{\"className\":\"x-p no-margin-bottom\",\"dangerouslySetInnerHTML\":{\"__html\":\"在训练一个CNN网络时（例如一个图片分类网络），策略通常是：\"}}],[\"$\",\"div\",null,{\"className\":\"x-oli\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-oli-number\",\"children\":\"1.\"}],[\"$\",\"div\",null,{\"className\":\"x-oli-content-wrapper\",\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"指定超参数\u003ccode class=\\\"x-inline-highlight\\\"\u003enum_epoch\u003c/code\u003e，在每个\u003ccode class=\\\"x-inline-highlight\\\"\u003eepoch\u003c/code\u003e中随机遍历训练集中的所有图像进行参数优化；\"}}]}]]}],[\"$\",\"div\",null,{\"className\":\"x-oli\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-oli-number\",\"children\":\"2.\"}],[\"$\",\"div\",null,{\"className\":\"x-oli-content-wrapper\",\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"重复执行\u003ccode class=\\\"x-inline-highlight\\\"\u003enum_epoch\u003c/code\u003e次。\"}}]}]]}],[\"$\",\"p\",null,{\"className\":\"x-p with-margin-top no-margin-bottom\",\"dangerouslySetInnerHTML\":{\"__html\":\"然而对于RNN来说这个概念似乎并不清晰，例如上述例子的训练策略是：\"}}],[\"$\",\"div\",null,{\"className\":\"x-oli\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-oli-number\",\"children\":\"1.\"}],[\"$\",\"div\",null,{\"className\":\"x-oli-content-wrapper\",\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"从\u003ccode class=\\\"x-inline-highlight\\\"\u003e0\u003c/code\u003e到\u003ccode class=\\\"x-inline-highlight\\\"\u003e(训练集大小 - 序列长度)\u003c/code\u003e依次遍历起始时间\u003ccode class=\\\"x-inline-highlight\\\"\u003et\u003c/code\u003e；\"}}]}]]}],[\"$\",\"div\",null,{\"className\":\"x-oli\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-oli-number\",\"children\":\"2.\"}],[\"$\",\"div\",null,{\"className\":\"x-oli-content-wrapper\",\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"对于每个起始时间\u003ccode class=\\\"x-inline-highlight\\\"\u003et\u003c/code\u003e，将\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[t]\u003c/code\u003e~\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[t+9]\u003c/code\u003e为输入，\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[t+10]\u003c/code\u003e为真值作为一组训练样本。\"}}]}]]}],[\"$\",\"div\",null,{\"className\":\"x-oli\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-oli-number\",\"children\":\"3.\"}],[\"$\",\"div\",null,{\"className\":\"x-oli-content-wrapper\",\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"第\u003ccode class=\\\"x-inline-highlight\\\"\u003e1\u003c/code\u003e步只遍历了一次！\"}}]}]]}],[\"$\",\"p\",null,{\"className\":\"x-p with-margin-top no-margin-bottom\",\"dangerouslySetInnerHTML\":{\"__html\":\"或者：\"}}],[\"$\",\"p\",null,{\"className\":\"x-p no-margin-bottom\",\"dangerouslySetInnerHTML\":{\"__html\":\"...\"}}],[\"$\",\"div\",null,{\"className\":\"x-oli\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-oli-number\",\"children\":\"3.\"}],[\"$\",\"div\",null,{\"className\":\"x-oli-content-wrapper\",\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"前两步同上，但多次遍历训练集。\"}}]}]]}],[\"$\",\"p\",null,{\"className\":\"x-p with-margin-top no-margin-bottom\",\"dangerouslySetInnerHTML\":{\"__html\":\"另一个常用的策略是：\"}}],[\"$\",\"div\",null,{\"className\":\"x-oli\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-oli-number\",\"children\":\"1.\"}],[\"$\",\"div\",null,{\"className\":\"x-oli-content-wrapper\",\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"指定超参数：训练轮次\u003ccode class=\\\"x-inline-highlight\\\"\u003enum_iter\u003c/code\u003e；\"}}]}]]}],[\"$\",\"div\",null,{\"className\":\"x-oli\",\"children\":[[\"$\",\"div\",null,{\"className\":\"x-oli-number\",\"children\":\"2.\"}],[\"$\",\"div\",null,{\"className\":\"x-oli-content-wrapper\",\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"重复执行\u003ccode class=\\\"x-inline-highlight\\\"\u003enum_iter\u003c/code\u003e次，每次随机抽取一个起始时间\u003ccode class=\\\"x-inline-highlight\\\"\u003et\u003c/code\u003e，并且将\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[t]\u003c/code\u003e~\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[t+9]\u003c/code\u003e为输入，\u003ccode class=\\\"x-inline-highlight\\\"\u003ey[t+10]\u003c/code\u003e为真值作为一组训练样本。\"}}]}]]}],[\"$\",\"h2\",null,{\"className\":\"x-h1\",\"children\":[\"$\",\"$L7\",null,{\"excludeFromContents\":\"$undefined\",\"children\":\"LSTM：一篇很好的博客\"}]}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"以下的内容和插图总结或翻译自这篇的英文博客：\u003ca href=\\\"https://colah.github.io/posts/2015-08-Understanding-LSTMs/\\\" target=\\\"_blank\\\" rel=\\\"noreferrer\\\" class=\\\"x-inline-link\\\"\u003eUnderstanding LSTM Networks\u003c/a\u003e\"}}],[\"$\",\"h3\",null,{\"className\":\"x-h2\",\"children\":[\"$\",\"$L7\",null,{\"excludeFromContents\":\"$undefined\",\"children\":\"长期依赖问题\"}]}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"RNN可以利用先前的信息理解当前的任务，这点非常不错；有时我们只需要短期的信息，例如一个语言模型预测下面的句子：\u003cbr/\u003e \u003ccode class=\\\"x-inline-highlight\\\"\u003e天空中飘着一朵白色的【云】\u003c/code\u003e，这很简单。但有些时候我们需要更多背景信息，例如：\u003cbr/\u003e\u003ccode class=\\\"x-inline-highlight\\\"\u003e我出生在法国，…… ，我可以说流利的【法语】\u003c/code\u003e，这个情况下，随着前后文距离变大，RNN对长期依赖关系的学习会变得困难。\"}}],[\"$\",\"h3\",null,{\"className\":\"x-h2\",\"children\":[\"$\",\"$L7\",null,{\"excludeFromContents\":\"$undefined\",\"children\":\"LSTM\"}]}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003cspan class=\\\"x-inline-strong\\\"\u003e长短期记忆网络\u003c/span\u003e\u003ccode class=\\\"x-inline-highlight\\\"\u003e(Long Short-Term Memory, LSTM)\u003c/code\u003e是一种特殊的RNN，可以学习长期依赖。以RNN为例，循环神经网络随时间展开通常具有如下的示意图：\"}}],[\"$\",\"$L8\",null,{\"src\":\"rnn2.png\",\"width\":\"600px\",\"invertInDarkTheme\":true}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"对于RNN来说，利用历史状态和输入得到新的状态，只经过一个简单的\u003ccode class=\\\"x-inline-highlight\\\"\u003etanh\u003c/code\u003e激活层，而对于LSTM来说，它的示意图略显复杂：\"}}],[\"$\",\"$L8\",null,{\"src\":\"lstm1.png\",\"width\":\"600px\",\"invertInDarkTheme\":true}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"在上图中，每条线表示一个向量，粉红色圆圈表示逐点式操作，黄色的方框是神经网络的层。这看起来很眼晕，不过我们接下来会一点点的解释图里的内容。\"}}],[\"$\",\"h3\",null,{\"className\":\"x-h2\",\"children\":[\"$\",\"$L7\",null,{\"excludeFromContents\":\"$undefined\",\"children\":\"门控单元\"}]}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"下面的结构称为门控单元：\"}}],[\"$\",\"$L8\",null,{\"src\":\"lstm2.png\",\"width\":\"100px\",\"invertInDarkTheme\":true}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"门控单元控制信息量通过的多少，通过向量\u003cspan class=\\\"katex\\\"\u003e\u003cspan class=\\\"katex-html\\\" aria-hidden=\\\"true\\\"\u003e\u003cspan class=\\\"base\\\"\u003e\u003cspan class=\\\"strut\\\" style=\\\"height:0.4306em;\\\"\u003e\u003c/span\u003e\u003cspan class=\\\"mord mathnormal\\\" style=\\\"margin-right:0.04398em;\\\"\u003ez\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e来控制\u003cspan class=\\\"katex\\\"\u003e\u003cspan class=\\\"katex-html\\\" aria-hidden=\\\"true\\\"\u003e\u003cspan class=\\\"base\\\"\u003e\u003cspan class=\\\"strut\\\" style=\\\"height:0.4306em;\\\"\u003e\u003c/span\u003e\u003cspan class=\\\"mord mathnormal\\\"\u003ex\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e通过的信息量：\"}}],[\"$\",\"div\",null,{\"className\":\"x-formula\",\"dangerouslySetInnerHTML\":{\"__html\":\"\u003cspan class=\\\"katex\\\"\u003e\u003cspan class=\\\"katex-html\\\" aria-hidden=\\\"true\\\"\u003e\u003cspan class=\\\"base\\\"\u003e\u003cspan class=\\\"strut\\\" style=\\\"height:0.4306em;\\\"\u003e\u003c/span\u003e\u003cspan class=\\\"mord mathnormal\\\"\u003eo\u003c/span\u003e\u003cspan class=\\\"mspace\\\" style=\\\"margin-right:0.2778em;\\\"\u003e\u003c/span\u003e\u003cspan class=\\\"mrel\\\"\u003e=\u003c/span\u003e\u003cspan class=\\\"mspace\\\" style=\\\"margin-right:0.2778em;\\\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\\\"base\\\"\u003e\u003cspan class=\\\"strut\\\" style=\\\"height:1em;vertical-align:-0.25em;\\\"\u003e\u003c/span\u003e\u003cspan class=\\\"mord mathnormal\\\" style=\\\"margin-right:0.03588em;\\\"\u003eσ\u003c/span\u003e\u003cspan class=\\\"mopen\\\"\u003e(\u003c/span\u003e\u003cspan class=\\\"mord mathnormal\\\" style=\\\"margin-right:0.04398em;\\\"\u003ez\u003c/span\u003e\u003cspan class=\\\"mclose\\\"\u003e)\u003c/span\u003e\u003cspan class=\\\"mspace\\\" style=\\\"margin-right:0.2222em;\\\"\u003e\u003c/span\u003e\u003cspan class=\\\"mbin\\\"\u003e⊗\u003c/span\u003e\u003cspan class=\\\"mspace\\\" style=\\\"margin-right:0.2222em;\\\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\\\"base\\\"\u003e\u003cspan class=\\\"strut\\\" style=\\\"height:0.4306em;\\\"\u003e\u003c/span\u003e\u003cspan class=\\\"mord mathnormal\\\"\u003ex\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\"}}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"$15\"}}],[\"$\",\"h3\",null,{\"className\":\"x-h2\",\"children\":[\"$\",\"$L7\",null,{\"excludeFromContents\":\"$undefined\",\"children\":\"逐部分分析LSTM\"}]}],[\"$\",\"h4\",null,{\"className\":\"x-h3\",\"children\":\"遗忘门\"}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"$16\"}}],[\"$\",\"$L8\",null,{\"src\":\"lstm3.png\",\"width\":\"600px\",\"invertInDarkTheme\":true}],[\"$\",\"div\",null,{\"className\":\"x-highlightblock highlight-background-gray\",\"children\":[[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"举一个概念性的例子：\"}}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"考虑一个语言模型，输入一个句子：\u003ccode class=\\\"x-inline-highlight\\\"\u003eAlice是一名女教师，她喜欢给学生讲课；Bob是一位男司机，他喝酒上瘾。\u003c/code\u003e\"}}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"$17\"}}]]}],[\"$\",\"h4\",null,{\"className\":\"x-h3\",\"children\":\"输入门\"}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"$18\"}}],[\"$\",\"$L8\",null,{\"src\":\"lstm4.png\",\"width\":\"600px\",\"invertInDarkTheme\":true}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"经历这两步之后，便可以相加得到新的单元状态：\"}}],[\"$\",\"$L8\",null,{\"src\":\"lstm5.png\",\"width\":\"600px\",\"invertInDarkTheme\":true}],[\"$\",\"div\",null,{\"className\":\"x-highlightblock highlight-background-gray\",\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"同理，当模型看到\u003ccode class=\\\"x-inline-highlight\\\"\u003eBob是一位男司机\u003c/code\u003e时，我们可能会想丢掉此前的语义信息\u003ccode class=\\\"x-inline-highlight\\\"\u003e女性\u003c/code\u003e，并把新的语义信息\u003ccode class=\\\"x-inline-highlight\\\"\u003e男性\u003c/code\u003e存入单元状态，使得后文输出正确的代词\u003ccode class=\\\"x-inline-highlight\\\"\u003e他\u003c/code\u003e。\"}}]}],[\"$\",\"h4\",null,{\"className\":\"x-h3\",\"children\":\"输出门\"}],[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"$19\"}}],[\"$\",\"$L8\",null,{\"src\":\"lstm6.png\",\"width\":\"600px\",\"invertInDarkTheme\":true}],[\"$\",\"div\",null,{\"className\":\"x-highlightblock highlight-background-gray\",\"children\":[\"$\",\"p\",null,{\"className\":\"x-p\",\"dangerouslySetInnerHTML\":{\"__html\":\"当看到\u003ccode class=\\\"x-inline-highlight\\\"\u003eBob是一位男司机，他……\u003c/code\u003e时，由于出现了主语\u003ccode class=\\\"x-inline-highlight\\\"\u003e他\u003c/code\u003e，模型可能会输出和\u003ccode class=\\\"x-inline-highlight\\\"\u003e谓语动词\u003c/code\u003e有关的语义信息。\"}}]}]],null]]},[\"$\",\"$L1a\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"(blogs)\",\"children\",\"23d\",\"children\",\"learn-rnn-lstm\",\"children\"],\"loading\":\"$undefined\",\"loadingStyles\":\"$undefined\",\"loadingScripts\":\"$undefined\",\"hasLoading\":false,\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L1b\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"styles\":[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/2ca3ce358f319fca.css\",\"precedence\":\"next\",\"crossOrigin\":\"\"}]]}]]},[\"$\",\"$L1a\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"(blogs)\",\"children\",\"23d\",\"children\"],\"loading\":\"$undefined\",\"loadingStyles\":\"$undefined\",\"loadingScripts\":\"$undefined\",\"hasLoading\":false,\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L1b\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"styles\":null}]]},[null,[\"$\",\"div\",null,{\"id\":\"blog-layout\",\"children\":[[\"$\",\"div\",null,{\"id\":\"main\",\"children\":[\"$\",\"$L1a\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"(blogs)\",\"children\"],\"loading\":\"$undefined\",\"loadingStyles\":\"$undefined\",\"loadingScripts\":\"$undefined\",\"hasLoading\":false,\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L1b\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"styles\":null}]}],[\"$\",\"$L1c\",null,{}],[\"$\",\"$L1d\",null,{}]]}],null]]},[null,[\"$\",\"html\",null,{\"lang\":\"zh-CN\",\"suppressHydrationWarning\":true,\"children\":[[\"$\",\"head\",null,{\"children\":[[\"$\",\"link\",null,{\"rel\":\"icon\",\"href\":\"favicon.ico\"}],[\"$\",\"script\",null,{\"async\":true,\"src\":\"https://www.googletagmanager.com/gtag/js?id=G-45BYSZ6WPY\"}],[\"$\",\"script\",null,{\"async\":true,\"src\":\"https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js\"}],[\"$\",\"script\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"\\nwindow.dataLayer = window.dataLayer || [];\\nfunction gtag() {\\n    dataLayer.push(arguments);\\n}\\ngtag('js', new Date());\\ngtag('config', 'G-45BYSZ6WPY');\\nif (!localStorage.getItem('theme')) localStorage.setItem('theme', 'light');\\ndocument.documentElement.setAttribute('class', localStorage.getItem('theme'));\\n\"}}],[\"$\",\"script\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"const a=z=\u003eh.getItem(z),b=(y,z)=\u003eh.setItem(y,z),c=(y,z)=\u003edocument.documentElement.setAttribute(y,z),d='theme',e='dark',f='light',g='class',h=localStorage;a(d)!==e\u0026\u0026a(d)!==f\u0026\u0026b(d,f);a(d)===e?c(g,e):c(g,f);\"}}]]}],[\"$\",\"body\",null,{\"children\":[\"$\",\"$L1e\",null,{\"children\":[[\"$\",\"$L1f\",null,{}],[\"$\",\"$L1a\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"loading\":\"$undefined\",\"loadingStyles\":\"$undefined\",\"loadingScripts\":\"$undefined\",\"hasLoading\":false,\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L1b\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[\"$\",\"div\",null,{\"id\":\"notfound\",\"children\":[[\"$\",\"img\",null,{\"alt\":\"img\",\"src\":\"/images/cry.gif\"}],[\"$\",\"div\",null,{\"id\":\"notfound-404\",\"children\":\"404\"}],[\"$\",\"div\",null,{\"id\":\"notfound-text\",\"children\":\"Page Not Found\"}]]}],\"notFoundStyles\":[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/eccd2e7a1149e571.css\",\"precedence\":\"next\",\"crossOrigin\":\"\"}]],\"styles\":[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/803fe687e7e31b6c.css\",\"precedence\":\"next\",\"crossOrigin\":\"\"}]]}]]}]}]]}],null]],\"initialHead\":[false,\"$L20\"],\"globalErrorComponent\":\"$21\",\"missingSlots\":\"$W22\"}]]\n"])</script><script>self.__next_f.push([1,"20:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}],[\"$\",\"meta\",\"1\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"2\",{\"children\":\"学习RNN和LSTM - 铃木的网络日记\"}],[\"$\",\"link\",\"3\",{\"rel\":\"canonical\",\"href\":\"https://1kuzus.github.io/23d/learn-rnn-lstm/\"}]]\n6:null\n"])</script><script>self.__next_f.push([1,""])</script></body></html>